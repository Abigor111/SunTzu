{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "import jsonschema\n",
    "from jsonschema.exceptions import ValidationError\n",
    "import os\n",
    "import pathlib\n",
    "import os.path\n",
    "import polars as pl \n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "import time\n",
    "import os\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# netCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_netCDF_metadata(self, variables=None, attributes=None):\n",
    "    \"\"\"\n",
    "    Get metadata for variables.\n",
    "\n",
    "    Args:\n",
    "        variables (list): List of variable names. If None, metadata for all variables will be retrieved.\n",
    "        attributes (list): List of attribute names. If None, all attributes will be retrieved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    def read_variable_metadata(var_name, var):\n",
    "        \"\"\"\n",
    "        Print metadata for a variable.\n",
    "\n",
    "        Args:\n",
    "            var_name (str): Name of the variable.\n",
    "            var (Variable): Variable object.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        print(f\"Variable: {var_name}\")\n",
    "        if not var.attrs:\n",
    "            if var.values is not None:\n",
    "                print(f\"    Values: {var.values}\")\n",
    "            else:\n",
    "                print(\"No values were found\")\n",
    "            print(\"    No attributes were found for this variable.\")\n",
    "        else:\n",
    "            print(f\"    Values: {var.values}\")\n",
    "            print(\"    Attributes:\")\n",
    "            for key, value in var.attrs.items():\n",
    "                if attributes is None or key in attributes:\n",
    "                    print(f\"     {key}: {value}\")\n",
    "\n",
    "    if variables is None:\n",
    "        variables = get_file_variables(self)\n",
    "    for var_name in variables:\n",
    "        try:\n",
    "            coord_var = self.coords[var_name]\n",
    "            read_variable_metadata(var_name, coord_var)\n",
    "        except (KeyError, AttributeError) as e:\n",
    "            print(f\"Error occurred while retrieving metadata for variable {var_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_metadata_input(self, variables=None, attributes=None, new_file=False, filename=\"new_file.nc\",):\n",
    "    \"\"\"\n",
    "    This function prompts the user to input metadata for the specified variables in a netCDF file.\n",
    "    \n",
    "    Parameters:\n",
    "    - filename (str): Name of the netCDF file.\n",
    "    - variables (list): List of variable names. If None, all coordinate variables are used.\n",
    "    - attributes (list): List of attribute names. If None, default attributes are used.\n",
    "    - new_file (bool): If True, a new netCDF file is created. If False, the existing file is used.\n",
    "    \n",
    "    Raises:\n",
    "    - KeyError: If a variable was not found.\n",
    "    - FileExistsError: If the specified file already exists.\n",
    "    - ValueError: If the filename is invalid.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define default attributes if not provided\n",
    "    default_attributes = [\n",
    "        \"Units\", \"Long_Name\", \"Standard_Name/Short_Name\", \n",
    "        \"Valid_Min\", \"Valid_Max\", \"Missing_Value\", \n",
    "        \"Fill_Value\", \"Scale_Factor\", \"Add_Offset\", \n",
    "        \"Coordinates\", \"Axis\", \"Description\"\n",
    "    ]\n",
    "    if attributes is None:\n",
    "        attributes = default_attributes\n",
    "\n",
    "    if variables is None:\n",
    "        variables = get_file_variables(self)\n",
    "\n",
    "    for coord_name in variables:\n",
    "        try:\n",
    "            for attribute in attributes:\n",
    "                self[coord_name].attrs[attribute] = input(f\"{coord_name}: {attribute} - Enter value: \")\n",
    "        except KeyError as e:\n",
    "            raise KeyError(f\"Variable {coord_name} not found.\") from e\n",
    "    if new_file:\n",
    "        export_to_file(self,filename)\n",
    "    read_netCDF_metadata(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_metadata_dict(self, dictionary, variables=None, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Insert metadata into a netCDF file using a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - self: The netCDF object.\n",
    "    - dictionary: A dictionary containing the metadata to be inserted.\n",
    "    - filename: The name of the netCDF file to be created or modified.\n",
    "    - variables: A list of variables to insert the metadata into. If None, all variables will be used.\n",
    "    - new_file: If True, a new file will be created. If False, the metadata will be inserted into an existing file.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If dictionary is None.\n",
    "    - AttributeError: If dictionary is not a dictionary.\n",
    "    - FileExistsError: If the specified file already exists.\n",
    "    - ValueError: If the filename is invalid.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if dictionary is None:\n",
    "        raise ValueError(\"Please provide a dictionary.\")\n",
    "    if variables is None:\n",
    "        variables = get_file_variables(self)\n",
    "    if isinstance(dictionary, dict):\n",
    "        for var in variables:\n",
    "            for key, value in dictionary.items():\n",
    "                self[var].attrs[key] = value\n",
    "    else:\n",
    "        raise AttributeError(f\"{dictionary} is not a dictionary.\")\n",
    "    if new_file:\n",
    "        export_to_file(self,filename)\n",
    "    read_netCDF_metadata(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_metadata_json(self, json_file, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Inserts metadata from a JSON file into a netCDF file.\n",
    "\n",
    "    Args:\n",
    "        self: The instance of the class that the function belongs to.\n",
    "        json_file (str): The path to the JSON file containing the metadata.\n",
    "        new_file (bool, optional): A boolean flag indicating whether a new netCDF file should be created. Defaults to False.\n",
    "        filename (str, optional): The name of the new netCDF file. Defaults to \"new_file.nc\".\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified filename already exists.\n",
    "\n",
    "    Returns:\n",
    "        None: The function modifies the attributes of the netCDF file directly.\n",
    "    \"\"\"\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"patternProperties\": {\n",
    "            \".*\": {\n",
    "                \"type\": \"object\",\n",
    "                \"patternProperties\": {\n",
    "                    \".*\": {\n",
    "                        \"type\": \"string\",\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"additionalProperties\": False\n",
    "            }   \n",
    "        }   \n",
    "    try:\n",
    "        with open(json_file, 'r') as file:\n",
    "            metadata = json.load(file)\n",
    "    except IOError:\n",
    "        raise IOError(\"Error opening JSON file. Please check if the file exists or if there are any permission issues.\")\n",
    "    try:\n",
    "        # Validate JSON against schema\n",
    "        jsonschema.validate(instance=metadata, schema=schema)\n",
    "    except ValidationError as e:\n",
    "        raise ValidationError(str(e))\n",
    "    for var, attributes in metadata.items():\n",
    "        for attr, value in attributes.items():\n",
    "            self[var].attrs[attr] = value    \n",
    "    if new_file:\n",
    "        export_to_file(self,filename)\n",
    "    read_netCDF_metadata(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_metadata(self, via=\"input\", **kwargs):\n",
    "    \"\"\"\n",
    "    Insert metadata into the netCDF file.\n",
    "\n",
    "    Parameters:\n",
    "        via (str, optional): The method of providing metadata. Can be \"dict\", \"json\", or \"input\". Defaults to \"input\".\n",
    "        **kwargs: Additional keyword arguments for the specific method.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `via` is not a valid metadata input.\n",
    "    \"\"\"\n",
    "    via_lower = via.lower()\n",
    "    try:\n",
    "        if via_lower == \"dict\":\n",
    "            insert_netCDF_metadata_dict(self, **kwargs)\n",
    "        elif via_lower == \"json\":\n",
    "            insert_netCDF_metadata_json(self, **kwargs)\n",
    "        elif via_lower == \"input\":\n",
    "            insert_netCDF_metadata_input(self, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"{via} is not a valid metadata input.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error inserting netCDF metadata: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attrs(self):\n",
    "    return self.attrs\n",
    "\n",
    "def read_global_metadata(self, attributes=None):\n",
    "    \"\"\"\n",
    "    Print the global metadata attributes of the dataset.\n",
    "\n",
    "    Args:\n",
    "        attributes (list): List of attribute names to print. If None, all attributes will be printed.\n",
    "    \"\"\"\n",
    "    attrs = get_attrs(self)\n",
    "    if not attrs:\n",
    "        print(\"No Global Attributes were found.\")\n",
    "    else:\n",
    "        if attributes is None:\n",
    "            for attr_name, attr_value in attrs.items():\n",
    "                print(attr_name, \":\", attr_value)\n",
    "        else:\n",
    "            for attr_name, attr_value in attrs.items():\n",
    "                if attr_name in attributes:\n",
    "                    print(attr_name, \":\", attr_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_global_metadata_input(self, attributes=None, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Insert global netCDF metadata attributes.\n",
    "\n",
    "    Args:\n",
    "        attributes (list): List of attributes to insert. If None, default attributes will be used.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    default_attributes = [\n",
    "        \"Title\", \"Institution\", \"Source\",\n",
    "        \"History\", \"References\", \"Conventions\",\n",
    "        \"Creator_Author\", \"Project\", \"Description\"\n",
    "    ]\n",
    "    if attributes is None:\n",
    "        attributes = default_attributes\n",
    "    try:\n",
    "        if not isinstance(attributes, list):\n",
    "            raise ValueError(\"attributes must be a list\")\n",
    "        for attribute in attributes:\n",
    "            if not isinstance(attribute, str):\n",
    "                raise ValueError(\"attributes must contain only strings\")\n",
    "            self.attrs[attribute] = input(f\"{attribute} - Enter value: \")\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    if new_file:\n",
    "        export_to_file(self, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_global_metadata_dict(self, dictionary, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Inserts a dictionary of global netCDF metadata into a netCDF file.\n",
    "\n",
    "    Args:\n",
    "        self: The instance of the class that the function belongs to.\n",
    "        dictionary (dict): The dictionary of global netCDF metadata to be inserted.\n",
    "        new_file (bool, optional): A boolean flag indicating whether to create a new netCDF file or not. Default is True.\n",
    "        filename (str, optional): The name of the new netCDF file to be created. Default is \"new_file.nc\".\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If the dictionary parameter is not a valid dictionary.\n",
    "        FileNotFoundError: If the filename is invalid.\n",
    "        FileExistsError: If the specified filename already exists.\n",
    "\n",
    "    Returns:\n",
    "        None. The function doesn't return any value.\n",
    "    \"\"\"\n",
    "    if not isinstance(dictionary, dict):\n",
    "        raise TypeError(f\"{dictionary} is not a dictionary.\")\n",
    "    \n",
    "    for key, value in dictionary.items():\n",
    "        self.attrs[key] = value\n",
    "    if new_file:\n",
    "        export_to_file(self, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_global_metadata_json(self, json_file, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Inserts global metadata from a JSON file into a netCDF file.\n",
    "\n",
    "    Args:\n",
    "        self: The instance of the class calling the function.\n",
    "        json_file (str): The path to the JSON file containing the metadata.\n",
    "        new_file (bool, optional): Indicates whether a new netCDF file should be created. Default is False.\n",
    "        filename (str, optional): Specifies the name of the new netCDF file. Default is \"new_file.nc\".\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If there is an error opening the JSON file.\n",
    "        json.JSONDecodeError: If there is an error decoding the JSON file.\n",
    "        ValueError: If the filename is invalid.\n",
    "        FileExistsError: If the filename already exists.\n",
    "        ValidationError: If the JSON file does not match the specified schema.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"patternProperties\": {\n",
    "            \".*\": { \"type\": \"string\" }\n",
    "        },\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with open(json_file, 'r') as file:\n",
    "            metadata = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"Error opening JSON file. Please check if the file exists or if there are any permission issues.\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise json.JSONDecodeError(\"Error decoding JSON file. Please check if the file contains valid JSON.\")\n",
    "    \n",
    "    try:\n",
    "        # Validate JSON against schema\n",
    "        jsonschema.validate(instance=metadata, schema=schema)\n",
    "    except ValidationError as e:\n",
    "        raise ValidationError(str(e))\n",
    "    if new_file:\n",
    "        export_to_file(self, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet_metadata(self, attributes=None, cols=None):\n",
    "    \"\"\"\n",
    "    Reads the metadata of a Parquet file and prints the attributes of each column.\n",
    "\n",
    "    Args:\n",
    "        attributes (list, optional): A list of attributes to filter the metadata. If not provided, all attributes will be printed.\n",
    "        cols (list, optional): A list of column names to filter the columns. If not provided, metadata of all columns will be printed.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Example Usage:\n",
    "        # Example 1: Read metadata of all columns\n",
    "        read_parquet_metadata()\n",
    "\n",
    "        # Example 2: Read metadata of specific columns\n",
    "        read_parquet_metadata(cols=['column1', 'column2'])\n",
    "\n",
    "        # Example 3: Read metadata of specific attributes\n",
    "        read_parquet_metadata(attributes=['attribute1', 'attribute2'])\n",
    "\n",
    "        # Example 4: Read metadata of specific columns and attributes\n",
    "        read_parquet_metadata(cols=['column1', 'column2'], attributes=['attribute1', 'attribute2'])\n",
    "    \"\"\"\n",
    "    if isinstance(self, pd.DataFrame):\n",
    "        self = pa.Table.from_pandas(self)\n",
    "    if cols is None:\n",
    "        for i in range(self.num_columns):\n",
    "            field = self.field(i)\n",
    "            col = field.name\n",
    "            print(col)\n",
    "            if field.metadata is None:\n",
    "                print(\"    No attributes were found for this column.\")\n",
    "            else:\n",
    "                metadata = {key.decode('utf-8'): value.decode('utf-8') for key, value in field.metadata.items()}\n",
    "                for key, value in metadata.items():\n",
    "                    if attributes is None or key in attributes:\n",
    "                        print(f\"    {key}: {value}\")\n",
    "    else:\n",
    "        for i in range(self.num_columns):\n",
    "            field = self.field(i)\n",
    "            col = field.name\n",
    "            if col in cols:\n",
    "                print(col)\n",
    "                if field.metadata is None:\n",
    "                    print(\"    No attributes were found for this column.\")\n",
    "                else:\n",
    "                    metadata = {key.decode('utf-8'): value.decode('utf-8') for key, value in field.metadata.items()}\n",
    "                    if attributes:\n",
    "                        for attr in attributes:\n",
    "                            if attr in metadata:\n",
    "                                print(f\"    {attr}: {metadata[attr]}\")\n",
    "                            else:\n",
    "                                print(f\"    The '{attr}' attribute was not found in this column's metadata.\")\n",
    "                    else:\n",
    "                        for key, value in metadata.items():\n",
    "                            print(f\"    {key}: {value}\") \n",
    "        # TODO: Check why the else statement is much bigger than the if statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_parquet_metadata_input(self, attributes=None, cols=None, new_file=False, filename=\"new_file.parquet\"):\n",
    "    \"\"\"\n",
    "    Inserts metadata into a Parquet file.\n",
    "\n",
    "    Args:\n",
    "        attributes (list, optional): A list of attribute names to be used as metadata keys. Default value is ['Description', 'Units', 'Data Source', 'Valid Range or Categories'].\n",
    "        cols (list, optional): A list of column names for which metadata needs to be inserted. Default value is all the columns in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pyarrow.Table: A Parquet table with metadata inserted.\n",
    "    \"\"\"\n",
    "    default_attributes = ['Description', 'Units', 'Data Source', 'Valid Range or Categories']\n",
    "    if attributes is None:\n",
    "        attributes = default_attributes\n",
    "    if cols is None:\n",
    "        cols = list(self.columns)  # Suggestion 1: Use list(self.columns) instead of self.columns.tolist()\n",
    "    metadata = []\n",
    "    columns = self.columns  # Suggestion 2: Store self.columns in a variable\n",
    "    cols_set = set(cols)  # Suggestion 3: Convert cols to a set for faster lookup\n",
    "    for col in columns:\n",
    "        if col in cols_set:\n",
    "            col_metadata = {}\n",
    "            for attribute in attributes:\n",
    "                data = input(f\"{col}: {attribute} - Enter value: \")\n",
    "                col_metadata[attribute] = data\n",
    "            metadata.append(col_metadata)\n",
    "        else:\n",
    "            metadata.append(None)\n",
    "    dtypes = self.dtypes  # Suggestion 4: Get all column data types at once\n",
    "    dtypes = [\"string\" if dtype == \"category\" else str(dtype) for dtype in dtypes]\n",
    "    cols_dtypes = zip(columns, dtypes, metadata)\n",
    "    schema = [pa.field(col, pa.type_for_alias(dtype), metadata=meta) for col, dtype, meta in cols_dtypes]\n",
    "    table_schema = pa.schema(schema)\n",
    "    table = pa.Table.from_pandas(self, schema=table_schema)\n",
    "    if new_file:\n",
    "        export_to_file(table, filename)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_parquet_metadata_dict(self, dictionary, cols=None, new_file=False, filename=\"new_file.parquet\"):\n",
    "    \"\"\"\n",
    "    Insert metadata into a netCDF file using a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - self: The netCDF object.\n",
    "    - dictionary: A dictionary containing the metadata to be inserted.\n",
    "    - filename: The name of the netCDF file to be created or modified.\n",
    "    - variables: A list of variables to insert the metadata into. If None, all variables will be used.\n",
    "    - new_file: If True, a new file will be created. If False, the metadata will be inserted into an existing file.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If dictionary is None.\n",
    "    - AttributeError: If dictionary is not a dictionary.\n",
    "    - FileExistsError: If the specified file already exists.\n",
    "    - ValueError: If the filename is invalid.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if dictionary is None:\n",
    "        raise ValueError(\"Please provide a dictionary.\")\n",
    "    if cols is None:\n",
    "        cols = list(self.columns)\n",
    "    columns = self.columns  # Suggestion 2: Store self.columns in a variable\n",
    "    dtypes = self.dtypes  # Suggestion 4: Get all column data types at once\n",
    "    dtypes = [\"string\" if dtype == \"category\" else str(dtype) for dtype in dtypes]\n",
    "    metadata = []\n",
    "    if isinstance(dictionary, dict):\n",
    "        cols_set = set(cols)  # Suggestion 3: Convert cols to a set for faster lookup\n",
    "        for col in columns:\n",
    "            if col in cols_set:\n",
    "                metadata.append(dictionary)\n",
    "            else:\n",
    "                metadata.append(None)\n",
    "        cols_dtypes = zip(columns, dtypes, metadata)\n",
    "        schema = [pa.field(col, pa.type_for_alias(dtype), metadata=meta) for col, dtype, meta in cols_dtypes]\n",
    "        table_schema = pa.schema(schema)\n",
    "        table = pa.Table.from_pandas(self, schema=table_schema)\n",
    "        if new_file:\n",
    "            export_to_file(table, filename)\n",
    "        return table  \n",
    "    else:\n",
    "        raise AttributeError(f\"{dictionary} is not a dictionary.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_parquet_metadata_json(self, json_file, new_file=False, filename=\"new_file.parquet\"):\n",
    "    \"\"\"\n",
    "    Inserts metadata from a JSON file into a netCDF file.\n",
    "\n",
    "    Args:\n",
    "        self: The instance of the class that the function belongs to.\n",
    "        json_file (str): The path to the JSON file containing the metadata.\n",
    "        new_file (bool, optional): A boolean flag indicating whether a new netCDF file should be created. Defaults to False.\n",
    "        filename (str, optional): The name of the new netCDF file. Defaults to \"new_file.nc\".\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified filename already exists.\n",
    "\n",
    "    Returns:\n",
    "        None: The function modifies the attributes of the netCDF file directly.\n",
    "    \"\"\"\n",
    "    schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"patternProperties\": {\n",
    "        \".*\": {\n",
    "            \"type\": \"object\",\n",
    "            \"patternProperties\": {\n",
    "                \".*\": {\n",
    "                    \"type\": \"string\",\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"additionalProperties\": False\n",
    "        }   \n",
    "    }   \n",
    "    try:\n",
    "        with open(json_file, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "    except IOError:\n",
    "        raise IOError(\"Error opening JSON file. Please check if the file exists or if there are any permission issues.\")\n",
    "    try:\n",
    "        # Validate JSON against schema\n",
    "        jsonschema.validate(instance=json_data, schema=schema)\n",
    "    except ValidationError as e:\n",
    "        raise ValidationError(str(e))\n",
    "    cols_dtypes = get_df_cols_dtypes(self)\n",
    "    cols_dtypes = [[col, \"string\"] if dtype == \"category\" else [col, str(dtype)] for col, dtype in cols_dtypes]\n",
    "    metadata = []\n",
    "    for col in cols_dtypes:\n",
    "        if col[0] in json_data:\n",
    "            col_metadata = json_data[col[0]]\n",
    "            metadata.append(col_metadata)\n",
    "        else:\n",
    "            metadata.append(None)\n",
    "    cols_dtypes = zip(cols_dtypes, metadata)\n",
    "    schema = [pa.field(col_dtype[0], pa.type_for_alias(col_dtype[1]), metadata=meta) for col_dtype, meta in cols_dtypes]\n",
    "    table_schema = pa.schema(schema)\n",
    "    table = pa.Table.from_pandas(self, schema=table_schema)\n",
    "    if new_file:\n",
    "        export_to_file(table, filename)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_extension(filename):\n",
    "    suffix = pathlib.Path(filename).suffix\n",
    "    return suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_file(self, filename):\n",
    "    suffixs = [\".nc\", \".parquet\"]\n",
    "    if not os.path.isfile(filename):\n",
    "        if get_file_extension(filename) in suffixs:\n",
    "            if get_file_extension(filename) == \".nc\":\n",
    "                self.to_netcdf(filename)\n",
    "            elif get_file_extension(filename) == \".parquet\":\n",
    "                pq.write_table(self, filename, compression=None)        \n",
    "        else:\n",
    "            raise ValueError(f\"Invalid file extension. Please provide a valid filename. Valid file extesions {suffixs}.\")\n",
    "    else:\n",
    "        raise FileExistsError(f\"{filename} already exists. Please change it or delete it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_variables(self):\n",
    "    variables = list(self.variables.keys())\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtypes(self):\n",
    "    dtypes = (str(dtype) for dtype in self.dtypes)\n",
    "    return dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtype(self, col):\n",
    "    return self[col].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols(self):\n",
    "    cols = list(self.columns)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_dtypes(self):\n",
    "    cols = get_cols(self)\n",
    "    dtypes = get_dtypes(self)\n",
    "    cols_dtypes = list(zip(cols, dtypes))\n",
    "    return cols_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_python_type(min_value, max_value):\n",
    "            if isinstance(min_value, (int, np.integer)) and isinstance(max_value, (int, np.integer)):\n",
    "                return int(min_value), int(max_value)\n",
    "            elif isinstance(min_value, (float, np.floating)) and isinstance(max_value, (float, np.floating)):\n",
    "                return float(min_value), float(max_value)\n",
    "            elif isinstance(min_value, (np.bool_, bool)) and isinstance(max_value, (np.bool_, bool)):\n",
    "                return bool(min_value), bool(max_value)\n",
    "            else:\n",
    "                return min_value, max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'> <class 'bool'>\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "col_min = np.bool_(True)  # Replace this line with self[column].min() in your code\n",
    "col_max = np.bool_(False)  # Replace this line with self[column].max() in your code\n",
    "\n",
    "# Convert to Python types\n",
    "col_min, col_max = convert_python_type(col_min, col_max)\n",
    "\n",
    "print(type(col_min), type(col_max))\n",
    "if isinstance(col_min, int) and isinstance(col_max, int):\n",
    "    if col_min >= -128 and col_max <= 127:\n",
    "         print(\"a\")\n",
    "    elif col_min >= -32768 and col_max <= 32767:\n",
    "         print(\"b\")\n",
    "    elif col_min >= -2147483648 and col_max <= 2147483647:\n",
    "         print(\"c\")\n",
    "    else:\n",
    "         print(\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example numpy bool value\n",
    "numpy_bool_value = np.bool_(False)  # Replace this with your numpy.bool_ value\n",
    "\n",
    "# Convert numpy.bool_ to bool\n",
    "python_bool_value = bool(numpy_bool_value)\n",
    "\n",
    "print(type(python_bool_value))  # Check the type after conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_dtypes(self, change_dtype=False):\n",
    "    dtype_mapping = {\n",
    "        (-128, 127): 'int8',\n",
    "        (-32768, 32767): 'int16',\n",
    "        (-2147483648, 2147483647): 'int32',\n",
    "        (np.finfo(np.float16).min, np.finfo(np.float16).max): 'float16',\n",
    "        (np.finfo(np.float32).min, np.finfo(np.float32).max): 'float32',\n",
    "        (np.finfo(np.float64).min, np.finfo(np.float64).max): 'float64',\n",
    "        (False, True): 'bool'\n",
    "    }\n",
    "\n",
    "    for column in self.columns:\n",
    "        if self[column].dtype != \"category\":\n",
    "            col_min = self[column].min()\n",
    "            col_max = self[column].max()\n",
    "            col_min, col_max = convert_python_type(col_min, col_max)\n",
    "            print(col_min, col_max)\n",
    "            print(column, type(col_min), type(col_max))\n",
    "            if isinstance(col_min, int) and isinstance(col_max, int):\n",
    "                if col_min >= -128 and col_max <= 127:\n",
    "                    return \"int8\"\n",
    "                elif col_min >= -32768 and col_max <= 32767:\n",
    "                    return \"int16\"\n",
    "                elif col_min >= -2147483648 and col_max <= 2147483647:\n",
    "                    return \"int32\"\n",
    "                else:\n",
    "                    return \"int64\"\n",
    "            elif isinstance(col_min, float) and isinstance(col_max, float):\n",
    "                if col_min >= np.finfo(np.float16).min and col_min <= np.finfo(np.float16).max:\n",
    "                    return \"float16\"\n",
    "                elif col_max >= np.finfo(np.float32).min and col_max <= np.finfo(np.float32).max:\n",
    "                    return \"float32\"\n",
    "                else:\n",
    "                    return \"float64\"\n",
    "        else:\n",
    "            return \"category\"\n",
    "        # else:\n",
    "        #     print(\"Debug4\")\n",
    "        #     dtype = 'categorical'\n",
    "        # print(f'The best dtype for {column} is {dtype}')\n",
    "    #     else:\n",
    "    #         dtype = dtype_mapping.get((col_min, col_max), 'category')\n",
    "    #         self[column] = self[column].astype(dtype)\n",
    "\n",
    "    # print('New Dtypes')\n",
    "    # print(self.dtypes)\n",
    "    # return self\n",
    "\n",
    "#get_best_dtypes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_dtype(self, column, change_dtype=False):\n",
    "        if self[column].dtype != \"category\":\n",
    "            col_min = self[column].min()\n",
    "            col_max = self[column].max()\n",
    "            col_min, col_max = convert_python_type(col_min, col_max)\n",
    "            if isinstance(col_min, bool) and isinstance(col_max, bool):\n",
    "                return \"bool\"\n",
    "            elif isinstance(col_min, int) and isinstance(col_max, int):\n",
    "                if col_min >= -128 and col_max <= 127:\n",
    "                    return \"int8\"\n",
    "                elif col_min >= -32768 and col_max <= 32767:\n",
    "                    return \"int16\"\n",
    "                elif col_min >= -2147483648 and col_max <= 2147483647:\n",
    "                    return \"int32\"\n",
    "                else:\n",
    "                    return \"int64\"\n",
    "            elif isinstance(col_min, float) and isinstance(col_max, float):\n",
    "                if col_min >= np.finfo(np.float16).min and col_min <= np.finfo(np.float16).max:\n",
    "                    return \"float16\"\n",
    "                elif col_max >= np.finfo(np.float32).min and col_max <= np.finfo(np.float32).max:\n",
    "                    return \"float32\"\n",
    "                else:\n",
    "                    return \"float64\"\n",
    "        else:\n",
    "            return \"category\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings_on_Board</th>\n",
       "      <th>Parents_on_Board</th>\n",
       "      <th>Ticket_Price</th>\n",
       "      <th>Port_of_Embarkation</th>\n",
       "      <th>Class</th>\n",
       "      <th>Adult/Child</th>\n",
       "      <th>Alone</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Third</td>\n",
       "      <td>Adult</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.28</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>First</td>\n",
       "      <td>Adult</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.92</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Third</td>\n",
       "      <td>Adult</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.10</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>First</td>\n",
       "      <td>Adult</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Third</td>\n",
       "      <td>Adult</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender   Age  Siblings_on_Board  Parents_on_Board  Ticket_Price  \\\n",
       "0      M  22.0                  1                 0          7.25   \n",
       "1      F  38.0                  1                 0         71.28   \n",
       "2      F  26.0                  0                 0          7.92   \n",
       "3      F  35.0                  1                 0         53.10   \n",
       "4      M  35.0                  0                 0          8.05   \n",
       "\n",
       "  Port_of_Embarkation  Class Adult/Child  Alone  Survived  \n",
       "0         Southampton  Third       Adult  False         0  \n",
       "1           Cherbourg  First       Adult  False         1  \n",
       "2         Southampton  Third       Adult   True         1  \n",
       "3         Southampton  First       Adult  False         1  \n",
       "4         Southampton  Third       Adult   True         0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"./aa.parquet\")\n",
    "df.memory_usage().idxmax()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_memory_usage(self, col, unit=\"kb\"):\n",
    "    memory_usage = self[col].memory_usage(deep=True)\n",
    "    if unit == \"kb\":\n",
    "        return f\"{round(memory_usage / 1024, 2)} kb\"    \n",
    "    elif unit == \"mb\":\n",
    "        return f\"{round(memory_usage / (1024**2), 2)} mb\"\n",
    "    else:\n",
    "        return memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage(self, unit=\"kb\"):\n",
    "    total = 0\n",
    "    for col in self.columns:\n",
    "        memory_usage = self[col].memory_usage(deep=True)\n",
    "        total += memory_usage\n",
    "    if unit == \"kb\":\n",
    "        return f\"{round(total / 1024, 2)} kb\"    \n",
    "    elif unit == \"mb\":\n",
    "        return f\"{round(total / (1024**2), 2)} mb\"\n",
    "    else:\n",
    "        return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'29.26 kb'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_memory_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_count(self, col):\n",
    "    return self[col].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_null_count_percentage(self, col):\n",
    "    value = self[col].isnull().sum()\n",
    "    value = round((value/len(self[col])) * 100, 2)  \n",
    "    return f\"{value}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values_count(self, col):\n",
    "    return self[col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_value(self, col):\n",
    "    if self[col].dtype != \"category\":\n",
    "        value = self[col].max()\n",
    "        return value\n",
    "    else:\n",
    "        value = self[col].value_counts().idxmax()\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_value_count(self, col):\n",
    "    if self[col].dtype != \"category\":\n",
    "        value = self[col].max()\n",
    "        value = self[self[col] == value][col].count()\n",
    "        return value\n",
    "    else:\n",
    "        value = self[col].value_counts().max()\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_value_percentage(self, col):\n",
    "    if self[col].dtype != \"category\":\n",
    "        value = self[col].max()\n",
    "        value = self[self[col] == value][col].count()\n",
    "        value = round((value/len(self[col])) * 100, 2)\n",
    "        return f\"{value}%\"\n",
    "    else:\n",
    "        value = self[col].value_counts().max()\n",
    "        value = round((value/len(self[col])) * 100, 2)\n",
    "        return f\"{value}%\"\n",
    "# TODO: Display the name of the value and col, add tip about numerical values.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_value(self, col):\n",
    "    if self[col].dtype != \"category\":\n",
    "        value = self[col].min()\n",
    "        return value\n",
    "    else:\n",
    "        value = self[col].value_counts().idxmin()\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_value_count(self, col):\n",
    "    if self[col].dtype != \"category\":\n",
    "        value = self[col].min()\n",
    "        value = self[self[col] == value][col].count()\n",
    "        return value\n",
    "    else:\n",
    "        value = self[col].value_counts().min()\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_value_percentage(self, col):\n",
    "    if self[col].dtype != \"category\":\n",
    "        value = self[col].min()\n",
    "        value = self[self[col] == value][col].count()\n",
    "        value = round((value/len(self[col])) * 100, 2)\n",
    "        return f\"{value}%\"\n",
    "    else:\n",
    "        value = self[col].value_counts().min()\n",
    "        value = round((value/len(self[col])) * 100, 2)\n",
    "        return f\"{value}%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'61.62%'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_min_value_percentage(df, \"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Dtype</th>\n",
       "      <th>Recommend_Dtype</th>\n",
       "      <th>Memory</th>\n",
       "      <th>Missing_Values</th>\n",
       "      <th>Percentage_of_Missing_Values</th>\n",
       "      <th>Distinct_Values</th>\n",
       "      <th>Most_Common/Max_Value</th>\n",
       "      <th>Occurrences_of_Max_Value</th>\n",
       "      <th>Percentages_of_Occurrences_of_Max_Value</th>\n",
       "      <th>Less_Common/Min_Value</th>\n",
       "      <th>Occurrences_of_Min_Value</th>\n",
       "      <th>Percentage_of_Occurrences_of_Min_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>category</td>\n",
       "      <td>category</td>\n",
       "      <td>1.21 kb</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>577</td>\n",
       "      <td>64.76%</td>\n",
       "      <td>F</td>\n",
       "      <td>314</td>\n",
       "      <td>35.24%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>float64</td>\n",
       "      <td>float16</td>\n",
       "      <td>7.09 kb</td>\n",
       "      <td>177</td>\n",
       "      <td>19.87%</td>\n",
       "      <td>88</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11%</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siblings_on_Board</td>\n",
       "      <td>int8</td>\n",
       "      <td>int8</td>\n",
       "      <td>1.0 kb</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.79%</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>68.24%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parents_on_Board</td>\n",
       "      <td>int8</td>\n",
       "      <td>int8</td>\n",
       "      <td>1.0 kb</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11%</td>\n",
       "      <td>0</td>\n",
       "      <td>678</td>\n",
       "      <td>76.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ticket_Price</td>\n",
       "      <td>float64</td>\n",
       "      <td>float16</td>\n",
       "      <td>7.09 kb</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>236</td>\n",
       "      <td>512.33</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.68%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Port_of_Embarkation</td>\n",
       "      <td>category</td>\n",
       "      <td>category</td>\n",
       "      <td>1.3 kb</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>3</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>644</td>\n",
       "      <td>72.28%</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>77</td>\n",
       "      <td>8.64%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Class</td>\n",
       "      <td>category</td>\n",
       "      <td>category</td>\n",
       "      <td>1.28 kb</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>3</td>\n",
       "      <td>Third</td>\n",
       "      <td>491</td>\n",
       "      <td>55.11%</td>\n",
       "      <td>Second</td>\n",
       "      <td>184</td>\n",
       "      <td>20.65%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adult/Child</td>\n",
       "      <td>category</td>\n",
       "      <td>category</td>\n",
       "      <td>1.22 kb</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>2</td>\n",
       "      <td>Adult</td>\n",
       "      <td>808</td>\n",
       "      <td>90.68%</td>\n",
       "      <td>Child</td>\n",
       "      <td>83</td>\n",
       "      <td>9.32%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alone</td>\n",
       "      <td>bool</td>\n",
       "      <td>bool</td>\n",
       "      <td>1.0 kb</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>537</td>\n",
       "      <td>60.27%</td>\n",
       "      <td>False</td>\n",
       "      <td>354</td>\n",
       "      <td>39.73%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Survived</td>\n",
       "      <td>int64</td>\n",
       "      <td>int8</td>\n",
       "      <td>7.09 kb</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "      <td>38.38%</td>\n",
       "      <td>0</td>\n",
       "      <td>549</td>\n",
       "      <td>61.62%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Column     Dtype Recommend_Dtype   Memory  Missing_Values  \\\n",
       "0               Gender  category        category  1.21 kb               0   \n",
       "1                  Age   float64         float16  7.09 kb             177   \n",
       "2    Siblings_on_Board      int8            int8   1.0 kb               0   \n",
       "3     Parents_on_Board      int8            int8   1.0 kb               0   \n",
       "4         Ticket_Price   float64         float16  7.09 kb               0   \n",
       "5  Port_of_Embarkation  category        category   1.3 kb               2   \n",
       "6                Class  category        category  1.28 kb               0   \n",
       "7          Adult/Child  category        category  1.22 kb               0   \n",
       "8                Alone      bool            bool   1.0 kb               0   \n",
       "9             Survived     int64            int8  7.09 kb               0   \n",
       "\n",
       "  Percentage_of_Missing_Values  Distinct_Values Most_Common/Max_Value  \\\n",
       "0                         0.0%                2                     M   \n",
       "1                       19.87%               88                  80.0   \n",
       "2                         0.0%                7                     8   \n",
       "3                         0.0%                7                     6   \n",
       "4                         0.0%              236                512.33   \n",
       "5                        0.22%                3           Southampton   \n",
       "6                         0.0%                3                 Third   \n",
       "7                         0.0%                2                 Adult   \n",
       "8                         0.0%                2                  True   \n",
       "9                         0.0%                2                     1   \n",
       "\n",
       "   Occurrences_of_Max_Value Percentages_of_Occurrences_of_Max_Value  \\\n",
       "0                       577                                  64.76%   \n",
       "1                         1                                   0.11%   \n",
       "2                         7                                   0.79%   \n",
       "3                         1                                   0.11%   \n",
       "4                         3                                   0.34%   \n",
       "5                       644                                  72.28%   \n",
       "6                       491                                  55.11%   \n",
       "7                       808                                  90.68%   \n",
       "8                       537                                  60.27%   \n",
       "9                       342                                  38.38%   \n",
       "\n",
       "  Less_Common/Min_Value  Occurrences_of_Min_Value  \\\n",
       "0                     F                       314   \n",
       "1                  0.42                         1   \n",
       "2                     0                       608   \n",
       "3                     0                       678   \n",
       "4                   0.0                        15   \n",
       "5            Queenstown                        77   \n",
       "6                Second                       184   \n",
       "7                 Child                        83   \n",
       "8                 False                       354   \n",
       "9                     0                       549   \n",
       "\n",
       "  Percentage_of_Occurrences_of_Min_Value  \n",
       "0                                 35.24%  \n",
       "1                                  0.11%  \n",
       "2                                 68.24%  \n",
       "3                                 76.09%  \n",
       "4                                  1.68%  \n",
       "5                                  8.64%  \n",
       "6                                 20.65%  \n",
       "7                                  9.32%  \n",
       "8                                 39.73%  \n",
       "9                                 61.62%  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = []\n",
    "for col in df.columns:\n",
    "    col_info = [\n",
    "        col,\n",
    "        get_dtype(df, col),\n",
    "        get_best_dtype(df, col),\n",
    "        get_col_memory_usage(df, col),\n",
    "        get_null_count(df, col),\n",
    "        get_null_count_percentage(df, col),\n",
    "        get_unique_values_count(df, col),\n",
    "        get_max_value(df, col),\n",
    "        get_max_value_count(df, col),\n",
    "        get_max_value_percentage(df, col),\n",
    "        get_min_value(df, col),\n",
    "        get_min_value_count(df, col),\n",
    "        get_min_value_percentage(df, col)\n",
    "    ]\n",
    "    dataframe.append(col_info)\n",
    "\n",
    "column_names = [\n",
    "    'Column',\n",
    "    'Dtype',\n",
    "    'Recommend_Dtype',\n",
    "    'Memory',\n",
    "    'Missing_Values',\n",
    "    'Percentage_of_Missing_Values',\n",
    "    'Distinct_Values',\n",
    "    'Most_Common/Max_Value',\n",
    "    'Occurrences_of_Max_Value',\n",
    "    'Percentages_of_Occurrences_of_Max_Value',\n",
    "    'Less_Common/Min_Value',\n",
    "    'Occurrences_of_Min_Value',\n",
    "    'Percentage_of_Occurrences_of_Min_Value'\n",
    "]\n",
    "\n",
    "dataframe = pd.DataFrame(dataframe, columns=column_names)\n",
    "dataframe.head(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telegram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://api.telegram.org/bot6148622889:AAFHdvQ_CxImlx1VEXE_vYhg4_2NFXk1OyU/sendPhoto\"\n",
    "def send_images_via_telegram(file_path):\n",
    "    my_file = open(file_path, 'rb')\n",
    "    parameters = {\n",
    "    \"chat_id\" : \"-935188347\",\n",
    "    \"caption\" : \"This is a caption\"\n",
    "    }\n",
    "    files = {   \n",
    "    \"photo\" : my_file\n",
    "    }\n",
    "    resp = requests.post(base_url, data=parameters, files=files)\n",
    "    print(resp.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_token = \"xoxp-5452682117826-5446024818310-5452588829571-92e60adc3ecd07a736b6faea910b8831\"\n",
    "channel_id = \"C05DAGDAPEX\"\n",
    "client = WebClient(token=slack_token)\n",
    "def send_images_via_slack(file_path):\n",
    "    try:\n",
    "        response = client.files_upload(\n",
    "                channels=channel_id,\n",
    "                file=file_path\n",
    "                )\n",
    "        print(response)\n",
    "    except SlackApiError as e:\n",
    "        print(f\"Error uploading file: {e.response['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## netCDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = xr.open_dataset(\"example.nc\")\n",
    "# read_netCDF_metadata(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables = [\"lat\", \"lon\"]\n",
    "# attributes= [\"Units\"]\n",
    "# insert_netCDF_metadata(df, via=\"input\", variables=variables, attributes=attributes, new_file=True, filename=\"wdwee.nbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wdwee = xr.open_dataset(\"wdwee.nc\")\n",
    "# read_netCDF_metadata(wdwee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pq.read_table(\"./updated_Titanic.parquet\")\n",
    "# read_parquet_metadata(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "    units: Celsius\n",
      "    description: Temperature dwd\n",
      "Age\n",
      "    No attributes were found for this column.\n",
      "Siblings_on_Board\n",
      "    No attributes were found for this column.\n",
      "Parents_on_Board\n",
      "    No attributes were found for this column.\n",
      "Ticket_Price\n",
      "    No attributes were found for this column.\n",
      "Port_of_Embarkation\n",
      "    No attributes were found for this column.\n",
      "Class\n",
      "    No attributes were found for this column.\n",
      "Adult/Child\n",
      "    No attributes were found for this column.\n",
      "Alone\n",
      "    units: Pascal\n",
      "    description: Pressure readings\n",
      "Survived\n",
      "    No attributes were found for this column.\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_parquet(\"./Titanic.parquet\")\n",
    "# get_df_cols_dtypes(df)\n",
    "# df = insert_parquet_metadata_json(df, \"./bosses.json\", True, \"ddwd.parquet\")\n",
    "# df = pq.read_table(\"./ddwd.parquet\")\n",
    "# read_parquet_metadata(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lat', 'lon', 'los', 'pair', 'ref', 'rep']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = xr.open_dataset(\"./dw.nc\")\n",
    "# get_file_variables(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygmtsar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
