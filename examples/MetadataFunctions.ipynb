{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "import jsonschema\n",
    "from jsonschema.exceptions import ValidationError\n",
    "import os\n",
    "from tqdm.notebook  import tqdm\n",
    "import pathlib\n",
    "import os.path\n",
    "import polars as pl \n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "import time\n",
    "import os\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./aa.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = ProfileReport(df, title=\"Profiling Report\", html={'style':{'full_width': True}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# netCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_netCDF_metadata(self, variables=None, attributes=None):\n",
    "    \"\"\"\n",
    "    Get metadata for variables.\n",
    "\n",
    "    Args:\n",
    "        variables (list): List of variable names. If None, metadata for all variables will be retrieved.\n",
    "        attributes (list): List of attribute names. If None, all attributes will be retrieved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    def read_variable_metadata(var_name, var):\n",
    "        \"\"\"\n",
    "        Print metadata for a variable.\n",
    "\n",
    "        Args:\n",
    "            var_name (str): Name of the variable.\n",
    "            var (Variable): Variable object.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        print(f\"Variable: {var_name}\")\n",
    "        if not var.attrs:\n",
    "            if var.values is not None:\n",
    "                print(f\"    Values: {var.values}\")\n",
    "            else:\n",
    "                print(\"No values were found\")\n",
    "            print(\"    No attributes were found for this variable.\")\n",
    "        else:\n",
    "            print(f\"    Values: {var.values}\")\n",
    "            print(\"    Attributes:\")\n",
    "            for key, value in var.attrs.items():\n",
    "                if attributes is None or key in attributes:\n",
    "                    print(f\"     {key}: {value}\")\n",
    "\n",
    "    if variables is None:\n",
    "        variables = get_file_variables(self)\n",
    "    for var_name in variables:\n",
    "        try:\n",
    "            coord_var = self.coords[var_name]\n",
    "            read_variable_metadata(var_name, coord_var)\n",
    "        except (KeyError, AttributeError) as e:\n",
    "            print(f\"Error occurred while retrieving metadata for variable {var_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_metadata_input(self, variables=None, attributes=None, new_file=False, filename=\"new_file.nc\",):\n",
    "    \"\"\"\n",
    "    This function prompts the user to input metadata for the specified variables in a netCDF file.\n",
    "    \n",
    "    Parameters:\n",
    "    - filename (str): Name of the netCDF file.\n",
    "    - variables (list): List of variable names. If None, all coordinate variables are used.\n",
    "    - attributes (list): List of attribute names. If None, default attributes are used.\n",
    "    - new_file (bool): If True, a new netCDF file is created. If False, the existing file is used.\n",
    "    \n",
    "    Raises:\n",
    "    - KeyError: If a variable was not found.\n",
    "    - FileExistsError: If the specified file already exists.\n",
    "    - ValueError: If the filename is invalid.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define default attributes if not provided\n",
    "    default_attributes = [\n",
    "        \"Units\", \"Long_Name\", \"Standard_Name/Short_Name\", \n",
    "        \"Valid_Min\", \"Valid_Max\", \"Missing_Value\", \n",
    "        \"Fill_Value\", \"Scale_Factor\", \"Add_Offset\", \n",
    "        \"Coordinates\", \"Axis\", \"Description\"\n",
    "    ]\n",
    "    if attributes is None:\n",
    "        attributes = default_attributes\n",
    "\n",
    "    if variables is None:\n",
    "        variables = get_file_variables(self)\n",
    "\n",
    "    for coord_name in variables:\n",
    "        try:\n",
    "            for attribute in attributes:\n",
    "                self[coord_name].attrs[attribute] = input(f\"{coord_name}: {attribute} - Enter value: \")\n",
    "        except KeyError as e:\n",
    "            raise KeyError(f\"Variable {coord_name} not found.\") from e\n",
    "    if new_file:\n",
    "        export_to_file(self,filename)\n",
    "    read_netCDF_metadata(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_metadata_dict(self, dictionary, variables=None, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Insert metadata into a netCDF file using a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - self: The netCDF object.\n",
    "    - dictionary: A dictionary containing the metadata to be inserted.\n",
    "    - filename: The name of the netCDF file to be created or modified.\n",
    "    - variables: A list of variables to insert the metadata into. If None, all variables will be used.\n",
    "    - new_file: If True, a new file will be created. If False, the metadata will be inserted into an existing file.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If dictionary is None.\n",
    "    - AttributeError: If dictionary is not a dictionary.\n",
    "    - FileExistsError: If the specified file already exists.\n",
    "    - ValueError: If the filename is invalid.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if dictionary is None:\n",
    "        raise ValueError(\"Please provide a dictionary.\")\n",
    "    if variables is None:\n",
    "        variables = get_file_variables(self)\n",
    "    if isinstance(dictionary, dict):\n",
    "        for var in variables:\n",
    "            for key, value in dictionary.items():\n",
    "                self[var].attrs[key] = value\n",
    "    else:\n",
    "        raise AttributeError(f\"{dictionary} is not a dictionary.\")\n",
    "    if new_file:\n",
    "        export_to_file(self,filename)\n",
    "    read_netCDF_metadata(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_metadata_json(self, json_file, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Inserts metadata from a JSON file into a netCDF file.\n",
    "\n",
    "    Args:\n",
    "        self: The instance of the class that the function belongs to.\n",
    "        json_file (str): The path to the JSON file containing the metadata.\n",
    "        new_file (bool, optional): A boolean flag indicating whether a new netCDF file should be created. Defaults to False.\n",
    "        filename (str, optional): The name of the new netCDF file. Defaults to \"new_file.nc\".\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified filename already exists.\n",
    "\n",
    "    Returns:\n",
    "        None: The function modifies the attributes of the netCDF file directly.\n",
    "    \"\"\"\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"patternProperties\": {\n",
    "            \".*\": {\n",
    "                \"type\": \"object\",\n",
    "                \"patternProperties\": {\n",
    "                    \".*\": {\n",
    "                        \"type\": \"string\",\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"additionalProperties\": False\n",
    "            }   \n",
    "        }   \n",
    "    try:\n",
    "        with open(json_file, 'r') as file:\n",
    "            metadata = json.load(file)\n",
    "    except IOError:\n",
    "        raise IOError(\"Error opening JSON file. Please check if the file exists or if there are any permission issues.\")\n",
    "    try:\n",
    "        # Validate JSON against schema\n",
    "        jsonschema.validate(instance=metadata, schema=schema)\n",
    "    except ValidationError as e:\n",
    "        raise ValidationError(str(e))\n",
    "    for var, attributes in metadata.items():\n",
    "        for attr, value in attributes.items():\n",
    "            self[var].attrs[attr] = value    \n",
    "    if new_file:\n",
    "        export_to_file(self,filename)\n",
    "    read_netCDF_metadata(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_metadata(self, via=\"input\", **kwargs):\n",
    "    \"\"\"\n",
    "    Insert metadata into the netCDF file.\n",
    "\n",
    "    Parameters:\n",
    "        via (str, optional): The method of providing metadata. Can be \"dict\", \"json\", or \"input\". Defaults to \"input\".\n",
    "        **kwargs: Additional keyword arguments for the specific method.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `via` is not a valid metadata input.\n",
    "    \"\"\"\n",
    "    via_lower = via.lower()\n",
    "    try:\n",
    "        if via_lower == \"dict\":\n",
    "            insert_netCDF_metadata_dict(self, **kwargs)\n",
    "        elif via_lower == \"json\":\n",
    "            insert_netCDF_metadata_json(self, **kwargs)\n",
    "        elif via_lower == \"input\":\n",
    "            insert_netCDF_metadata_input(self, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"{via} is not a valid metadata input.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error inserting netCDF metadata: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attrs(self):\n",
    "    return self.attrs\n",
    "\n",
    "def read_global_metadata(self, attributes=None):\n",
    "    \"\"\"\n",
    "    Print the global metadata attributes of the dataset.\n",
    "\n",
    "    Args:\n",
    "        attributes (list): List of attribute names to print. If None, all attributes will be printed.\n",
    "    \"\"\"\n",
    "    attrs = get_attrs(self)\n",
    "    if not attrs:\n",
    "        print(\"No Global Attributes were found.\")\n",
    "    else:\n",
    "        if attributes is None:\n",
    "            for attr_name, attr_value in attrs.items():\n",
    "                print(attr_name, \":\", attr_value)\n",
    "        else:\n",
    "            for attr_name, attr_value in attrs.items():\n",
    "                if attr_name in attributes:\n",
    "                    print(attr_name, \":\", attr_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_global_metadata_input(self, attributes=None, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Insert global netCDF metadata attributes.\n",
    "\n",
    "    Args:\n",
    "        attributes (list): List of attributes to insert. If None, default attributes will be used.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    default_attributes = [\n",
    "        \"Title\", \"Institution\", \"Source\",\n",
    "        \"History\", \"References\", \"Conventions\",\n",
    "        \"Creator_Author\", \"Project\", \"Description\"\n",
    "    ]\n",
    "    if attributes is None:\n",
    "        attributes = default_attributes\n",
    "    try:\n",
    "        if not isinstance(attributes, list):\n",
    "            raise ValueError(\"attributes must be a list\")\n",
    "        for attribute in attributes:\n",
    "            if not isinstance(attribute, str):\n",
    "                raise ValueError(\"attributes must contain only strings\")\n",
    "            self.attrs[attribute] = input(f\"{attribute} - Enter value: \")\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    if new_file:\n",
    "        export_to_file(self, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_global_metadata_dict(self, dictionary, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Inserts a dictionary of global netCDF metadata into a netCDF file.\n",
    "\n",
    "    Args:\n",
    "        self: The instance of the class that the function belongs to.\n",
    "        dictionary (dict): The dictionary of global netCDF metadata to be inserted.\n",
    "        new_file (bool, optional): A boolean flag indicating whether to create a new netCDF file or not. Default is True.\n",
    "        filename (str, optional): The name of the new netCDF file to be created. Default is \"new_file.nc\".\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If the dictionary parameter is not a valid dictionary.\n",
    "        FileNotFoundError: If the filename is invalid.\n",
    "        FileExistsError: If the specified filename already exists.\n",
    "\n",
    "    Returns:\n",
    "        None. The function doesn't return any value.\n",
    "    \"\"\"\n",
    "    if not isinstance(dictionary, dict):\n",
    "        raise TypeError(f\"{dictionary} is not a dictionary.\")\n",
    "    \n",
    "    for key, value in dictionary.items():\n",
    "        self.attrs[key] = value\n",
    "    if new_file:\n",
    "        export_to_file(self, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_global_metadata_json(self, json_file, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Inserts global metadata from a JSON file into a netCDF file.\n",
    "\n",
    "    Args:\n",
    "        self: The instance of the class calling the function.\n",
    "        json_file (str): The path to the JSON file containing the metadata.\n",
    "        new_file (bool, optional): Indicates whether a new netCDF file should be created. Default is False.\n",
    "        filename (str, optional): Specifies the name of the new netCDF file. Default is \"new_file.nc\".\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If there is an error opening the JSON file.\n",
    "        json.JSONDecodeError: If there is an error decoding the JSON file.\n",
    "        ValueError: If the filename is invalid.\n",
    "        FileExistsError: If the filename already exists.\n",
    "        ValidationError: If the JSON file does not match the specified schema.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"patternProperties\": {\n",
    "            \".*\": { \"type\": \"string\" }\n",
    "        },\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with open(json_file, 'r') as file:\n",
    "            metadata = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"Error opening JSON file. Please check if the file exists or if there are any permission issues.\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise json.JSONDecodeError(\"Error decoding JSON file. Please check if the file contains valid JSON.\")\n",
    "    \n",
    "    try:\n",
    "        # Validate JSON against schema\n",
    "        jsonschema.validate(instance=metadata, schema=schema)\n",
    "    except ValidationError as e:\n",
    "        raise ValidationError(str(e))\n",
    "    if new_file:\n",
    "        export_to_file(self, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet_metadata(self, attributes=None, cols=None):\n",
    "    \"\"\"\n",
    "    Reads the metadata of a Parquet file and prints the attributes of each column.\n",
    "\n",
    "    Args:\n",
    "        attributes (list, optional): A list of attributes to filter the metadata. If not provided, all attributes will be printed.\n",
    "        cols (list, optional): A list of column names to filter the columns. If not provided, metadata of all columns will be printed.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Example Usage:\n",
    "        # Example 1: Read metadata of all columns\n",
    "        read_parquet_metadata()\n",
    "\n",
    "        # Example 2: Read metadata of specific columns\n",
    "        read_parquet_metadata(cols=['column1', 'column2'])\n",
    "\n",
    "        # Example 3: Read metadata of specific attributes\n",
    "        read_parquet_metadata(attributes=['attribute1', 'attribute2'])\n",
    "\n",
    "        # Example 4: Read metadata of specific columns and attributes\n",
    "        read_parquet_metadata(cols=['column1', 'column2'], attributes=['attribute1', 'attribute2'])\n",
    "    \"\"\"\n",
    "    if isinstance(self, pd.DataFrame):\n",
    "        self = pa.Table.from_pandas(self)\n",
    "    if cols is None:\n",
    "        for i in range(self.num_columns):\n",
    "            field = self.field(i)\n",
    "            col = field.name\n",
    "            print(col)\n",
    "            if field.metadata is None:\n",
    "                print(\"    No attributes were found for this column.\")\n",
    "            else:\n",
    "                metadata = {key.decode('utf-8'): value.decode('utf-8') for key, value in field.metadata.items()}\n",
    "                for key, value in metadata.items():\n",
    "                    if attributes is None or key in attributes:\n",
    "                        print(f\"    {key}: {value}\")\n",
    "    else:\n",
    "        for i in range(self.num_columns):\n",
    "            field = self.field(i)\n",
    "            col = field.name\n",
    "            if col in cols:\n",
    "                print(col)\n",
    "                if field.metadata is None:\n",
    "                    print(\"    No attributes were found for this column.\")\n",
    "                else:\n",
    "                    metadata = {key.decode('utf-8'): value.decode('utf-8') for key, value in field.metadata.items()}\n",
    "                    if attributes:\n",
    "                        for attr in attributes:\n",
    "                            if attr in metadata:\n",
    "                                print(f\"    {attr}: {metadata[attr]}\")\n",
    "                            else:\n",
    "                                print(f\"    The '{attr}' attribute was not found in this column's metadata.\")\n",
    "                    else:\n",
    "                        for key, value in metadata.items():\n",
    "                            print(f\"    {key}: {value}\") \n",
    "        # TODO: Check why the else statement is much bigger than the if statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_parquet_metadata_input(self, attributes=None, cols=None, new_file=False, filename=\"new_file.parquet\"):\n",
    "    \"\"\"\n",
    "    Inserts metadata into a Parquet file.\n",
    "\n",
    "    Args:\n",
    "        attributes (list, optional): A list of attribute names to be used as metadata keys. Default value is ['Description', 'Units', 'Data Source', 'Valid Range or Categories'].\n",
    "        cols (list, optional): A list of column names for which metadata needs to be inserted. Default value is all the columns in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pyarrow.Table: A Parquet table with metadata inserted.\n",
    "    \"\"\"\n",
    "    default_attributes = ['Description', 'Units', 'Data Source', 'Valid Range or Categories']\n",
    "    if attributes is None:\n",
    "        attributes = default_attributes\n",
    "    if cols is None:\n",
    "        cols = list(self.columns)  # Suggestion 1: Use list(self.columns) instead of self.columns.tolist()\n",
    "    metadata = []\n",
    "    columns = self.columns  # Suggestion 2: Store self.columns in a variable\n",
    "    cols_set = set(cols)  # Suggestion 3: Convert cols to a set for faster lookup\n",
    "    for col in columns:\n",
    "        if col in cols_set:\n",
    "            col_metadata = {}\n",
    "            for attribute in attributes:\n",
    "                data = input(f\"{col}: {attribute} - Enter value: \")\n",
    "                col_metadata[attribute] = data\n",
    "            metadata.append(col_metadata)\n",
    "        else:\n",
    "            metadata.append(None)\n",
    "    dtypes = self.dtypes  # Suggestion 4: Get all column data types at once\n",
    "    dtypes = [\"string\" if dtype == \"category\" else str(dtype) for dtype in dtypes]\n",
    "    cols_dtypes = zip(columns, dtypes, metadata)\n",
    "    schema = [pa.field(col, pa.type_for_alias(dtype), metadata=meta) for col, dtype, meta in cols_dtypes]\n",
    "    table_schema = pa.schema(schema)\n",
    "    table = pa.Table.from_pandas(self, schema=table_schema)\n",
    "    if new_file:\n",
    "        export_to_file(table, filename)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_parquet_metadata_dict(self, dictionary, cols=None, new_file=False, filename=\"new_file.parquet\"):\n",
    "    \"\"\"\n",
    "    Insert metadata into a netCDF file using a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - self: The netCDF object.\n",
    "    - dictionary: A dictionary containing the metadata to be inserted.\n",
    "    - filename: The name of the netCDF file to be created or modified.\n",
    "    - variables: A list of variables to insert the metadata into. If None, all variables will be used.\n",
    "    - new_file: If True, a new file will be created. If False, the metadata will be inserted into an existing file.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If dictionary is None.\n",
    "    - AttributeError: If dictionary is not a dictionary.\n",
    "    - FileExistsError: If the specified file already exists.\n",
    "    - ValueError: If the filename is invalid.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if dictionary is None:\n",
    "        raise ValueError(\"Please provide a dictionary.\")\n",
    "    if cols is None:\n",
    "        cols = list(self.columns)\n",
    "    columns = self.columns  # Suggestion 2: Store self.columns in a variable\n",
    "    dtypes = self.dtypes  # Suggestion 4: Get all column data types at once\n",
    "    dtypes = [\"string\" if dtype == \"category\" else str(dtype) for dtype in dtypes]\n",
    "    metadata = []\n",
    "    if isinstance(dictionary, dict):\n",
    "        cols_set = set(cols)  # Suggestion 3: Convert cols to a set for faster lookup\n",
    "        for col in columns:\n",
    "            if col in cols_set:\n",
    "                metadata.append(dictionary)\n",
    "            else:\n",
    "                metadata.append(None)\n",
    "        cols_dtypes = zip(columns, dtypes, metadata)\n",
    "        schema = [pa.field(col, pa.type_for_alias(dtype), metadata=meta) for col, dtype, meta in cols_dtypes]\n",
    "        table_schema = pa.schema(schema)\n",
    "        table = pa.Table.from_pandas(self, schema=table_schema)\n",
    "        if new_file:\n",
    "            export_to_file(table, filename)\n",
    "        return table  \n",
    "    else:\n",
    "        raise AttributeError(f\"{dictionary} is not a dictionary.\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_parquet_metadata_json(self, json_file, new_file=False, filename=\"new_file.parquet\"):\n",
    "    \"\"\"\n",
    "    Inserts metadata from a JSON file into a netCDF file.\n",
    "\n",
    "    Args:\n",
    "        self: The instance of the class that the function belongs to.\n",
    "        json_file (str): The path to the JSON file containing the metadata.\n",
    "        new_file (bool, optional): A boolean flag indicating whether a new netCDF file should be created. Defaults to False.\n",
    "        filename (str, optional): The name of the new netCDF file. Defaults to \"new_file.nc\".\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified filename already exists.\n",
    "\n",
    "    Returns:\n",
    "        None: The function modifies the attributes of the netCDF file directly.\n",
    "    \"\"\"\n",
    "    schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"patternProperties\": {\n",
    "        \".*\": {\n",
    "            \"type\": \"object\",\n",
    "            \"patternProperties\": {\n",
    "                \".*\": {\n",
    "                    \"type\": \"string\",\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"additionalProperties\": False\n",
    "        }   \n",
    "    }   \n",
    "    try:\n",
    "        with open(json_file, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "    except IOError:\n",
    "        raise IOError(\"Error opening JSON file. Please check if the file exists or if there are any permission issues.\")\n",
    "    try:\n",
    "        # Validate JSON against schema\n",
    "        jsonschema.validate(instance=json_data, schema=schema)\n",
    "    except ValidationError as e:\n",
    "        raise ValidationError(str(e))\n",
    "    cols_dtypes = get_cols_dtypes(self)\n",
    "    cols_dtypes = [[col, \"string\"] if dtype == \"category\" else [col, str(dtype)] for col, dtype in cols_dtypes]\n",
    "    metadata = []\n",
    "    for col in cols_dtypes:\n",
    "        if col[0] in json_data:\n",
    "            col_metadata = json_data[col[0]]\n",
    "            metadata.append(col_metadata)\n",
    "        else:\n",
    "            metadata.append(None)\n",
    "    cols_dtypes = zip(cols_dtypes, metadata)\n",
    "    schema = [pa.field(col_dtype[0], pa.type_for_alias(col_dtype[1]), metadata=meta) for col_dtype, meta in cols_dtypes]\n",
    "    table_schema = pa.schema(schema)\n",
    "    table = pa.Table.from_pandas(self, schema=table_schema)\n",
    "    if new_file:\n",
    "        export_to_file(table, filename)\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_extension(filename):\n",
    "    suffix = pathlib.Path(filename).suffix\n",
    "    return suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_file(self, filename):\n",
    "    suffixs = [\".nc\", \".parquet\"]\n",
    "    if not os.path.isfile(filename):\n",
    "        if get_file_extension(filename) in suffixs:\n",
    "            if get_file_extension(filename) == \".nc\":\n",
    "                self.to_netcdf(filename)\n",
    "            elif get_file_extension(filename) == \".parquet\":\n",
    "                pq.write_table(self, filename, compression=None)        \n",
    "        else:\n",
    "            raise ValueError(f\"Invalid file extension. Please provide a valid filename. Valid file extesions {suffixs}.\")\n",
    "    else:\n",
    "        raise FileExistsError(f\"{filename} already exists. Please change it or delete it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Col Statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_variables(self):\n",
    "    variables = list(self.variables.keys())\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtypes(self):\n",
    "    dtypes = (str(dtype) for dtype in self.dtypes)\n",
    "    return dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtype(self, col):\n",
    "    return self[col].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols(self):\n",
    "    cols = list(self.columns)\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols_dtypes(self):\n",
    "    cols = get_cols(self)\n",
    "    dtypes = get_dtypes(self)\n",
    "    cols_dtypes = list(zip(cols, dtypes))\n",
    "    return cols_dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_python_type(min_value, max_value):\n",
    "            if isinstance(min_value, (int, np.integer)) and isinstance(max_value, (int, np.integer)):\n",
    "                return int(min_value), int(max_value)\n",
    "            elif isinstance(min_value, (float, np.floating)) and isinstance(max_value, (float, np.floating)):\n",
    "                return float(min_value), float(max_value)\n",
    "            elif isinstance(min_value, (np.bool_, bool)) and isinstance(max_value, (np.bool_, bool)):\n",
    "                return bool(min_value), bool(max_value)\n",
    "            else:\n",
    "                return min_value, max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_dtypes(self, cols=None, convert=False):\n",
    "    if cols is None:\n",
    "        cols = self.columns\n",
    "    for col in cols:    \n",
    "        try:\n",
    "            if pd.api.types.is_numeric_dtype(self[col]):\n",
    "                col_min = self[col].min()\n",
    "                col_max = self[col].max()\n",
    "                col_min, col_max = convert_python_type(col_min, col_max)\n",
    "                if isinstance(col_min, bool) and isinstance(col_max, bool):\n",
    "                    if convert:\n",
    "                        self[col] = self[col].astype(\"bool\")\n",
    "                    else:\n",
    "                        print(f\"The best dtype for {col} is bool\") \n",
    "                elif isinstance(col_min, int) and isinstance(col_max, int):\n",
    "                    if col_min >= -128 and col_max <= 127:\n",
    "                        if convert:\n",
    "                            self[col] = self[col].astype(\"int8\")\n",
    "                        else:\n",
    "                            print(f\"The best dtype for {col} is int8\")\n",
    "                            if df[col].nunique(dropna=False) == 2:\n",
    "                                print(\"But consider changing it to bool, has you have 2 unique values so you can map the numbers to be True or False\")\n",
    "                    elif col_min >= -32768 and col_max <= 32767:\n",
    "                        if convert:\n",
    "                            self[col] = self[col].astype(\"int16\")\n",
    "                        else:\n",
    "                            print(f\"The best dtype for {col} is int16\")\n",
    "                    elif col_min >= -2147483648 and col_max <= 2147483647:\n",
    "                        if convert:\n",
    "                            self[col] = self[col].astype(\"int32\")\n",
    "                        else:\n",
    "                            print(f\"The best dtype for {col} is int32\")\n",
    "                    else:\n",
    "                        if convert:\n",
    "                            self[col] = self[col].astype(\"int64\")\n",
    "                        else:\n",
    "                            print(f\"The best dtype for {col} is int64\")\n",
    "                elif isinstance(col_min, float) and isinstance(col_max, float):\n",
    "                    if col_min >= np.finfo(np.float16).min and col_min <= np.finfo(np.float16).max:\n",
    "                        if convert:\n",
    "                            self[col] = self[col].astype(\"float16\")\n",
    "                        else:\n",
    "                            print(f\"The best dtype for {col} is float16\")\n",
    "                    elif col_max >= np.finfo(np.float32).min and col_max <= np.finfo(np.float32).max:\n",
    "                        if convert:\n",
    "                            self[col] = self[col].astype(\"float32\")\n",
    "                        else:\n",
    "                            print(f\"The best dtype for {col} is float32\")\n",
    "                    else:\n",
    "                        if convert:\n",
    "                            self[col] = self[col].astype(\"float64\")\n",
    "                        else:\n",
    "                            print(f\"The best dtype for {col} is float64\")\n",
    "            else:\n",
    "                if convert:\n",
    "                    self[col] = self[col].astype(\"category\")\n",
    "                else:\n",
    "                    print(f\"The best dtype for {col} is category\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar a coluna {col}: {e}\")\n",
    "    if convert:\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "def loop_to_col_info(self, func, new_col_name, show_df, get_total=False, output=True):\n",
    "    try:\n",
    "        if callable(func) is True:\n",
    "            if show_df:\n",
    "                dataframe = []\n",
    "            if get_total:\n",
    "                total = 0\n",
    "            for col in self.columns:\n",
    "                value = func(self, col, False)\n",
    "                if get_total:\n",
    "                    total += value\n",
    "                if output:\n",
    "                    func(self, col)     \n",
    "                if show_df:\n",
    "                    col_info = [col, value]\n",
    "                    dataframe.append(col_info)\n",
    "            if show_df:\n",
    "                collums = [\"Col_Name\", new_col_name]\n",
    "                if get_total:\n",
    "                    dataframe.append([\"Total\", total])\n",
    "                dataframe = pd.DataFrame(dataframe, columns=collums)\n",
    "                if get_total:\n",
    "                    n_rows = len(self.columns) + 1\n",
    "                    display(dataframe.head(n_rows))\n",
    "                    return total\n",
    "                else:\n",
    "                    return dataframe\n",
    "            if get_total:\n",
    "                if output:   \n",
    "                    print(f\"Total: {total}\")\n",
    "                return total\n",
    "    except ValueError:\n",
    "        print(f\"{func} has to be a function.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_memory_usage(self, col, output=True, unit=\"kb\"):\n",
    "    memory_usage = self[col].memory_usage(deep=True)\n",
    "    if unit == \"kb\":\n",
    "        value = round(memory_usage / 1024, 2)\n",
    "        if output:\n",
    "            print(f\"{value} kb\")\n",
    "        return value    \n",
    "    elif unit == \"mb\":\n",
    "        value = round(memory_usage / (1024**2), 2)\n",
    "        if output:\n",
    "            print(f\"{value} mb\")\n",
    "        return value\n",
    "    elif unit == \"b\":\n",
    "        if output:\n",
    "            print(f\"{memory_usage} b\")\n",
    "        return memory_usage\n",
    "    else:\n",
    "        raise ValueError(f\"{unit} not supported. Units supported is bytes, kilobytes and megabytes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage(self, show_df=False, get_total=True, output=False):\n",
    "    return loop_to_col_info(self, func=get_col_memory_usage, new_col_name=\"Memory_Used\", show_df= show_df, get_total=get_total, output=output)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_memory_usage_percentage(self, col, output=True, unit=\"kb\"):\n",
    "    total_usage = get_memory_usage(self)\n",
    "    col_usage = get_col_memory_usage(self, col, False, unit)\n",
    "    value = round((col_usage/total_usage) * 100, 2)\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_memory_usage_percentage(self, show_df=False, get_total=True, output=False):\n",
    "    return loop_to_col_info(self, func=get_col_memory_usage_percentage, new_col_name=\"Memory_Used\", show_df= show_df, get_total=get_total, output=output)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.28"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_memory_usage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col_Name</th>\n",
       "      <th>Memory_Used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>4.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>24.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siblings_on_Board</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parents_on_Board</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ticket_Price</td>\n",
       "      <td>24.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Port_of_Embarkation</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Class</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adult/Child</td>\n",
       "      <td>4.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alone</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Survived</td>\n",
       "      <td>24.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Total</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Col_Name  Memory_Used\n",
       "0                Gender         4.13\n",
       "1                   Age        24.21\n",
       "2     Siblings_on_Board         3.42\n",
       "3      Parents_on_Board         3.42\n",
       "4          Ticket_Price        24.21\n",
       "5   Port_of_Embarkation         4.44\n",
       "6                 Class         4.37\n",
       "7           Adult/Child         4.17\n",
       "8                 Alone         3.42\n",
       "9              Survived        24.21\n",
       "10                Total       100.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_memory_usage_percentage(df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callable(get_col_memory_usage_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_null_count(self, col, print_output=True):\n",
    "    value = self[col].isnull().sum()\n",
    "    if print_output:\n",
    "        print(f\"The number of null values in {col} is {value}\")\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nulls_count(self, show_df=False, get_total=True):\n",
    "    return loop_to_col_info(self, func=get_col_null_count, new_col_name=\"Null_Values\", show_df= show_df, get_total=get_total)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_null_percentage(self, col, print_output=True):\n",
    "    value = self[col].isnull().sum()\n",
    "    value = round((value/len(self[col])) * 100, 2)\n",
    "    if print_output:\n",
    "        print(f\"The percentage of null values in {col} is {value} %\")\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nulls_percentage(self, show_df=False):\n",
    "    return loop_to_col_info(self, func=get_col_null_percentage, new_col_name=\"Percentage_of_Null_Values\", show_df= show_df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_number_of_unique_values(self, col, print_output=True):\n",
    "    value = self[col].nunique()\n",
    "    if print_output:\n",
    "        print(f\"The number of unique values in {col} is {value}\")\n",
    "    return value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_unique_values(self, show_df=False, get_total=True):\n",
    "    return loop_to_col_info(self, func=get_col_number_of_unique_values, new_col_name=\"Unique_Values\", show_df= show_df, get_total=get_total)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique values in Gender is 2\n",
      "The number of unique values in Age is 88\n",
      "The number of unique values in Siblings_on_Board is 7\n",
      "The number of unique values in Parents_on_Board is 7\n",
      "The number of unique values in Ticket_Price is 236\n",
      "The number of unique values in Port_of_Embarkation is 3\n",
      "The number of unique values in Class is 3\n",
      "The number of unique values in Adult/Child is 2\n",
      "The number of unique values in Alone is 2\n",
      "The number of unique values in Survived is 2\n",
      "Total: 352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_number_of_unique_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_max_value(self, col, output=True):\n",
    "    if self[col].dtype != \"category\" and self[col].dtype != \"bool\":\n",
    "        value = self[col].max()\n",
    "        if output:\n",
    "            print(f\"The maximum value in {col} is {value}\")\n",
    "        return value\n",
    "    else:\n",
    "        value = self[col].value_counts().idxmax()\n",
    "        if output:\n",
    "            print(f\"The most common value in {col} is {value}\")\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_values(self, show_df=False):\n",
    "    return loop_to_col_info(self, func=get_col_max_value, new_col_name=\"Max_Values\", show_df= show_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_max_value_count(self, col, output=True):\n",
    "    if self[col].dtype != \"category\":\n",
    "        value = self[col].max()\n",
    "        value = self[self[col] == value][col].count()\n",
    "        if output:\n",
    "            print(f\"The number of ocurrences of the max value in {col} is {value}\")\n",
    "        return value\n",
    "    else:\n",
    "        value = self[col].value_counts().max()\n",
    "        if output:\n",
    "            print(f\"The number of ocurrences of the most common value in {col} is {value}\")\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_value_count(self, show_df=False):\n",
    "    return loop_to_col_info(self, func=get_col_max_value_count, new_col_name=\"Max_Values_Count\", show_df= show_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_max_value_percentage(self, col, output=True):\n",
    "    if self[col].dtype != \"category\":\n",
    "        value = self[col].max()\n",
    "        value = self[self[col] == value][col].count()\n",
    "        value = round((value/len(self[col])) * 100, 2)\n",
    "        if output:\n",
    "            print(f\"The percentage of max value in {col} is {value} %\")\n",
    "            print(\"Tip: It's possible for the percentage of max values being lower than the percentage of min values. So don't take this function seriously if you are using it for numerical columns.\")\n",
    "        return value\n",
    "    else:\n",
    "        value = self[col].value_counts().max()\n",
    "        value = round((value/len(self[col])) * 100, 2)\n",
    "        if output:\n",
    "            print(f\"The percentage of most common value in {col} is {value} %\")\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_value_percentage(self, show_df=False):\n",
    "    return loop_to_col_info(self, func=get_col_max_value_count, new_col_name=\"Max_Values_Percentage\", show_df= show_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_min_value(self, col, output=True):\n",
    "    if self[col].dtype != \"category\":\n",
    "        value = self[col].min()\n",
    "        if output:\n",
    "            print(f\"The minimum value in {col} is {value}\")\n",
    "        return value\n",
    "    else:\n",
    "        value = self[col].value_counts().idxmin()\n",
    "        if output:\n",
    "            print(f\"The less common value in {col} is {value}\")\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_value(self, show_df=False):\n",
    "    return loop_to_col_info(self, func=get_col_min_value, new_col_name=\"Min_Values\", show_df= show_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_min_value_count(self, col, output=True):\n",
    "    if self[col].dtype != \"category\":\n",
    "        value = self[col].min()\n",
    "        value = self[self[col] == value][col].count()\n",
    "        if output:\n",
    "            print(f\"The number of ocurrences of the minimum value in {col} is {value}\")\n",
    "        return value\n",
    "    else:\n",
    "        value = self[col].value_counts().min()\n",
    "        if output:\n",
    "            print(f\"The number of ocurrences of the less common value in {col} is {value}\")\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_value_count(self, show_df=False):\n",
    "    return loop_to_col_info(self, func=get_col_min_value_count, new_col_name=\"Min_Values_Count\", show_df= show_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_min_value_percentage(self, col, output=True):\n",
    "    if self[col].dtype != \"category\":\n",
    "        value = self[col].min()\n",
    "        value = self[self[col] == value][col].count()\n",
    "        value = round((value/len(self[col])) * 100, 2)\n",
    "        if output:\n",
    "            print(f\"The percentage of min value in {col} is {value} %\")\n",
    "            print(\"Tip: It's possible for the percentage of max values being lower than the percentage of min values. So don't take this function seriously if you are using it for numerical columns.\")\n",
    "        return value\n",
    "    else:\n",
    "        value = self[col].value_counts().min()\n",
    "        value = round((value/len(self[col])) * 100, 2)\n",
    "        if output:\n",
    "            print(f\"The percentage of less common value in {col} is {value} %\")\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_min_value_percentage(self, show_df=False):\n",
    "    return loop_to_col_info(self, func=get_col_min_value_count, new_col_name=\"Min_Values_Percentage\", show_df= show_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_mem_insight(self, transpose = False):\n",
    "    dataframe = []\n",
    "    for col in self.columns:\n",
    "        col_info = [\n",
    "            col,\n",
    "            get_dtype(df, col),\n",
    "            get_best_dtypes(df, col),\n",
    "            get_col_memory_usage(df, col),\n",
    "            get_col_null_count(df, col, False),\n",
    "            f\"{get_col_null_percentage(df, col, False)}%\",\n",
    "            get_col_number_of_unique_values(df, col, False)\n",
    "        ]\n",
    "        dataframe.append(col_info)\n",
    "\n",
    "    column_names = [\n",
    "        'Column',\n",
    "        'Dtype',\n",
    "        'Recommend_Dtype',\n",
    "        'Memory',\n",
    "        'Missing_Values',\n",
    "        'Percentage_of_Missing_Values',\n",
    "        'Distinct_Values'\n",
    "    ]\n",
    "    dataframe = pd.DataFrame(dataframe, columns=column_names)\n",
    "    if transpose:\n",
    "        dataframe = dataframe.transpose()\n",
    "        dataframe.columns = dataframe.iloc[0]\n",
    "        dataframe = dataframe[1:]\n",
    "    return dataframe.head(len(self.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_values_insight(self, transpose = False):\n",
    "    dataframe = []\n",
    "    for col in self.columns:\n",
    "        col_info = [\n",
    "            col,\n",
    "            get_dtype(df, col),\n",
    "            get_col_number_of_unique_values(df, col, False),\n",
    "            get_col_max_value(df, col, False),\n",
    "            get_col_max_value_count(df, col, False),\n",
    "            f\"{get_col_max_value_percentage(df, col, False)}%\",\n",
    "            get_col_min_value(df, col, False),\n",
    "            get_col_min_value_count(df, col, False),\n",
    "            f\"{get_col_min_value_percentage(df, col, False)}%\",\n",
    "            get_col_null_count(df, col, False),\n",
    "            f\"{get_col_null_percentage(df, col, False)}%\"\n",
    "        ]\n",
    "        dataframe.append(col_info)\n",
    "\n",
    "    column_names = [\n",
    "        'Column',\n",
    "        'Dtype',\n",
    "        'Distinct_Values',\n",
    "        'Most_Common/Max_Value',\n",
    "        'Occurrences_of_Max_Value',\n",
    "        'Percentages_of_Occurrences_of_Max_Value',\n",
    "        'Less_Common/Min_Value',\n",
    "        'Occurrences_of_Min_Value',\n",
    "        'Percentage_of_Occurrences_of_Min_Value',\n",
    "        'Missing_Values',\n",
    "        'Percentage_of_Missing_Values'\n",
    "    ]\n",
    "    dataframe = pd.DataFrame(dataframe, columns=column_names)\n",
    "    if transpose:\n",
    "        dataframe = dataframe.transpose()\n",
    "        dataframe.columns = dataframe.iloc[0]\n",
    "        dataframe = dataframe[1:]\n",
    "    return dataframe.head(len(self.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Dtype</th>\n",
       "      <th>Distinct_Values</th>\n",
       "      <th>Most_Common/Max_Value</th>\n",
       "      <th>Occurrences_of_Max_Value</th>\n",
       "      <th>Percentages_of_Occurrences_of_Max_Value</th>\n",
       "      <th>Less_Common/Min_Value</th>\n",
       "      <th>Occurrences_of_Min_Value</th>\n",
       "      <th>Percentage_of_Occurrences_of_Min_Value</th>\n",
       "      <th>Missing_Values</th>\n",
       "      <th>Percentage_of_Missing_Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>category</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>577</td>\n",
       "      <td>64.76%</td>\n",
       "      <td>F</td>\n",
       "      <td>314</td>\n",
       "      <td>35.24%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>float64</td>\n",
       "      <td>88</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11%</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11%</td>\n",
       "      <td>177</td>\n",
       "      <td>19.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siblings_on_Board</td>\n",
       "      <td>int8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.79%</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>68.24%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parents_on_Board</td>\n",
       "      <td>int8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.11%</td>\n",
       "      <td>0</td>\n",
       "      <td>678</td>\n",
       "      <td>76.09%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ticket_Price</td>\n",
       "      <td>float64</td>\n",
       "      <td>236</td>\n",
       "      <td>512.33</td>\n",
       "      <td>3</td>\n",
       "      <td>0.34%</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.68%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Port_of_Embarkation</td>\n",
       "      <td>category</td>\n",
       "      <td>3</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>644</td>\n",
       "      <td>72.28%</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>77</td>\n",
       "      <td>8.64%</td>\n",
       "      <td>2</td>\n",
       "      <td>0.22%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Class</td>\n",
       "      <td>category</td>\n",
       "      <td>3</td>\n",
       "      <td>Third</td>\n",
       "      <td>491</td>\n",
       "      <td>55.11%</td>\n",
       "      <td>Second</td>\n",
       "      <td>184</td>\n",
       "      <td>20.65%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adult/Child</td>\n",
       "      <td>category</td>\n",
       "      <td>2</td>\n",
       "      <td>Adult</td>\n",
       "      <td>808</td>\n",
       "      <td>90.68%</td>\n",
       "      <td>Child</td>\n",
       "      <td>83</td>\n",
       "      <td>9.32%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alone</td>\n",
       "      <td>bool</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>537</td>\n",
       "      <td>60.27%</td>\n",
       "      <td>False</td>\n",
       "      <td>354</td>\n",
       "      <td>39.73%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Survived</td>\n",
       "      <td>int64</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>342</td>\n",
       "      <td>38.38%</td>\n",
       "      <td>0</td>\n",
       "      <td>549</td>\n",
       "      <td>61.62%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Column     Dtype  Distinct_Values Most_Common/Max_Value  \\\n",
       "0               Gender  category                2                     M   \n",
       "1                  Age   float64               88                  80.0   \n",
       "2    Siblings_on_Board      int8                7                     8   \n",
       "3     Parents_on_Board      int8                7                     6   \n",
       "4         Ticket_Price   float64              236                512.33   \n",
       "5  Port_of_Embarkation  category                3           Southampton   \n",
       "6                Class  category                3                 Third   \n",
       "7          Adult/Child  category                2                 Adult   \n",
       "8                Alone      bool                2                  True   \n",
       "9             Survived     int64                2                     1   \n",
       "\n",
       "   Occurrences_of_Max_Value Percentages_of_Occurrences_of_Max_Value  \\\n",
       "0                       577                                  64.76%   \n",
       "1                         1                                   0.11%   \n",
       "2                         7                                   0.79%   \n",
       "3                         1                                   0.11%   \n",
       "4                         3                                   0.34%   \n",
       "5                       644                                  72.28%   \n",
       "6                       491                                  55.11%   \n",
       "7                       808                                  90.68%   \n",
       "8                       537                                  60.27%   \n",
       "9                       342                                  38.38%   \n",
       "\n",
       "  Less_Common/Min_Value  Occurrences_of_Min_Value  \\\n",
       "0                     F                       314   \n",
       "1                  0.42                         1   \n",
       "2                     0                       608   \n",
       "3                     0                       678   \n",
       "4                   0.0                        15   \n",
       "5            Queenstown                        77   \n",
       "6                Second                       184   \n",
       "7                 Child                        83   \n",
       "8                 False                       354   \n",
       "9                     0                       549   \n",
       "\n",
       "  Percentage_of_Occurrences_of_Min_Value  Missing_Values  \\\n",
       "0                                 35.24%               0   \n",
       "1                                  0.11%             177   \n",
       "2                                 68.24%               0   \n",
       "3                                 76.09%               0   \n",
       "4                                  1.68%               0   \n",
       "5                                  8.64%               2   \n",
       "6                                 20.65%               0   \n",
       "7                                  9.32%               0   \n",
       "8                                 39.73%               0   \n",
       "9                                 61.62%               0   \n",
       "\n",
       "  Percentage_of_Missing_Values  \n",
       "0                         0.0%  \n",
       "1                       19.87%  \n",
       "2                         0.0%  \n",
       "3                         0.0%  \n",
       "4                         0.0%  \n",
       "5                        0.22%  \n",
       "6                         0.0%  \n",
       "7                         0.0%  \n",
       "8                         0.0%  \n",
       "9                         0.0%  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dataframe_values_insight(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Next Steps** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Add more values insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Get the percentage of memory of the dataframe that the col is using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Fix get_best_dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Cleaning Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 - Analysis Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# dataframe = []\n",
    "# for col in df.columns:\n",
    "#     col_info = [\n",
    "#         col,\n",
    "#         get_dtype(df, col),\n",
    "#         get_best_dtype(df, col),\n",
    "#         get_col_memory_usage(df, col),\n",
    "#         get_col_null_count(df, col, False),\n",
    "#         f\"{get_col_null_percentage(df, col, False)}%\",\n",
    "#         get_col_number_of_unique_values(df, col, False),\n",
    "#         get_col_max_value(df, col, False),\n",
    "#         get_col_max_value_count(df, col, False),\n",
    "#         f\"{get_col_max_value_percentage(df, col, False)}%\",\n",
    "#         get_col_min_value(df, col, False),\n",
    "#         get_col_min_value_count(df, col, False),\n",
    "#         f\"{get_col_min_value_percentage(df, col, False)}%\"\n",
    "#     ]\n",
    "#     dataframe.append(col_info)\n",
    "\n",
    "# column_names = [\n",
    "#     'Attributes',\n",
    "#     'Dtype',\n",
    "#     'Recommend_Dtype',\n",
    "#     'Memory',\n",
    "#     'Missing_Values',\n",
    "#     'Percentage_of_Missing_Values',\n",
    "#     'Distinct_Values',\n",
    "#     'Most_Common/Max_Value',\n",
    "#     'Occurrences_of_Max_Value',\n",
    "#     'Percentages_of_Occurrences_of_Max_Value',\n",
    "#     'Less_Common/Min_Value',\n",
    "#     'Occurrences_of_Min_Value',\n",
    "#     'Percentage_of_Occurrences_of_Min_Value'\n",
    "# ]\n",
    "# # total = [\"Total\", get_memory_usage(self)]\n",
    "# # dataframe.append(total)\n",
    "# dataframe = pd.DataFrame(dataframe, columns=column_names).transpose()\n",
    "\n",
    "# # Set the first row as column names\n",
    "# dataframe.columns = dataframe.iloc[0]\n",
    "\n",
    "# # Drop the first row (now it's redundant)\n",
    "# dataframe = dataframe[1:]\n",
    "\n",
    "# # Display the updated DataFrame\n",
    "# dataframe.head(len(dataframe.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Titanic.csv\")\n",
    "df1 = pd.read_csv(\"./Sales_Data.csv\")\n",
    "df2 = pd.read_parquet(\"./Titanic_Cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   sex       891 non-null    object \n",
      " 1   age       714 non-null    float64\n",
      " 2   sibsp     891 non-null    int64  \n",
      " 3   parch     891 non-null    int64  \n",
      " 4   fare      891 non-null    float64\n",
      " 5   embarked  889 non-null    object \n",
      " 6   class     891 non-null    object \n",
      " 7   who       891 non-null    object \n",
      " 8   alone     891 non-null    bool   \n",
      " 9   survived  891 non-null    int64  \n",
      "dtypes: bool(1), float64(2), int64(3), object(4)\n",
      "memory usage: 63.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex\"] = df[\"sex\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best dtype for sex is category\n",
      "The best dtype for age is float16\n",
      "The best dtype for sibsp is int8\n",
      "The best dtype for parch is int8\n",
      "The best dtype for fare is float16\n",
      "The best dtype for embarked is category\n",
      "The best dtype for class is category\n",
      "The best dtype for who is category\n",
      "The best dtype for alone is bool\n",
      "The best dtype for survived is int8\n",
      "But consider changing it to bool, has you have 2 unique values so you can map the numbers to be True or False\n"
     ]
    }
   ],
   "source": [
    "teste = get_best_dtypes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   sex       891 non-null    category\n",
      " 1   age       714 non-null    float16 \n",
      " 2   sibsp     891 non-null    int8    \n",
      " 3   parch     891 non-null    int8    \n",
      " 4   fare      891 non-null    float16 \n",
      " 5   embarked  889 non-null    category\n",
      " 6   class     891 non-null    category\n",
      " 7   who       891 non-null    category\n",
      " 8   alone     891 non-null    bool    \n",
      " 9   survived  891 non-null    int8    \n",
      "dtypes: bool(1), category(4), float16(2), int8(3)\n",
      "memory usage: 11.1 KB\n"
     ]
    }
   ],
   "source": [
    "teste.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalize_cols_name(self, cols = None):\n",
    "    if cols is None:\n",
    "        cols = self.columns\n",
    "    for col in tqdm(cols, desc='Renaming Collumns', unit='Columns'):\n",
    "        new_col = col.capitalize()\n",
    "        self = self.rename(columns={col: new_col})\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_cols_name(self, cols = None):\n",
    "    if cols is None:\n",
    "        cols = self.columns\n",
    "    for col in tqdm(cols, desc='Renaming Collumns', unit='Columns'):\n",
    "        new_col = col.lower()\n",
    "        self = self.rename(columns={col: new_col})\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_cols_name(self, cols = None):\n",
    "    if cols is None:\n",
    "        cols = self.columns\n",
    "    for col in tqdm(cols, desc='Renaming Collumns', unit='Columns'):\n",
    "        new_col = col.upper()\n",
    "        self = self.rename(columns={col: new_col})\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols_blankspaces(self, cols = None):\n",
    "    if cols is None:\n",
    "        cols = self.columns\n",
    "    for column in tqdm(cols, desc='Removing BlankSpaces', unit='BlankSpaces'):\n",
    "        if ' ' in column:\n",
    "            new_column = column.replace(' ', '')\n",
    "            self = self.rename(columns={column: new_column})\n",
    "        else:\n",
    "            continue\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols_underscores(self, cols = None):\n",
    "    if cols is None:\n",
    "        cols = self.columns\n",
    "    for column in tqdm(cols, desc='Removing Underscores', unit='Underscores'):\n",
    "        if '_' in column:\n",
    "            new_column = column.replace('_', '')\n",
    "            self = self.rename(columns={column: new_column})\n",
    "        else:\n",
    "            continue\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_cols_character(self, cols = None, characters=['_'], add_blankspace=False):\n",
    "    if cols is None:\n",
    "        cols = self.columns\n",
    "    for col in tqdm(cols, desc=\"\", unit=\"\"):\n",
    "        for character in characters:\n",
    "            if character in col:\n",
    "                if not add_blankspace:\n",
    "                    new_column = col.replace(character, '')\n",
    "                else:\n",
    "                    new_column = col.replace(character, ' ')\n",
    "                self = self.rename(columns={col: new_column})\n",
    "            else:\n",
    "                continue\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_rows_value(self, col, decimals=2):\n",
    "    dtype = get_dtype(self, col)\n",
    "    if dtype not in [\"categorical\", \"bool\", \"object\"]:\n",
    "        for index, row in tqdm(self.iterrows(), desc= \"Rounding Rows Value\", unit=\"Rows\"):\n",
    "            self.loc[index, col] = round(row[col], decimals) \n",
    "    else:\n",
    "        raise ValueError(f\"{col}'s dtype is not a numerical.\")\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_character(self, cols = None, characters=[','], add_blankspace=False):\n",
    "    if cols is None:\n",
    "        cols = self.columns\n",
    "    for col in tqdm(cols, desc=\"\", unit=\"\"):\n",
    "        dtype = get_dtype(self, col) \n",
    "        if dtype in [\"categorical\", \"bool\", \"object\"]:\n",
    "            for character in characters:\n",
    "                if not add_blankspace:\n",
    "                    self[col] = self[col].apply(lambda x: x.replace(character, '') if isinstance(x, str) and character in x else x)\n",
    "                else:\n",
    "                    self[col] = self[col].apply(lambda x: x.replace(character, ' ') if isinstance(x, str) and character in x else x)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalize_rows_string(self, cols = None):\n",
    "    if cols is None:\n",
    "        cols = self.columns\n",
    "    for col in tqdm(cols, desc=\"\", unit=\"\"):\n",
    "        dtype = get_dtype(self, col) \n",
    "        if dtype in [\"categorical\", \"bool\", \"object\"]:\n",
    "            self[col] = self[col].apply(lambda x: x.capitalize() if isinstance(x, str) else x)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_rows_string(self, cols = None):\n",
    "    if cols is None:\n",
    "        cols = self.columns\n",
    "    for col in tqdm(cols, desc=\"\", unit=\"\"):\n",
    "        dtype = get_dtype(self, col) \n",
    "        if dtype in [\"categorical\", \"bool\", \"object\"]:\n",
    "            self[col] = self[col].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_rows_string(self, cols = None):\n",
    "    if cols is None:\n",
    "        cols = self.columns\n",
    "    for col in tqdm(cols, desc=\"\", unit=\"\"):\n",
    "        dtype = get_dtype(self, col) \n",
    "        if dtype in [\"categorical\", \"bool\", \"object\"]:\n",
    "            self[col] = self[col].apply(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rows_with_missing_values(self, cols = None):\n",
    "    if cols is None:\n",
    "        self = self.dropna(axis=0)\n",
    "    else:\n",
    "        self = self.dropna(subset=cols)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def interpolate_rows_with_missing_values(self, cols = None):\n",
    "    if cols is None:\n",
    "        self = self.interpolate()\n",
    "    else:\n",
    "        for col in tqdm(cols, desc=\"\", unit=\"\"):\n",
    "            dtype = get_dtype(self, col) \n",
    "            if dtype in [\"categorical\", \"bool\", \"object\"]:\n",
    "                raise ValueError(f\"{col} does not have numerical values. Please use mode to replace the missing values.\")\n",
    "            else:\n",
    "                self = self[col].interpolate()\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foward_fill_rows_with_missing_values(self, cols = None):\n",
    "    if cols is None:\n",
    "        self = self.ffill()\n",
    "    else:\n",
    "        self = self.ffill(subset=cols)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows_string(self, col, new_cols, separator=\",\", delete_col=True, save_remain=True):\n",
    "    split_result = self[col].str.split(separator, expand=True)\n",
    "    split_result = split_result.fillna('')\n",
    "    for i, new_col in enumerate(new_cols):\n",
    "        if i == 0:\n",
    "            self[new_col] = split_result[i]\n",
    "        else:\n",
    "            if save_remain:\n",
    "                self[new_col] = split_result.loc[:, i:].apply(lambda x: separator.join(x), axis=1)\n",
    "    if delete_col:\n",
    "        self = self.drop([col], axis=1)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_fill_rows_with_missing_values(self, cols = None):\n",
    "    if cols is None:\n",
    "        self = self.bfill()\n",
    "    else:\n",
    "        self = self.bfill(subset=cols)\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_rows_with_missing_values_mean(self, cols = None, decimals=2):\n",
    "    if cols is None:\n",
    "       self = self.fill(self.mean())\n",
    "    else:\n",
    "        for col in tqdm(cols, desc=\"\", unit=\"\"):\n",
    "            dtype = get_dtype(self, col) \n",
    "            if dtype in [\"categorical\", \"bool\", \"object\"]:\n",
    "                self = self[col].fillna(self[col].mode())\n",
    "            else:\n",
    "                self = self[col].fillna(round(self[col].mean(), decimals))\n",
    "    return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste1 = remove_rows_with_missing_values(df, [\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of null values in sex is 0\n",
      "The number of null values in age is 0\n",
      "The number of null values in sibsp is 0\n",
      "The number of null values in parch is 0\n",
      "The number of null values in fare is 0\n",
      "The number of null values in embarked is 2\n",
      "The number of null values in class is 0\n",
      "The number of null values in who is 0\n",
      "The number of null values in alone is 0\n",
      "The number of null values in survived is 0\n",
      "Total: 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nulls_count(teste1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple, pie</td>\n",
       "      <td>ice-cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banana! split</td>\n",
       "      <td>chocolate? cake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cherry? cake</td>\n",
       "      <td>strawberry! shortcake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            col1                   col2\n",
       "0     apple, pie              ice-cream\n",
       "1  banana! split        chocolate? cake\n",
       "2   cherry? cake  strawberry! shortcake"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {\n",
    "    'col1': ['apple, pie', 'banana! split', 'cherry? cake'],\n",
    "    'col2': ['ice-cream', 'chocolate? cake', 'strawberry! shortcake']\n",
    "}\n",
    "\n",
    "teste = pd.DataFrame(data)\n",
    "teste.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>alone</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age  sibsp  parch     fare embarked  class    who  alone  survived\n",
       "0    male  22.0      1      0   7.2500        S  Third    man  False         0\n",
       "1  female  38.0      1      0  71.2833        C  First  woman  False         1\n",
       "2  female  26.0      0      0   7.9250        S  Third  woman   True         1\n",
       "3  female  35.0      1      0  53.1000        S  First  woman  False         1\n",
       "4    male  35.0      0      0   8.0500        S  Third    man   True         0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(self, conditions, AND=True, OR=False):\n",
    "    combined_condition = conditions[0]\n",
    "    if AND:\n",
    "        for condition in conditions[1:]:\n",
    "            combined_condition = combined_condition & condition\n",
    "    elif OR:\n",
    "        for condition in conditions[1:]:\n",
    "            combined_condition = combined_condition | condition\n",
    "    elif OR and AND:\n",
    "        raise ValueError(\"Both AND and OR cannot be True simultaneously.\")\n",
    "    else:\n",
    "        raise ValueError(\"Either AND or OR must be True.\")\n",
    "    return self[combined_condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>alone</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "      <td>Second</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>child</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2417</td>\n",
       "      <td>C</td>\n",
       "      <td>Third</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>female</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>41.5792</td>\n",
       "      <td>C</td>\n",
       "      <td>Second</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sex   age  sibsp  parch     fare embarked   class    who  alone  \\\n",
       "9   female  14.0      1      0  30.0708        C  Second  child  False   \n",
       "10  female   4.0      1      1  16.7000        S   Third  child  False   \n",
       "22  female  15.0      0      0   8.0292        Q   Third  child   True   \n",
       "39  female  14.0      1      0  11.2417        C   Third  child  False   \n",
       "43  female   3.0      1      2  41.5792        C  Second  child  False   \n",
       "\n",
       "    survived  \n",
       "9          1  \n",
       "10         1  \n",
       "22         1  \n",
       "39         1  \n",
       "43         1  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition = df[\"sex\"] == \"female\"\n",
    "condition4 = df[\"who\"] == \"child\"\n",
    "condition2 = df[\"survived\"] > 0\n",
    "conditions = [condition, condition2, condition4]\n",
    "adw = find(df, conditions)\n",
    "adw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50420dab63ae492e9b56697aa2d196de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple  pie</td>\n",
       "      <td>ice cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>banana  split</td>\n",
       "      <td>chocolate  cake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cherry  cake</td>\n",
       "      <td>strawberry  shortcake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            col1                   col2\n",
       "0     apple  pie              ice cream\n",
       "1  banana  split        chocolate  cake\n",
       "2   cherry  cake  strawberry  shortcake"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = remove_rows_character(teste, characters=[\"-\", \"?\", \"!\", \" \", \",\"], add_blankspace=True)\n",
    "teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1[\"Product\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of null values in Order ID is 1\n",
      "The number of null values in Product is 1\n",
      "The number of null values in Quantity Ordered is 1\n",
      "The number of null values in Price Each is 1\n",
      "The number of null values in Order Date is 1\n",
      "The number of null values in Purchase Address is 1\n",
      "Total: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nulls_count(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 372990 entries, 0 to 372989\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Order ID          371900 non-null  float64\n",
      " 1   Product           371900 non-null  object \n",
      " 2   Quantity Ordered  371900 non-null  float64\n",
      " 3   Price Each        371900 non-null  float64\n",
      " 4   Order Date        371900 non-null  object \n",
      " 5   Purchase Address  371900 non-null  object \n",
      "dtypes: float64(3), object(3)\n",
      "memory usage: 17.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_dtype(df1, \"Product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = get_best_dtypes(df1, convert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 372990 entries, 0 to 372989\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count   Dtype   \n",
      "---  ------            --------------   -----   \n",
      " 0   Order ID          371900 non-null  float32 \n",
      " 1   Product           371900 non-null  category\n",
      " 2   Quantity Ordered  371900 non-null  float16 \n",
      " 3   Price Each        371900 non-null  float16 \n",
      " 4   Order Date        371900 non-null  category\n",
      " 5   Purchase Address  371900 non-null  category\n",
      "dtypes: category(3), float16(2), float32(1)\n",
      "memory usage: 16.3 MB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = remove_rows_with_missing_values(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of null values in ['Purchase Address'] is Purchase Address    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Purchase Address    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_col_null_count(df1, [\"Purchase Address\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity Ordered</th>\n",
       "      <th>Price Each</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Purchase Address</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150502.0</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>700.00</td>\n",
       "      <td>02/18/19 01:35</td>\n",
       "      <td>866 Spruce St, Portland, ME 04101</td>\n",
       "      <td>866 Spruce St</td>\n",
       "      <td>Portland, ME 04101</td>\n",
       "      <td>ME 04101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150503.0</td>\n",
       "      <td>AA Batteries (4-pack)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>02/13/19 07:24</td>\n",
       "      <td>18 13th St, San Francisco, CA 94016</td>\n",
       "      <td>18 13th St</td>\n",
       "      <td>San Francisco, CA 94016</td>\n",
       "      <td>CA 94016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150504.0</td>\n",
       "      <td>27in 4K Gaming Monitor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>389.99</td>\n",
       "      <td>02/18/19 09:46</td>\n",
       "      <td>52 6th St, New York City, NY 10001</td>\n",
       "      <td>52 6th St</td>\n",
       "      <td>New York City, NY 10001</td>\n",
       "      <td>NY 10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150505.0</td>\n",
       "      <td>Lightning Charging Cable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>02/02/19 16:47</td>\n",
       "      <td>129 Cherry St, Atlanta, GA 30301</td>\n",
       "      <td>129 Cherry St</td>\n",
       "      <td>Atlanta, GA 30301</td>\n",
       "      <td>GA 30301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150506.0</td>\n",
       "      <td>AA Batteries (4-pack)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>02/28/19 20:32</td>\n",
       "      <td>548 Lincoln St, Seattle, WA 98101</td>\n",
       "      <td>548 Lincoln St</td>\n",
       "      <td>Seattle, WA 98101</td>\n",
       "      <td>WA 98101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372985</th>\n",
       "      <td>295660.0</td>\n",
       "      <td>AAA Batteries (4-pack)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>11/04/19 14:17</td>\n",
       "      <td>574 4th St, Los Angeles, CA 90001</td>\n",
       "      <td>574 4th St</td>\n",
       "      <td>Los Angeles, CA 90001</td>\n",
       "      <td>CA 90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372986</th>\n",
       "      <td>295661.0</td>\n",
       "      <td>USB-C Charging Cable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.95</td>\n",
       "      <td>11/23/19 07:22</td>\n",
       "      <td>359 1st St, Austin, TX 73301</td>\n",
       "      <td>359 1st St</td>\n",
       "      <td>Austin, TX 73301</td>\n",
       "      <td>TX 73301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372987</th>\n",
       "      <td>295662.0</td>\n",
       "      <td>Lightning Charging Cable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>11/13/19 16:12</td>\n",
       "      <td>900 10th St, Boston, MA 02215</td>\n",
       "      <td>900 10th St</td>\n",
       "      <td>Boston, MA 02215</td>\n",
       "      <td>MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372988</th>\n",
       "      <td>295663.0</td>\n",
       "      <td>AAA Batteries (4-pack)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>11/17/19 17:08</td>\n",
       "      <td>592 Sunset St, Boston, MA 02215</td>\n",
       "      <td>592 Sunset St</td>\n",
       "      <td>Boston, MA 02215</td>\n",
       "      <td>MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372989</th>\n",
       "      <td>295664.0</td>\n",
       "      <td>Google Phone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600.00</td>\n",
       "      <td>11/17/19 16:13</td>\n",
       "      <td>428 Jackson St, Boston, MA 02215</td>\n",
       "      <td>428 Jackson St</td>\n",
       "      <td>Boston, MA 02215</td>\n",
       "      <td>MA 02215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>371900 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Order ID                   Product  Quantity Ordered  Price Each  \\\n",
       "0       150502.0                    iPhone               1.0      700.00   \n",
       "1       150503.0     AA Batteries (4-pack)               1.0        3.84   \n",
       "2       150504.0    27in 4K Gaming Monitor               1.0      389.99   \n",
       "3       150505.0  Lightning Charging Cable               1.0       14.95   \n",
       "4       150506.0     AA Batteries (4-pack)               2.0        3.84   \n",
       "...          ...                       ...               ...         ...   \n",
       "372985  295660.0    AAA Batteries (4-pack)               2.0        2.99   \n",
       "372986  295661.0      USB-C Charging Cable               1.0       11.95   \n",
       "372987  295662.0  Lightning Charging Cable               1.0       14.95   \n",
       "372988  295663.0    AAA Batteries (4-pack)               1.0        2.99   \n",
       "372989  295664.0              Google Phone               1.0      600.00   \n",
       "\n",
       "            Order Date                     Purchase Address         Address  \\\n",
       "0       02/18/19 01:35    866 Spruce St, Portland, ME 04101   866 Spruce St   \n",
       "1       02/13/19 07:24  18 13th St, San Francisco, CA 94016      18 13th St   \n",
       "2       02/18/19 09:46   52 6th St, New York City, NY 10001       52 6th St   \n",
       "3       02/02/19 16:47     129 Cherry St, Atlanta, GA 30301   129 Cherry St   \n",
       "4       02/28/19 20:32    548 Lincoln St, Seattle, WA 98101  548 Lincoln St   \n",
       "...                ...                                  ...             ...   \n",
       "372985  11/04/19 14:17    574 4th St, Los Angeles, CA 90001      574 4th St   \n",
       "372986  11/23/19 07:22         359 1st St, Austin, TX 73301      359 1st St   \n",
       "372987  11/13/19 16:12        900 10th St, Boston, MA 02215     900 10th St   \n",
       "372988  11/17/19 17:08      592 Sunset St, Boston, MA 02215   592 Sunset St   \n",
       "372989  11/17/19 16:13     428 Jackson St, Boston, MA 02215  428 Jackson St   \n",
       "\n",
       "                            City      State  \n",
       "0             Portland, ME 04101   ME 04101  \n",
       "1        San Francisco, CA 94016   CA 94016  \n",
       "2        New York City, NY 10001   NY 10001  \n",
       "3              Atlanta, GA 30301   GA 30301  \n",
       "4              Seattle, WA 98101   WA 98101  \n",
       "...                          ...        ...  \n",
       "372985     Los Angeles, CA 90001   CA 90001  \n",
       "372986          Austin, TX 73301   TX 73301  \n",
       "372987          Boston, MA 02215   MA 02215  \n",
       "372988          Boston, MA 02215   MA 02215  \n",
       "372989          Boston, MA 02215   MA 02215  \n",
       "\n",
       "[371900 rows x 9 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_rows_string(df1, \"Purchase Address\", [\"Address\", \"City\", \"State\"], delete_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://api.telegram.org/bot6148622889:AAFHdvQ_CxImlx1VEXE_vYhg4_2NFXk1OyU/sendPhoto\"\n",
    "def send_images_via_telegram(file_path, chat_id, caption=\"This is a caption\"):\n",
    "    my_file = open(file_path, 'rb')\n",
    "    parameters = {\n",
    "    \"chat_id\" : chat_id,\n",
    "    \"caption\" : caption\n",
    "    }\n",
    "    files = {   \n",
    "    \"photo\" : my_file\n",
    "    }\n",
    "    resp = requests.post(base_url, data=parameters, files=files)\n",
    "    print(resp.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_token = \"xoxp-5452682117826-5446024818310-5452588829571-92e60adc3ecd07a736b6faea910b8831\"\n",
    "channel_id = \"C05DAGDAPEX\"\n",
    "client = WebClient(token=slack_token)\n",
    "def send_images_via_slack(file_path):\n",
    "    try:\n",
    "        response = client.files_upload(\n",
    "                channels=channel_id,\n",
    "                file=file_path\n",
    "                )\n",
    "        print(response)\n",
    "    except SlackApiError as e:\n",
    "        print(f\"Error uploading file: {e.response['error']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygmtsar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
