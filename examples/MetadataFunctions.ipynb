{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import json\n",
    "import jsonschema\n",
    "from jsonschema.exceptions import ValidationError\n",
    "import os\n",
    "from tqdm.notebook  import tqdm\n",
    "import pathlib\n",
    "import os.path\n",
    "import polars as pl \n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import seaborn as sns\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metadata:\n",
    "    def read_netCDF_metadata(self, variables=None, attributes=None):\n",
    "        \"\"\"\n",
    "        Read and print metadata information from a NetCDF file.\n",
    "\n",
    "        Args:\n",
    "            variables (list, optional): A list of variable names to retrieve metadata for. If not specified, all variables in the NetCDF file will be retrieved.\n",
    "            attributes (list, optional): A list of attribute names to retrieve for each variable. If not specified, all attributes for each variable will be retrieved.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        Example Usage:\n",
    "            # Read metadata for all variables in the NetCDF file\n",
    "            read_netCDF_metadata()\n",
    "\n",
    "            # Read metadata for specific variables in the NetCDF file\n",
    "            read_netCDF_metadata(variables=['temperature', 'humidity'])\n",
    "\n",
    "            # Read metadata for specific attributes of all variables in the NetCDF file\n",
    "            read_netCDF_metadata(attributes=['units', 'long_name'])\n",
    "        \"\"\"\n",
    "\n",
    "        def read_variable_metadata(var_name, var):\n",
    "            print(f\"Variable: {var_name}\")\n",
    "            if not var.attrs:\n",
    "                if var.values is not None:\n",
    "                    print(f\"    Values: {var.values}\")\n",
    "                else:\n",
    "                    print(\"No values were found\")\n",
    "                print(\"    No attributes were found for this variable.\")\n",
    "            else:\n",
    "                print(f\"    Values: {var.values}\")\n",
    "                print(\"    Attributes:\")\n",
    "                for key, value in var.attrs.items():\n",
    "                    if attributes is None or key in attributes:\n",
    "                        print(f\"     {key}: {value}\")\n",
    "\n",
    "        if variables is None:\n",
    "            variables = Statistics.get_file_variables(self)\n",
    "        for var_name in variables:\n",
    "            try:\n",
    "                coord_var = self.coords[var_name]\n",
    "                read_variable_metadata(var_name, coord_var)\n",
    "            except (KeyError, AttributeError) as e:\n",
    "                print(f\"Error occurred while retrieving metadata for variable {var_name}: {str(e)}\")\n",
    "    def insert_netCDF_metadata_input(self, variables=None, attributes=None, new_file=False, filename=\"new_file.nc\",):\n",
    "        \"\"\"\n",
    "        This function prompts the user to input metadata for the specified variables in a netCDF file.\n",
    "        \n",
    "        Parameters:\n",
    "        - filename (str): Name of the netCDF file.\n",
    "        - variables (list): List of variable names. If None, all coordinate variables are used.\n",
    "        - attributes (list): List of attribute names. If None, default attributes are used.\n",
    "        - new_file (bool): If True, a new netCDF file is created. If False, the existing file is used.\n",
    "        \n",
    "        Raises:\n",
    "        - KeyError: If a variable was not found.\n",
    "        - FileExistsError: If the specified file already exists.\n",
    "        - ValueError: If the filename is invalid.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Define default attributes if not provided\n",
    "        default_attributes = [\n",
    "            \"Units\", \"Long_Name\", \"Standard_Name/Short_Name\", \n",
    "            \"Valid_Min\", \"Valid_Max\", \"Missing_Value\", \n",
    "            \"Fill_Value\", \"Scale_Factor\", \"Add_Offset\", \n",
    "            \"Coordinates\", \"Axis\", \"Description\"\n",
    "        ]\n",
    "        if attributes is None:\n",
    "            attributes = default_attributes\n",
    "\n",
    "        if variables is None:\n",
    "            variables = get_file_variables(self)\n",
    "\n",
    "        for coord_name in variables:\n",
    "            try:\n",
    "                for attribute in attributes:\n",
    "                    self[coord_name].attrs[attribute] = input(f\"{coord_name}: {attribute} - Enter value: \")\n",
    "            except KeyError as e:\n",
    "                raise KeyError(f\"Variable {coord_name} not found.\") from e\n",
    "        if new_file:\n",
    "            File.export_to_file(self,filename)\n",
    "        Metadata.read_netCDF_metadata(self)\n",
    "    def insert_netCDF_metadata_dict(self, dictionary, variables=None, new_file=False, filename=\"new_file.nc\"):\n",
    "        \"\"\"\n",
    "        Insert metadata into a netCDF file using a dictionary.\n",
    "\n",
    "        Parameters:\n",
    "        - self: The netCDF object.\n",
    "        - dictionary: A dictionary containing the metadata to be inserted.\n",
    "        - filename: The name of the netCDF file to be created or modified.\n",
    "        - variables: A list of variables to insert the metadata into. If None, all variables will be used.\n",
    "        - new_file: If True, a new file will be created. If False, the metadata will be inserted into an existing file.\n",
    "\n",
    "        Raises:\n",
    "        - ValueError: If dictionary is None.\n",
    "        - AttributeError: If dictionary is not a dictionary.\n",
    "        - FileExistsError: If the specified file already exists.\n",
    "        - ValueError: If the filename is invalid.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        if dictionary is None:\n",
    "            raise ValueError(\"Please provide a dictionary.\")\n",
    "        if variables is None:\n",
    "            variables = get_file_variables(self)\n",
    "        if isinstance(dictionary, dict):\n",
    "            for var in variables:\n",
    "                for key, value in dictionary.items():\n",
    "                    self[var].attrs[key] = value\n",
    "        else:\n",
    "            raise AttributeError(f\"{dictionary} is not a dictionary.\")\n",
    "        if new_file:\n",
    "            File.export_to_file(self,filename)\n",
    "        Metadata.read_netCDF_metadata(self)\n",
    "    def insert_netCDF_metadata_json(self, json_file, new_file=False, filename=\"new_file.nc\"):\n",
    "        \"\"\"\n",
    "        Inserts metadata from a JSON file into a netCDF file.\n",
    "\n",
    "        Args:\n",
    "            self: The instance of the class that the function belongs to.\n",
    "            json_file (str): The path to the JSON file containing the metadata.\n",
    "            new_file (bool, optional): A boolean flag indicating whether a new netCDF file should be created. Defaults to False.\n",
    "            filename (str, optional): The name of the new netCDF file. Defaults to \"new_file.nc\".\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If the specified filename already exists.\n",
    "\n",
    "        Returns:\n",
    "            None: The function modifies the attributes of the netCDF file directly.\n",
    "        \"\"\"\n",
    "        schema = {\n",
    "            \"type\": \"object\",\n",
    "            \"patternProperties\": {\n",
    "                \".*\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"patternProperties\": {\n",
    "                        \".*\": {\n",
    "                            \"type\": \"string\",\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"additionalProperties\": False\n",
    "                }   \n",
    "            }   \n",
    "        try:\n",
    "            with open(json_file, 'r') as file:\n",
    "                metadata = json.load(file)\n",
    "        except IOError:\n",
    "            raise IOError(\"Error opening JSON file. Please check if the file exists or if there are any permission issues.\")\n",
    "        try:\n",
    "            # Validate JSON against schema\n",
    "            jsonschema.validate(instance=metadata, schema=schema)\n",
    "        except ValidationError as e:\n",
    "            raise ValidationError(str(e))\n",
    "        for var, attributes in metadata.items():\n",
    "            for attr, value in attributes.items():\n",
    "                self[var].attrs[attr] = value    \n",
    "        if new_file:\n",
    "            File.export_to_file(self,filename)\n",
    "        Metadata.read_netCDF_metadata(self)\n",
    "    def insert_netCDF_metadata(self, via=\"input\", **kwargs):\n",
    "        \"\"\"\n",
    "        Insert metadata into the netCDF file.\n",
    "\n",
    "        Parameters:\n",
    "            via (str, optional): The method of providing metadata. Can be \"dict\", \"json\", or \"input\". Defaults to \"input\".\n",
    "            **kwargs: Additional keyword arguments for the specific method.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If `via` is not a valid metadata input.\n",
    "        \"\"\"\n",
    "        via_lower = via.lower()\n",
    "        try:\n",
    "            if via_lower == \"dict\":\n",
    "                self.insert_netCDF_metadata_dict(self, **kwargs)\n",
    "            elif via_lower == \"json\":\n",
    "                self.insert_netCDF_metadata_json(self, **kwargs)\n",
    "            elif via_lower == \"input\":\n",
    "                self.insert_netCDF_metadata_input(self, **kwargs)\n",
    "            else:\n",
    "                raise ValueError(f\"{via} is not a valid metadata input.\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error inserting netCDF metadata: {str(e)}\")\n",
    "    def get_attrs(self):\n",
    "        return self.attrs\n",
    "    def read_global_metadata(self, attributes=None):\n",
    "        \"\"\"\n",
    "        Print the global metadata attributes of the dataset.\n",
    "\n",
    "        Args:\n",
    "            attributes (list): List of attribute names to print. If None, all attributes will be printed.\n",
    "        \"\"\"\n",
    "        attrs = Metadata.get_attrs(self)\n",
    "        if not attrs:\n",
    "            print(\"No Global Attributes were found.\")\n",
    "        else:\n",
    "            if attributes is None:\n",
    "                for attr_name, attr_value in attrs.items():\n",
    "                    print(attr_name, \":\", attr_value)\n",
    "            else:\n",
    "                for attr_name, attr_value in attrs.items():\n",
    "                    if attr_name in attributes:\n",
    "                        print(attr_name, \":\", attr_value)\n",
    "    def insert_netCDF_global_metadata_input(self, attributes=None, new_file=False, filename=\"new_file.nc\"):\n",
    "        \"\"\"\n",
    "        Insert global metadata into a netCDF file.\n",
    "\n",
    "        Args:\n",
    "            attributes (list, optional): A list of attribute names for which the user will be prompted to enter values. \n",
    "                If not provided, a default list of attributes will be used.\n",
    "            new_file (bool, optional): A boolean indicating whether a new file should be created. \n",
    "                If True, the metadata will be exported to a file specified by the filename parameter. \n",
    "                Default is False.\n",
    "            filename (str, optional): The name of the file to which the metadata should be exported if new_file is True. \n",
    "                Default is \"new_file.nc\".\n",
    "\n",
    "        Returns:\n",
    "            None. The function modifies the metadata of the netCDF file and optionally exports it to a new file.\n",
    "        \"\"\"\n",
    "        default_attributes = [\n",
    "            \"Title\", \"Institution\", \"Source\",\n",
    "            \"History\", \"References\", \"Conventions\",\n",
    "            \"Creator_Author\", \"Project\", \"Description\"\n",
    "        ]\n",
    "        if attributes is None:\n",
    "            attributes = default_attributes\n",
    "        try:\n",
    "            if not isinstance(attributes, list):\n",
    "                raise ValueError(\"attributes must be a list\")\n",
    "            for attribute in attributes:\n",
    "                if not isinstance(attribute, str):\n",
    "                    raise ValueError(\"attributes must contain only strings\")\n",
    "                self.attrs[attribute] = input(f\"{attribute} - Enter value: \")\n",
    "        except ValueError as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "        if new_file:\n",
    "            File.export_to_file(self, filename)\n",
    "        Metadata.read_global_metadata(self)\n",
    "    def insert_netCDF_global_metadata_dict(self, dictionary, new_file=False, filename=\"new_file.nc\"):\n",
    "        \"\"\"\n",
    "        Insert global metadata into a netCDF file.\n",
    "\n",
    "        Args:\n",
    "            self (NetCDFFile): An instance of the NetCDFFile class.\n",
    "            dictionary (dict): A dictionary containing the global metadata to be inserted into the netCDF file.\n",
    "            new_file (bool, optional): A boolean flag indicating whether to export the modified netCDF file to a new file. Default is False.\n",
    "            filename (str, optional): The filename of the new netCDF file to be exported. Default is 'new_file.nc'.\n",
    "\n",
    "        Raises:\n",
    "            TypeError: If the dictionary input is not of type dict.\n",
    "\n",
    "        Returns:\n",
    "            None. The function modifies the netCDF file by inserting the global metadata attributes. If new_file is True, it also exports the modified netCDF file to a new file.\n",
    "        \"\"\"\n",
    "        if not isinstance(dictionary, dict):\n",
    "            raise TypeError(f\"{dictionary} is not a dictionary.\")\n",
    "        \n",
    "        for key, value in dictionary.items():\n",
    "            self.attrs[key] = value\n",
    "        if new_file:\n",
    "            File.export_to_file(self, filename)\n",
    "        Metadata.read_global_metadata(self)\n",
    "    def insert_netCDF_global_metadata_json(self, json_file, new_file=False, filename=\"new_file.nc\"):\n",
    "        \"\"\"\n",
    "        Inserts global metadata from a JSON file into a netCDF file.\n",
    "\n",
    "        Args:\n",
    "            self: The instance of the class calling the function.\n",
    "            json_file (str): The path to the JSON file containing the metadata.\n",
    "            new_file (bool, optional): Indicates whether a new netCDF file should be created. Default is False.\n",
    "            filename (str, optional): Specifies the name of the new netCDF file. Default is \"new_file.nc\".\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If there is an error opening the JSON file.\n",
    "            json.JSONDecodeError: If there is an error decoding the JSON file.\n",
    "            ValueError: If the filename is invalid.\n",
    "            FileExistsError: If the filename already exists.\n",
    "            ValidationError: If the JSON file does not match the specified schema.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        schema = {\n",
    "            \"type\": \"object\",\n",
    "            \"patternProperties\": {\n",
    "                \".*\": { \"type\": \"string\" }\n",
    "            },\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            with open(json_file, 'r') as file:\n",
    "                metadata = json.load(file)\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(\"Error opening JSON file. Please check if the file exists or if there are any permission issues.\")\n",
    "        except json.JSONDecodeError:\n",
    "            raise json.JSONDecodeError(\"Error decoding JSON file. Please check if the file contains valid JSON.\")\n",
    "        \n",
    "        try:\n",
    "            # Validate JSON against schema\n",
    "            jsonschema.validate(instance=metadata, schema=schema)\n",
    "        except ValidationError as e:\n",
    "            raise ValidationError(str(e))\n",
    "        if new_file:\n",
    "            File.export_to_file(self, filename)\n",
    "        Metadata.read_global_metadata(self)\n",
    "    def read_parquet_metadata(self, attributes=None, cols=None):\n",
    "        \"\"\"\n",
    "        Reads the metadata of a Parquet file and prints the attributes of each column.\n",
    "\n",
    "        Args:\n",
    "            attributes (list, optional): A list of attributes to filter the metadata. If not provided, all attributes will be printed.\n",
    "            cols (list, optional): A list of column names to filter the columns. If not provided, metadata of all columns will be printed.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "\n",
    "        Example Usage:\n",
    "            # Example 1: Read metadata of all columns\n",
    "            read_parquet_metadata()\n",
    "\n",
    "            # Example 2: Read metadata of specific columns\n",
    "            read_parquet_metadata(cols=['column1', 'column2'])\n",
    "\n",
    "            # Example 3: Read metadata of specific attributes\n",
    "            read_parquet_metadata(attributes=['attribute1', 'attribute2'])\n",
    "\n",
    "            # Example 4: Read metadata of specific columns and attributes\n",
    "            read_parquet_metadata(cols=['column1', 'column2'], attributes=['attribute1', 'attribute2'])\n",
    "        \"\"\"\n",
    "        if isinstance(self, pd.DataFrame):\n",
    "            self = pa.Table.from_pandas(self)\n",
    "        if cols is None:\n",
    "            for i in range(self.num_columns):\n",
    "                field = self.field(i)\n",
    "                col = field.name\n",
    "                print(col)\n",
    "                if field.metadata is None:\n",
    "                    print(\"    No attributes were found for this column.\")\n",
    "                else:\n",
    "                    metadata = {key.decode('utf-8'): value.decode('utf-8') for key, value in field.metadata.items()}\n",
    "                    if attributes:\n",
    "                        for attr in attributes:\n",
    "                            if attr in metadata:\n",
    "                                print(f\"    {attr}: {metadata[attr]}\")\n",
    "                            else:\n",
    "                                print(f\"    The '{attr}' attribute was not found in this column's metadata.\")\n",
    "                    else:\n",
    "                        for key, value in metadata.items():\n",
    "                            print(f\"    {key}: {value}\") \n",
    "        else:\n",
    "            for i in range(self.num_columns):\n",
    "                field = self.field(i)\n",
    "                col = field.name\n",
    "                if col in cols:\n",
    "                    print(col)\n",
    "                    if field.metadata is None:\n",
    "                        print(\"    No attributes were found for this column.\")\n",
    "                    else:\n",
    "                        metadata = {key.decode('utf-8'): value.decode('utf-8') for key, value in field.metadata.items()}\n",
    "                        if attributes:\n",
    "                            for attr in attributes:\n",
    "                                if attr in metadata:\n",
    "                                    print(f\"    {attr}: {metadata[attr]}\")\n",
    "                                else:\n",
    "                                    print(f\"    The '{attr}' attribute was not found in this column's metadata.\")\n",
    "                        else:\n",
    "                            for key, value in metadata.items():\n",
    "                                print(f\"    {key}: {value}\")\n",
    "    def insert_parquet_metadata_input(self, attributes=None, cols=None, new_file=False, filename=\"new_file.parquet\"):\n",
    "        \"\"\"\n",
    "        Insert metadata for columns in a Parquet file.\n",
    "\n",
    "        Args:\n",
    "            attributes (list, optional): A list of attributes for which metadata needs to be inserted. If not provided, default attributes are used.\n",
    "            cols (list, optional): A list of columns for which metadata needs to be inserted. If not provided, metadata is inserted for all columns in the DataFrame.\n",
    "            new_file (bool, optional): A boolean indicating whether to export the DataFrame to a new Parquet file. Default is False.\n",
    "            filename (str, optional): The name of the new Parquet file. Default is \"new_file.parquet\".\n",
    "\n",
    "        Returns:\n",
    "            pyarrow.Table: A Parquet table with the inserted metadata.\n",
    "\n",
    "        Example Usage:\n",
    "            # Insert metadata for all columns in a DataFrame and export it to a Parquet file\n",
    "            df.insert_parquet_metadata_input()\n",
    "\n",
    "            # Insert metadata for specific columns in a DataFrame and export it to a new Parquet file\n",
    "            df.insert_parquet_metadata_input(attributes=['Description', 'Units'], cols=['col1', 'col2'], new_file=True, filename='metadata.parquet')\n",
    "        \"\"\"\n",
    "        default_attributes = ['Description', 'Units', 'Data Source', 'Valid Range or Categories']\n",
    "        if attributes is None:\n",
    "            attributes = default_attributes\n",
    "        if cols is None:\n",
    "            cols = list(self.columns)\n",
    "        metadata = []\n",
    "        columns = self.columns  \n",
    "        cols_set = set(cols)  \n",
    "        for col in columns:\n",
    "            if col in cols_set:\n",
    "                col_metadata = {}\n",
    "                for attribute in attributes:\n",
    "                    data = input(f\"{col}: {attribute} - Enter value: \")\n",
    "                    col_metadata[attribute] = data\n",
    "                metadata.append(col_metadata)\n",
    "            else:\n",
    "                metadata.append(None)\n",
    "        dtypes = self.dtypes\n",
    "        dtypes = [\"string\" if dtype == \"category\" else str(dtype) for dtype in dtypes]\n",
    "        cols_dtypes = zip(columns, dtypes, metadata)\n",
    "        schema = [pa.field(col, pa.type_for_alias(dtype), metadata=meta) for col, dtype, meta in cols_dtypes]\n",
    "        table_schema = pa.schema(schema)\n",
    "        table = pa.Table.from_pandas(self, schema=table_schema)\n",
    "        if new_file:\n",
    "            File.export_to_file(table, filename)\n",
    "        return table\n",
    "    def insert_parquet_metadata_dict(self, dictionary, cols=None, new_file=False, filename=\"new_file.parquet\"):\n",
    "        \"\"\"\n",
    "        Inserts metadata into a Parquet file based on a given dictionary.\n",
    "\n",
    "        Args:\n",
    "            dictionary (dict): A dictionary containing the metadata to be inserted into the Parquet file.\n",
    "            cols (list, optional): A list of column names to specify which columns the metadata should be inserted into. \n",
    "                If not provided, metadata will be inserted into all columns. Default is None.\n",
    "            new_file (bool, optional): A boolean value indicating whether to create a new Parquet file with the inserted metadata. \n",
    "                Default is False.\n",
    "            filename (str, optional): The name of the new Parquet file to be created. Default is \"new_file.parquet\".\n",
    "\n",
    "        Returns:\n",
    "            pyarrow.Table: A Parquet table with the inserted metadata.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the dictionary parameter is not provided.\n",
    "            AttributeError: If the dictionary parameter is not a dictionary.\n",
    "\n",
    "        Example Usage:\n",
    "            # Create a DataFrame\n",
    "            df = pd.DataFrame({'A': [1, 2, 3], 'B': ['a', 'b', 'c']})\n",
    "\n",
    "            # Define a dictionary with metadata\n",
    "            metadata_dict = {'A': 'This is column A', 'B': 'This is column B'}\n",
    "\n",
    "            # Insert metadata into the Parquet file\n",
    "            df.insert_parquet_metadata_dict(metadata_dict, new_file=True, filename='new_file.parquet')\n",
    "        \"\"\"\n",
    "\n",
    "        if dictionary is None:\n",
    "            raise ValueError(\"Please provide a dictionary.\")\n",
    "        if cols is None:\n",
    "            cols = list(self.columns)\n",
    "        columns = self.columns\n",
    "        dtypes = self.dtypes\n",
    "        dtypes = [\"string\" if dtype == \"category\" else str(dtype) for dtype in dtypes]\n",
    "        metadata = []\n",
    "        if isinstance(dictionary, dict):\n",
    "            cols_set = set(cols)\n",
    "            for col in columns:\n",
    "                if col in cols_set:\n",
    "                    metadata.append(dictionary)\n",
    "                else:\n",
    "                    metadata.append(None)\n",
    "            cols_dtypes = zip(columns, dtypes, metadata)\n",
    "            schema = [pa.field(col, pa.type_for_alias(dtype), metadata=meta) for col, dtype, meta in cols_dtypes]\n",
    "            table_schema = pa.schema(schema)\n",
    "            table = pa.Table.from_pandas(self, schema=table_schema)\n",
    "            if new_file:\n",
    "                File.export_to_file(table, filename)\n",
    "            return table  \n",
    "        else:\n",
    "            raise AttributeError(f\"{dictionary} is not a dictionary.\")\n",
    "    def insert_parquet_metadata_json(self, json_file, new_file=False, filename=\"new_file.parquet\"):\n",
    "        \"\"\"\n",
    "        Inserts metadata from a JSON file into a Parquet file.\n",
    "\n",
    "        Args:\n",
    "            json_file (str): The path to the JSON file containing the metadata.\n",
    "            new_file (bool, optional): Indicates whether a new Parquet file should be created. Defaults to False.\n",
    "            filename (str, optional): The name of the new Parquet file. Defaults to \"new_file.parquet\".\n",
    "\n",
    "        Returns:\n",
    "            pyarrow.Table: The Parquet table with the updated metadata.\n",
    "\n",
    "        Raises:\n",
    "            IOError: If there is an error opening the JSON file.\n",
    "            ValidationError: If the JSON data does not match the predefined schema.\n",
    "        \"\"\"\n",
    "        schema = {\n",
    "            \"type\": \"object\",\n",
    "            \"patternProperties\": {\n",
    "                \".*\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"patternProperties\": {\n",
    "                        \".*\": {\n",
    "                            \"type\": \"string\",\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"additionalProperties\": False\n",
    "            }\n",
    "        }\n",
    "        try:\n",
    "            with open(json_file, 'r') as file:\n",
    "                json_data = json.load(file)\n",
    "        except IOError:\n",
    "            raise IOError(\"Error opening JSON file. Please check if the file exists or if there are any permission issues.\")\n",
    "        try:\n",
    "            # Validate JSON against schema\n",
    "            jsonschema.validate(instance=json_data, schema=schema)\n",
    "        except ValidationError as e:\n",
    "            raise ValidationError(str(e))\n",
    "        cols_dtypes = Statistics.get_cols_dtypes(self)\n",
    "        cols_dtypes = [[col, \"string\"] if dtype == \"category\" else [col, str(dtype)] for col, dtype in cols_dtypes]\n",
    "        metadata = []\n",
    "        for col in cols_dtypes:\n",
    "            if col[0] in json_data:\n",
    "                col_metadata = json_data[col[0]]\n",
    "                metadata.append(col_metadata)\n",
    "            else:\n",
    "                metadata.append(None)\n",
    "        cols_dtypes = zip(cols_dtypes, metadata)\n",
    "        schema = [pa.field(col_dtype[0], pa.type_for_alias(col_dtype[1]), metadata=meta) for col_dtype, meta in cols_dtypes]\n",
    "        table_schema = pa.schema(schema)\n",
    "        table = pa.Table.from_pandas(self, schema=table_schema)\n",
    "        if new_file:\n",
    "            File.export_to_file(table, filename)\n",
    "        return table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "class File:\n",
    "    @staticmethod\n",
    "    def get_file_extension(path):\n",
    "        return os.path.splitext(path)[1]\n",
    "\n",
    "    @staticmethod\n",
    "    def read_file(path, **kwargs):\n",
    "        \"\"\"\n",
    "        Read a file and return a DataFrame object.\n",
    "\n",
    "        Args:\n",
    "            cls: The class to be instantiated with the DataFrame object.\n",
    "            path: The path to the file.\n",
    "            **kwargs: Additional keyword arguments to be passed to the file reader.\n",
    "\n",
    "        Returns:\n",
    "            An instance of the specified class with the DataFrame object.\n",
    "\n",
    "        Raises:\n",
    "            TypeError: If the path is not a string.\n",
    "            ValueError: If the file format is not supported.\n",
    "            RuntimeError: If there is an error in reading the file.\n",
    "        \"\"\"\n",
    "        if not os.path.isfile(path):\n",
    "            raise ValueError(\"Invalid file path.\")\n",
    "\n",
    "        try:\n",
    "            extension = File.get_file_extension(path)\n",
    "            if extension == \".csv\":\n",
    "                return pd.read_csv(path, **kwargs)\n",
    "            elif extension == \".parquet\":\n",
    "                return pd.read_parquet(path, **kwargs)\n",
    "            elif extension == \".json\":\n",
    "                return pd.read_json(path, **kwargs)\n",
    "            elif extension == \".xlsx\":\n",
    "                return pd.read_excel(path, **kwargs)\n",
    "            elif extension == \".xml\":\n",
    "                return pd.read_xml(path, **kwargs)\n",
    "            elif extension == \".feather\":\n",
    "                return pd.read_feather(path, **kwargs)\n",
    "            elif extension == \".html\":\n",
    "                return pd.read_html(path, **kwargs)\n",
    "            elif extension == \".nc\":\n",
    "                return xr.open_dataset(path, **kwargs)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported file format for {path}. Supported formats: CSV, Parquet, Json, Excel, Avro, Arrow\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error in reading the file {path}: {e}\")\n",
    "def get_file_extension(filename):\n",
    "    suffix = pathlib.Path(filename).suffix\n",
    "    return suffix\n",
    "def export_to_file(self, filename):\n",
    "    \"\"\"\n",
    "    Exports data to a file with a specified filename.\n",
    "\n",
    "    Args:\n",
    "        self: The data object that needs to be exported.\n",
    "        filename (str): The name of the file to export the data to.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the file extension is not valid.\n",
    "        FileExistsError: If the file already exists.\n",
    "    \"\"\"\n",
    "    suffixs = [\".nc\", \".parquet\"]\n",
    "    if not os.path.isfile(filename):\n",
    "        if self.get_file_extension(filename) in suffixs:\n",
    "            if self.get_file_extension(filename) == \".nc\":\n",
    "                self.to_netcdf(filename)\n",
    "            elif self.get_file_extension(filename) == \".parquet\":\n",
    "                pq.write_table(self, filename, compression=None)        \n",
    "        else:\n",
    "            raise ValueError(f\"Invalid file extension. Please provide a valid filename. Valid file extesions {suffixs}.\")\n",
    "    else:\n",
    "        raise FileExistsError(f\"{filename} already exists. Please change it or delete it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statistics:\n",
    "    def get_file_variables(self):\n",
    "        \"\"\"\n",
    "        Get the variables of the file.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of variables in the file.\n",
    "        \"\"\"\n",
    "        variables = list(self.variables.keys())\n",
    "        return variables\n",
    "    def get_dtypes(self, cols=None, output=True):\n",
    "        \"\"\"\n",
    "        Get the data types of the specified columns.\n",
    "\n",
    "        Args:\n",
    "            cols (list): List of column names. If None, all columns will be used.\n",
    "            output (bool): If True, print the data types. Default is True.\n",
    "\n",
    "        Returns:\n",
    "            list: List of data types.\n",
    "\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        if output:\n",
    "            for col in cols:\n",
    "                print(f\"{col} dtype is {self[col].dtype.name}\")\n",
    "        dtypes = [self[col].dtype.name for col in cols]\n",
    "        return dtypes\n",
    "    def get_cols(self):\n",
    "        \"\"\"\n",
    "        Get the column names of the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of column names.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.columns.tolist()\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while accessing self.columns: {e}\")\n",
    "            return []\n",
    "    def get_cols_dtypes(self, cols=None, get_df=True):\n",
    "        \"\"\"\n",
    "        Returns the data types of the specified columns in a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names to get the data types for. If not provided, it gets the data types for all columns in the DataFrame.\n",
    "            get_df (bool, optional): A boolean flag indicating whether to return the data types as a DataFrame. Default is True.\n",
    "\n",
    "        Returns:\n",
    "            If get_df is True, returns a DataFrame with the column names and their data types.\n",
    "            If get_df is False, returns a dictionary with column names as keys and their corresponding data types as values.\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If the number of columns and the number of data types do not match.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        dtypes = []\n",
    "        for col in cols:\n",
    "            dtypes.append(Statistics.get_dtypes(self, [col], output=False))\n",
    "        if len(cols) != len(dtypes):\n",
    "            raise ValueError(\"Number of columns and number of data types do not match.\")\n",
    "        cols_dtypes = {col: dtype for col, dtype in zip(cols, dtypes)}\n",
    "        if get_df:\n",
    "            cols_info = [[col, str(dtype).strip(\"[]'\")] for col, dtype in zip(cols, dtypes)]\n",
    "            columns_name = [\"Column_Name\", \"Dtype\"]\n",
    "            dataframe = pd.DataFrame(cols_info, columns=columns_name)\n",
    "            return dataframe\n",
    "        return cols_dtypes\n",
    "    def convert_python_type(min_value, max_value):\n",
    "        \"\"\"\n",
    "        Convert the minimum and maximum values of a given type to the appropriate Python data type.\n",
    "\n",
    "        Args:\n",
    "            min_value: The minimum value of a given type.\n",
    "            max_value: The maximum value of a given type.\n",
    "\n",
    "        Returns:\n",
    "            A tuple containing the converted min_value and max_value.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If min_value and max_value are not of the same type or if they are not of a valid numeric or boolean type.\n",
    "        \"\"\"\n",
    "        if type(min_value) != type(max_value):\n",
    "            raise ValueError(\"min_value and max_value must be of the same type\")\n",
    "\n",
    "        if not isinstance(min_value, (int, np.integer, float, np.floating, np.bool_, bool)):\n",
    "            raise ValueError(\"Invalid input: min_value must be numeric or boolean.\")\n",
    "        if not isinstance(max_value, (int, np.integer, float, np.floating, np.bool_, bool)):\n",
    "            raise ValueError(\"Invalid input: max_value must be numeric or boolean.\")\n",
    "\n",
    "        if isinstance((min_value, max_value), (int, np.integer)):\n",
    "            return int(min_value), int(max_value)\n",
    "        elif isinstance((min_value, max_value), (float, np.floating)):\n",
    "            return float(min_value), float(max_value)\n",
    "        elif isinstance((min_value, max_value), (np.bool_, bool)):\n",
    "            return bool(min_value), bool(max_value)\n",
    "        else:\n",
    "            return min_value, max_value\n",
    "    def get_best_dtypes(self, cols=None, convert=False, output=True, show_df=False, get_dict=False):\n",
    "        \"\"\"\n",
    "        Determines the best data type for each column in a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names. If not provided, all columns in the DataFrame will be considered.\n",
    "            convert (bool, optional): Indicates whether to convert the columns to the best data type. Default is False.\n",
    "            output (bool, optional): Indicates whether to print the best data type for each column. Default is True.\n",
    "            show_df (bool, optional): Indicates whether to return a DataFrame with the column names and their best data types. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            str or DataFrame or None: \n",
    "                - If convert and show_df parameters are False, returns the best data type for each column as a string.\n",
    "                - If convert parameter is True, returns the modified DataFrame with columns converted to the best data types.\n",
    "                - If show_df parameter is True, returns a DataFrame with the column names and their best data types.\n",
    "                - Otherwise, returns None.\n",
    "\n",
    "        Raises:\n",
    "            Exception: If an error occurs while processing a column.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        if show_df:\n",
    "            output = False\n",
    "            dataframe = []\n",
    "            dataframe1 = Statistics.get_cols_dtypes(self, get_df=True)\n",
    "        if get_dict:\n",
    "            num_of_memory = {}\n",
    "        for col in cols:\n",
    "            try:\n",
    "                is_numeric = pd.api.types.is_numeric_dtype(self[col])\n",
    "                is_bool = pd.api.types.is_bool_dtype(self[col])\n",
    "                is_integer = pd.api.types.is_integer_dtype(self[col])\n",
    "                is_float = pd.api.types.is_float_dtype(self[col])\n",
    "\n",
    "                if is_numeric:\n",
    "                    col_min = self[col].min()\n",
    "                    col_max = self[col].max()\n",
    "                    col_min, col_max = Statistics.convert_python_type(col_min, col_max)\n",
    "\n",
    "                    if is_bool:\n",
    "                        col_dtype = \"bool\"\n",
    "                    elif is_integer:\n",
    "                        if col_min >= -128 and col_max <= 127:\n",
    "                            col_dtype = \"int8\"\n",
    "                        elif col_min >= -32768 and col_max <= 32767:\n",
    "                            col_dtype = \"int16\"\n",
    "                        elif col_min >= -2147483648 and col_max <= 2147483647:\n",
    "                            col_dtype = \"int32\"\n",
    "                        else:\n",
    "                            col_dtype = \"int64\"\n",
    "                    elif is_float:\n",
    "                        if col_min >= np.finfo(np.float16).min and col_min <= np.finfo(np.float16).max:\n",
    "                            col_dtype = \"float16\"\n",
    "                        elif col_max >= np.finfo(np.float32).min and col_max <= np.finfo(np.float32).max:\n",
    "                            col_dtype = \"float32\"\n",
    "                        else:\n",
    "                            col_dtype = \"float64\"\n",
    "                    else:\n",
    "                        col_dtype = \"category\"\n",
    "\n",
    "                    if output:\n",
    "                        print(f\"The best dtype for {col} is {col_dtype}\")\n",
    "                        if col_dtype == 'int8':\n",
    "                            if self[col].nunique(dropna=False) == 2:\n",
    "                                print(\"But consider changing it to bool, has you have 2 unique values so you can map the numbers to be True or False\")\n",
    "                            if convert:\n",
    "                                self[col] = self[col].astype(col_dtype)\n",
    "                    elif show_df:\n",
    "                        col_info = [col, col_dtype]\n",
    "                        dataframe.append(col_info)\n",
    "                        if convert:\n",
    "                            self[col] = self[col].astype(col_dtype)\n",
    "                    elif convert:\n",
    "                        self[col] = self[col].astype(col_dtype)\n",
    "                    else:\n",
    "                        return col_dtype\n",
    "\n",
    "                else:\n",
    "                    col_dtype = \"category\"\n",
    "                    if output:\n",
    "                        print(f\"The best dtype for {col} is {col_dtype}\")\n",
    "                        if self[col].nunique(dropna=False) == 2:\n",
    "                            print(\"But consider changing it to bool, has you have 2 unique values so you can map the numbers to be True or False\")\n",
    "                        if convert:\n",
    "                            self[col] = self[col].astype(col_dtype)\n",
    "                    elif show_df:\n",
    "                        col_info = [col, col_dtype]\n",
    "                        dataframe.append(col_info)\n",
    "                        if convert:\n",
    "                            self[col] = self[col].astype(col_dtype)\n",
    "                    elif convert:\n",
    "                        self[col] = self[col].astype(col_dtype)\n",
    "                    else:\n",
    "                        return col_dtype\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error on processing columm {col}: {e}\")\n",
    "\n",
    "        if show_df and convert:\n",
    "            dataframe = pd.DataFrame(dataframe, columns=[\"Column_Name\", \"Best_Dtype\"])\n",
    "            dataframe = dataframe1.merge(dataframe, how=\"inner\", on=\"Column_Name\")\n",
    "            display(dataframe)\n",
    "            return self\n",
    "        elif convert:\n",
    "            return self\n",
    "        elif show_df:\n",
    "            dataframe1 = Statistics.get_cols_dtypes(self, get_df=True)\n",
    "            dataframe = pd.DataFrame(dataframe, columns=[\"Column_Name\", \"Best_Dtype\"])\n",
    "            dataframe = dataframe1.merge(dataframe, how=\"inner\", on=\"Column_Name\")\n",
    "            return dataframe\n",
    "    def get_memory_usage(self, cols=None, output=True, get_total=True, show_df=False, unit=\"kb\", use_deep=True, get_dict=False):\n",
    "        \"\"\"\n",
    "        Calculate the memory usage of each column in a DataFrame and provide options to display the results, calculate the total memory usage, and return the information as a DataFrame or dictionary.\n",
    "\n",
    "        Parameters:\n",
    "        - cols (optional): A list of column names to calculate the memory usage for. If not provided, memory usage will be calculated for all columns in the DataFrame.\n",
    "        - output (optional): A boolean flag indicating whether to print the memory usage for each column. Default is True.\n",
    "        - get_total (optional): A boolean flag indicating whether to calculate the total memory usage. Default is True.\n",
    "        - show_df (optional): A boolean flag indicating whether to return the memory usage as a DataFrame. Default is False.\n",
    "        - unit (optional): The unit of memory usage to be displayed. Supported values are \"kb\" (kilobytes), \"mb\" (megabytes), and \"b\" (bytes). Default is \"kb\".\n",
    "        - use_deep (optional): A boolean flag indicating whether to include the memory usage of referenced objects. Default is True.\n",
    "        - get_dict (optional): A boolean flag indicating whether to return the memory usage as a dictionary. Default is False.\n",
    "\n",
    "        Returns:\n",
    "        - If output parameter is True, the memory usage for each column will be printed.\n",
    "        - If get_total parameter is True, the total memory usage will be returned as a float.\n",
    "        - If show_df parameter is True, a DataFrame with the column names and memory usage will be returned.\n",
    "        - If get_dict parameter is True, a dictionary with the column names as keys and memory usage as values will be returned.\n",
    "        \"\"\"\n",
    "\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        supported_bytes = [\"kb\", \"mb\", \"b\"]\n",
    "        assert unit in supported_bytes, f\"{unit} not supported. Units supported is bytes(b), kilobytes(kb) and megabytes(mb).\"\n",
    "        if get_total:\n",
    "            total = 0\n",
    "        if show_df:\n",
    "            dataframe = []\n",
    "            output = False\n",
    "        if get_dict:\n",
    "            get_total = False\n",
    "            num_of_memory = {}\n",
    "            num_of_memory.update([(\"unit\", unit)])\n",
    "        conversion_factors = {\n",
    "            \"kb\": 1024,\n",
    "            \"mb\": 1024**2,\n",
    "            \"b\": 1\n",
    "        }\n",
    "        conversion_factor = conversion_factors[unit]\n",
    "        for col in cols:\n",
    "            memory_usage = self[col].memory_usage(deep=use_deep)\n",
    "            value = round(memory_usage / conversion_factor, 2)\n",
    "            if output:\n",
    "                print(f\"Column: {col} uses {value}{unit}.\")\n",
    "            if get_total:\n",
    "                total += value   \n",
    "            if show_df:\n",
    "                col_info = [col, value]\n",
    "                dataframe.append(col_info)\n",
    "            if get_dict:\n",
    "                num_of_memory.update([(col, value)])    \n",
    "        if show_df:\n",
    "            collums = [\"Col_Name\", f\"Memory_Usage({unit})\"]\n",
    "            if get_total:\n",
    "                dataframe.append([\"Total\", total])\n",
    "            dataframe = pd.DataFrame(dataframe, columns=collums)\n",
    "            if get_total:\n",
    "                n_rows = len(self.columns) + 1\n",
    "                display(dataframe.head(n_rows))\n",
    "                return total\n",
    "            else:\n",
    "                return dataframe\n",
    "        if output:   \n",
    "                print(f\"Total: {total} {unit}\")\n",
    "        if get_total:\n",
    "            return total\n",
    "        if get_dict:\n",
    "            return num_of_memory\n",
    "    def get_memory_usage_percentage(self, cols=None, output=True, unit=\"kb\", get_total=True, show_df=False, use_deep=True, get_dict=False):\n",
    "        \"\"\"\n",
    "        Calculate the memory usage percentage of each column in a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names. If not provided, all columns in the DataFrame will be considered.\n",
    "            output (bool, optional): Indicates whether to print the memory usage percentage for each column. Default is True.\n",
    "            unit (str, optional): The unit of memory usage to be displayed. Supported units are bytes (b), kilobytes (kb), and megabytes (mb). Default is kb.\n",
    "            get_total (bool, optional): Indicates whether to calculate the total memory usage percentage. Default is True.\n",
    "            show_df (bool, optional): Indicates whether to return a DataFrame with the column names and their memory usage percentages. Default is False.\n",
    "            use_deep (bool, optional): Indicates whether to use deep memory usage calculation. Default is True.\n",
    "            get_dict (bool, optional): Indicates whether to return a dictionary with column names as keys and their memory usage percentages as values. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            float or DataFrame or None: Depending on the parameters, the method returns the total memory usage percentage as a float, a DataFrame with the column names and their memory usage percentages, or None.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        supported_bytes = [\"kb\", \"mb\", \"b\"]\n",
    "        assert unit in supported_bytes, f\"{unit} not supported. Units supported is bytes(b), kilobytes(kb) and megabytes(mb).\"\n",
    "        if get_total:\n",
    "            total = 0\n",
    "        if show_df:\n",
    "            dataframe = []\n",
    "            output = False\n",
    "        if get_dict:\n",
    "            get_total = False\n",
    "            percentage_of_memory = {}\n",
    "            percentage_of_memory.update([(\"unit\", unit)])\n",
    "        for col in cols:\n",
    "            total_usage = Statistics.get_memory_usage(self, output=False)\n",
    "            col_usage = Statistics.get_memory_usage(self, [col], output=False, unit=unit, use_deep=use_deep)\n",
    "            value = round((col_usage/total_usage) * 100, 2)\n",
    "            if output:\n",
    "                print(f\"Column: {col} uses {value}{unit}.\")\n",
    "            if get_total:\n",
    "                total += value   \n",
    "            if show_df:\n",
    "                col_info = [col, f\"{value}%\"]\n",
    "                dataframe.append(col_info)\n",
    "            if get_dict:\n",
    "                percentage_of_memory.update([(col, f\"{value}%\")])\n",
    "        if show_df:\n",
    "            collums = [\"Col_Name\", f\"Percentage_of_Memory_Usage({unit})\"]\n",
    "            if get_total:\n",
    "                dataframe.append([\"Total\", f\"{total}%\"])\n",
    "            dataframe = pd.DataFrame(dataframe, columns=collums)\n",
    "            if get_total:\n",
    "                n_rows = len(self.columns) + 1\n",
    "                display(dataframe.head(n_rows))\n",
    "                return total\n",
    "            else:\n",
    "                return dataframe\n",
    "        if get_total:\n",
    "            if output:   \n",
    "                print(f\"Total: {total} {unit}\")\n",
    "            return total\n",
    "        if get_dict:\n",
    "            if output:   \n",
    "                print(f\"Total: {total} {unit}\")\n",
    "            return percentage_of_memory\n",
    "    def get_nulls_count(self, cols=None, output=True, show_df=False, get_total=True, get_dict=False):\n",
    "        \"\"\"\n",
    "        Calculate the number of null values in each column of a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names to calculate the number of null values for. If not provided, all columns in the DataFrame will be considered.\n",
    "            output (bool, optional): A boolean flag indicating whether to print the number of null values for each column. Default is True.\n",
    "            show_df (bool, optional): A boolean flag indicating whether to return a DataFrame with the column names and their corresponding null value counts. Default is False.\n",
    "            get_total (bool, optional): A boolean flag indicating whether to return the total number of null values in the DataFrame. Default is True.\n",
    "            get_dict (bool, optional): A boolean flag indicating whether to return a dictionary with column names as keys and their corresponding null value counts as values. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame or int or dict: Depending on the input parameters, the method returns:\n",
    "                - If show_df is True, a DataFrame with the column names and their corresponding null value counts.\n",
    "                - If get_total is True, the total number of null values in the DataFrame.\n",
    "                - If get_dict is True, a dictionary with column names as keys and their corresponding null value counts as values.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        if get_total:\n",
    "            total = 0\n",
    "        if show_df:\n",
    "            dataframe = [] \n",
    "            output = False\n",
    "        if get_dict:\n",
    "            get_total = False\n",
    "            num_of_nulls = {}\n",
    "        for col in cols:\n",
    "            value = self[col].isnull().sum() \n",
    "            if output:\n",
    "                print(f\"The number of null values in {col} is {value}\")\n",
    "            if get_total:\n",
    "                total += value   \n",
    "            if show_df:\n",
    "                col_info = [col, value]\n",
    "                dataframe.append(col_info)\n",
    "            if get_dict:\n",
    "                num_of_nulls.update([(col, value)])\n",
    "        if show_df:\n",
    "            collums = [\"Col_Name\", \"Null_Values\"]\n",
    "            if get_total:\n",
    "                dataframe.append([\"Total\", total])\n",
    "            dataframe = pd.DataFrame(dataframe, columns=collums)\n",
    "            if get_total:\n",
    "                n_rows = len(dataframe.columns)\n",
    "                display(dataframe.head(n_rows))\n",
    "                return total\n",
    "            else:\n",
    "                return dataframe\n",
    "        if get_total:\n",
    "            if output:   \n",
    "                print(f\"In this dataframe are missing a total {total} of null values.\")\n",
    "            return total\n",
    "        if get_dict:\n",
    "            return num_of_nulls\n",
    "\n",
    "    def get_null_percentage(self, cols=None, output=True, show_df=False, get_total=True, get_dict=False):\n",
    "        \"\"\"\n",
    "        Calculate the percentage of null values in each column of a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names. If not provided, all columns in the DataFrame will be considered.\n",
    "            output (bool, optional): Indicates whether to print the percentage of null values in each column. Default is True.\n",
    "            show_df (bool, optional): Indicates whether to return a DataFrame with the column names and their percentage of null values. Default is False.\n",
    "            get_total (bool, optional): Indicates whether to return the total percentage of null values in the DataFrame. Default is True.\n",
    "            get_dict (bool, optional): Indicates whether to return a dictionary with column names as keys and their corresponding percentage of null values as values. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            If output is True, the percentage of null values in each column is printed.\n",
    "            If show_df is True, a DataFrame with the column names and their percentage of null values is returned.\n",
    "            If get_total is True, the total percentage of null values in the DataFrame is returned.\n",
    "            If get_dict is True, a dictionary with column names as keys and their corresponding percentage of null values as values is returned.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        if get_total:\n",
    "            total = 0\n",
    "        if show_df:\n",
    "            dataframe = [] \n",
    "            output = False\n",
    "        if get_dict:\n",
    "            get_total = False\n",
    "            percentage_of_nulls = {}\n",
    "        for col in cols:\n",
    "            value = round((Statistics.get_nulls_count(self, [col], False)/len(self[col])) * 100, 2)\n",
    "            if output:\n",
    "                print(f\"The percentage of null values in {col} is {value}%\")\n",
    "            if get_total:\n",
    "                total += value   \n",
    "            if show_df:\n",
    "                col_info = [col, f\"{value}%\"]\n",
    "                dataframe.append(col_info)\n",
    "            if get_dict:\n",
    "                percentage_of_nulls.update([(col, f\"{value}%\")])\n",
    "        if show_df:\n",
    "            collums = [\"Col_Name\", \"Percentage_of_Null_Values\"]\n",
    "            if get_total:\n",
    "                dataframe.append([\"Total\", f\"{total}%\"])\n",
    "            dataframe = pd.DataFrame(dataframe, columns=collums)\n",
    "            if get_total:\n",
    "                n_rows = len(self.columns) + 1\n",
    "                display(dataframe.head(n_rows))\n",
    "                return total\n",
    "            else:\n",
    "                return dataframe\n",
    "        elif get_total:\n",
    "            if output:   \n",
    "                print(f\"{total}% of the values in this dataframe are missing.\")\n",
    "            return total\n",
    "        elif get_dict:\n",
    "            return percentage_of_nulls\n",
    "    def get_num_of_unique_values(self, cols=None, output=True, show_df=False):\n",
    "        \"\"\"\n",
    "        Calculate the number of unique values in specified columns of a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names. If not provided, all columns in the DataFrame will be considered.\n",
    "            output (bool, optional): A boolean flag indicating whether to print the number of unique values. Default is True.\n",
    "            show_df (bool, optional): A boolean flag indicating whether to return a DataFrame with the column names and their corresponding number of unique values. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            dict or DataFrame: If `show_df` is True, a DataFrame is returned with the column names and their corresponding number of unique values.\n",
    "                               Otherwise, a dictionary is returned with the column names as keys and the number of unique values as values.\n",
    "        \"\"\"\n",
    "\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        if show_df:\n",
    "            dataframe = []  \n",
    "            output = False\n",
    "        num_of_uniques = {}\n",
    "        for col in cols:\n",
    "            try:\n",
    "                num_unique_values = self[col].nunique()\n",
    "                num_of_uniques.update([(col, num_unique_values)])\n",
    "                if output:\n",
    "                    print(f\"The number of unique values in {col} is {num_unique_values}\")\n",
    "                if show_df:\n",
    "                    col_info = [col, num_unique_values]\n",
    "                    dataframe.append(col_info)\n",
    "            except KeyError:\n",
    "                print(f\"Column {col} does not exist in the DataFrame.\")\n",
    "        if show_df:\n",
    "            columns = [\"Col_Name\", \"Unique_Values\"]\n",
    "            dataframe = pd.DataFrame(dataframe, columns=columns)\n",
    "            return dataframe\n",
    "        else:\n",
    "            return num_of_uniques\n",
    "    def get_max_values(self, cols=None, output=True, show_df=False):\n",
    "        \"\"\"\n",
    "        Find the maximum values or the most common values in each column of a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names. If not provided, all columns in the DataFrame will be considered.\n",
    "            output (bool, optional): Indicates whether to print the maximum values. Default is True.\n",
    "            show_df (bool, optional): Indicates whether to return a DataFrame with the column names and their maximum values. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            dict or DataFrame: If show_df is False, a dictionary is returned with column names as keys and their corresponding maximum values or most common values as values.\n",
    "                               If show_df is True, a DataFrame is returned with the column names and their maximum values or most common values.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        max_values = {}\n",
    "        for col in cols:\n",
    "            try:\n",
    "                if not pd.api.types.is_categorical_dtype(self[col]) and not pd.api.types.is_bool_dtype(self[col]):\n",
    "                    value = self[col].max()\n",
    "                    max_values.update([(col, value)])\n",
    "                else:\n",
    "                    value = self[col].mode()[0]\n",
    "                    max_values.update([(col, value)])\n",
    "                if output:\n",
    "                    if not pd.api.types.is_categorical_dtype(self[col]) and not pd.api.types.is_bool_dtype(self[col]):\n",
    "                        print(f\"The maximum value in {col} is {value}\")\n",
    "                    else:\n",
    "                        print(f\"The most common value in {col} is {value}\")\n",
    "            except KeyError:\n",
    "                print(f\"Column {col} does not exist in the DataFrame.\")\n",
    "        if show_df:\n",
    "            dataframe = []\n",
    "            for col in cols:\n",
    "                col_info = [col, max_values[col]]\n",
    "                dataframe.append(col_info)\n",
    "            columns = [\"Col_Name\", \"Max_Values/Most_Common\"]\n",
    "            dataframe = pd.DataFrame(dataframe, columns=columns)\n",
    "            return dataframe\n",
    "        else:\n",
    "            return max_values\n",
    "    def get_max_values_count(self, cols=None, output=True, show_df=False):\n",
    "        \"\"\"\n",
    "        Returns the number of occurrences of the maximum value or the most common value in each column of a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names. If not provided, all columns in the DataFrame will be considered.\n",
    "            output (bool, optional): Indicates whether to print the number of occurrences of the maximum value or the most common value in each column. Default is True.\n",
    "            show_df (bool, optional): Indicates whether to return a DataFrame with the column names and the number of occurrences of the maximum value or the most common value. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame or dict: If show_df is True, returns a DataFrame with the column names and the number of occurrences of the maximum value or the most common value. Otherwise, returns a dictionary with the column names as keys and the number of occurrences of the maximum value or the most common value as values.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        max_values_count = {}\n",
    "        for col in cols:\n",
    "            try:\n",
    "                if not pd.api.types.is_categorical_dtype(self[col]) and not pd.api.types.is_bool_dtype(self[col]):\n",
    "                    value = self[col].max()\n",
    "                    value = self[col].eq(value).sum()  \n",
    "                    max_values_count.update([(col, value)])\n",
    "                else:\n",
    "                    value = self[col].value_counts().iat[0]  \n",
    "                    max_values_count.update([(col, value)])\n",
    "                if output:\n",
    "                    if not pd.api.types.is_categorical_dtype(self[col]) and not pd.api.types.is_bool_dtype(self[col]):\n",
    "                        print(f\"The number of ocurrences of the max value in {col} is {value}\")\n",
    "                    else:\n",
    "                        print(f\"The number of ocurrences of the most common value in {col} is {value}\")\n",
    "            except KeyError:\n",
    "                print(f\"Column {col} does not exist in the DataFrame.\")\n",
    "        if show_df:\n",
    "            dataframe = []\n",
    "            for col in cols:\n",
    "                col_info = [col, max_values_count[col]]\n",
    "                dataframe.append(col_info)\n",
    "            columns = [\"Col_Name\", \"Max_Values/Most_Common Count\"]\n",
    "            dataframe = pd.DataFrame(dataframe, columns=columns)\n",
    "            return dataframe\n",
    "        else:\n",
    "            return max_values_count\n",
    "    def get_max_values_percentage(self, cols=None, output=True, show_df=False):\n",
    "        \"\"\"\n",
    "        Calculates the percentage of the maximum value or the most common value in each column of a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names. If not provided, all columns in the DataFrame will be considered.\n",
    "            output (bool, optional): Indicates whether to print the percentage of the maximum value or the most common value. Default is True.\n",
    "            show_df (bool, optional): Indicates whether to return a DataFrame with the column names and their corresponding percentages. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            dict or DataFrame: If `show_df` is True, it returns a DataFrame with the column names and their corresponding percentages. \n",
    "                               Otherwise, it returns a dictionary with column names as keys and their corresponding percentages as values.\n",
    "\n",
    "        Raises:\n",
    "            KeyError: If a column specified in `cols` does not exist in the DataFrame.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        max_values_percentage = {}\n",
    "        for col in cols:\n",
    "            try:\n",
    "                if not pd.api.types.is_categorical_dtype(self[col]) and not pd.api.types.is_bool_dtype(self[col]):\n",
    "                    value = self[col].max()\n",
    "                    value = self[col].eq(value).sum()\n",
    "                    value = (value / self[col].count()) * 100\n",
    "                    value = round(value, 2)\n",
    "                    max_values_percentage.update([(col, value)])\n",
    "                else:\n",
    "                    value = self[col].value_counts().iat[0]\n",
    "                    value = (value / self[col].count()) * 100\n",
    "                    value = round(value, 2)\n",
    "                    max_values_percentage.update([(col, value)])\n",
    "                if output:\n",
    "                    if not pd.api.types.is_categorical_dtype(self[col]) and not pd.api.types.is_bool_dtype(self[col]):\n",
    "                        print(f\"The percentage of max value in {col} is {value} %\")\n",
    "                        print(\"Tip: It's possible for the percentage of max values being lower than the percentage of min values. So don't take this function seriously if you are using it for numerical columns.\")\n",
    "                    else:\n",
    "                        print(f\"The percentage of most common value in {col} is {value} %\")\n",
    "            except KeyError:\n",
    "                print(f\"Column {col} does not exist in the DataFrame.\")\n",
    "        if show_df:\n",
    "            dataframe = []\n",
    "            for col in cols:\n",
    "                col_info = [col, f\"{max_values_percentage[col]}%\"]\n",
    "                dataframe.append(col_info)\n",
    "            columns = [\"Col_Name\", \"Max_Values/Most_Common Percentage\"]\n",
    "            dataframe = pd.DataFrame(dataframe, columns=columns)\n",
    "            return dataframe\n",
    "        else:\n",
    "            return max_values_percentage\n",
    "    def get_min_values(self, cols=None, output=True, show_df=False):\n",
    "        \"\"\"\n",
    "        Retrieve the minimum values for specified columns in a DataFrame.\n",
    "    \n",
    "        Args:\n",
    "            cols (list, optional): A list of column names for which the minimum values should be retrieved. \n",
    "                If not provided, the method will consider all columns in the DataFrame.\n",
    "            output (bool, optional): A boolean flag indicating whether to print the minimum values for each column. \n",
    "                Default is True.\n",
    "            show_df (bool, optional): A boolean flag indicating whether to return the result as a DataFrame. \n",
    "                Default is False.\n",
    "    \n",
    "        Returns:\n",
    "            dict or DataFrame: If show_df is False, the method returns a dictionary with column names as keys \n",
    "                and their corresponding minimum values as values. If show_df is True, the method returns a DataFrame \n",
    "                with two columns: \"Col_Name\" and \"Min_Values/Less_Common\", containing the column names and their \n",
    "                minimum values.\n",
    "    \n",
    "        Raises:\n",
    "            KeyError: If a specified column does not exist in the DataFrame.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        min_values = {}\n",
    "        for col in cols:\n",
    "            try:\n",
    "                if not pd.api.types.is_categorical_dtype(self[col]) and not pd.api.types.is_bool_dtype(self[col]):\n",
    "                    value = self[col].min()\n",
    "                    min_values.update([(col, value)])\n",
    "                else:\n",
    "                    value = self[col].value_counts()\n",
    "                    value = value.index[-1]\n",
    "                    min_values.update([(col, value)])\n",
    "                if output:\n",
    "                    if not pd.api.types.is_categorical_dtype(self[col]) and not pd.api.types.is_bool_dtype(self[col]):\n",
    "                        print(f\"The minimum value in {col} is {value}\")\n",
    "                    else:\n",
    "                        print(f\"The less common value in {col} is {value}\")\n",
    "            except KeyError:\n",
    "                print(f\"Column {col} does not exist in the DataFrame.\")\n",
    "        if show_df:\n",
    "            dataframe = []\n",
    "            for col in cols:\n",
    "                col_info = [col, min_values[col]]\n",
    "                dataframe.append(col_info)\n",
    "            columns = [\"Col_Name\", \"Min_Values/Less_Common\"]\n",
    "            dataframe = pd.DataFrame(dataframe, columns=columns)\n",
    "            return dataframe\n",
    "        else:\n",
    "            return min_values\n",
    "    def get_min_values_count(self, cols=None, output=True, show_df=False):\n",
    "        \"\"\"\n",
    "        Calculate the count of the minimum values or the count of the less common values in each column of a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names. If not provided, all columns in the DataFrame will be considered.\n",
    "            output (bool, optional): A boolean flag indicating whether to print the count of the minimum values or less common values. Default is True.\n",
    "            show_df (bool, optional): A boolean flag indicating whether to return a DataFrame with the column names and their corresponding counts. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            dict or DataFrame: If show_df is False, returns a dictionary with column names as keys and their corresponding counts as values.\n",
    "                               If show_df is True, returns a DataFrame with the column names and their corresponding counts.\n",
    "\n",
    "        Raises:\n",
    "            KeyError: If a column specified in cols does not exist in the DataFrame.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        min_values_count = {}\n",
    "        for col in cols:\n",
    "            try:\n",
    "                if not pd.api.types.is_categorical_dtype(self[col]) and not pd.api.types.is_bool_dtype(self[col]):\n",
    "                    value = self[col].min()\n",
    "                    value = self[col].eq(value).sum()\n",
    "                    min_values_count.update([(col, value)])\n",
    "                else:\n",
    "                    value = self[col].value_counts().iat[-1]\n",
    "                    min_values_count.update([(col, value)])\n",
    "                if output:\n",
    "                    if not pd.api.types.is_categorical_dtype(self[col]) and not pd.api.types.is_bool_dtype(self[col]):\n",
    "                        print(f\"The number of ocurrences of the min value in {col} is {value}\")\n",
    "                    else:\n",
    "                        print(f\"The number of ocurrences of the less common value in {col} is {value}\")\n",
    "            except KeyError:\n",
    "                print(f\"Column {col} does not exist in the DataFrame.\")\n",
    "        if show_df:\n",
    "            dataframe = []\n",
    "            for col in cols:\n",
    "                col_info = [col, min_values_count[col]]\n",
    "                dataframe.append(col_info)\n",
    "            columns = [\"Col_Name\", \"Min_Values/Less_Common Count\"]\n",
    "            dataframe = pd.DataFrame(dataframe, columns=columns)\n",
    "            return dataframe\n",
    "        else:\n",
    "            return min_values_count\n",
    "    def get_min_values_percentage(self, cols=None, output=True, show_df=False):\n",
    "        \"\"\"\n",
    "        Calculates the percentage of the minimum value or the percentage of the less common value in each column of a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names. If not provided, all columns in the DataFrame will be considered.\n",
    "            output (bool, optional): Indicates whether to print the percentage of the minimum value or the less common value in each column. Default is True.\n",
    "            show_df (bool, optional): Indicates whether to return a DataFrame with the column names and their corresponding percentages. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            dict or DataFrame: If `show_df` is True, returns a DataFrame with the column names and their corresponding percentages. \n",
    "                               If `show_df` is False, returns a dictionary with the column names as keys and their corresponding percentages as values.\n",
    "                               If `output` is True, prints the percentage of the minimum value or the less common value in each column.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        min_values_percentage = {}\n",
    "        for col in cols:\n",
    "            try:\n",
    "                if not pd.api.types.is_categorical_dtype(self[col]) and not pd.api.types.is_bool_dtype(self[col]):\n",
    "                    value = self[col].min()\n",
    "                    value = self[col].eq(value).sum()\n",
    "                    value = (value / self[col].count()) * 100\n",
    "                    value = round(value, 2)\n",
    "                    min_values_percentage.update([(col, value)])\n",
    "                else:\n",
    "                    value = self[col].value_counts().iat[-1]\n",
    "                    value = (value / self[col].count()) * 100\n",
    "                    value = round(value, 2)\n",
    "                    min_values_percentage.update([(col, value)])\n",
    "                if output:\n",
    "                    if not pd.api.types.is_categorical_dtype(self[col]) and not pd.api.types.is_bool_dtype(self[col]):\n",
    "                        print(f\"The percentage of min value in {col} is {value} %\")\n",
    "                        print(\"Tip: It's possible for the percentage of max values being lower than the percentage of min values. So don't take this function seriously if you are using it for numerical columns.\")\n",
    "                    else:\n",
    "                        print(f\"The percentage of less common value in {col} is {value} %\")\n",
    "            except KeyError:\n",
    "                print(f\"Column {col} does not exist in the DataFrame.\")\n",
    "        if show_df:\n",
    "            dataframe = []\n",
    "            for col in cols:\n",
    "                col_info = [col, f\"{min_values_percentage[col]}%\"]\n",
    "                dataframe.append(col_info)\n",
    "            columns = [\"Col_Name\", \"Min_Values/Less_Common Percentage\"]\n",
    "            dataframe = pd.DataFrame(dataframe, columns=columns)\n",
    "            return dataframe\n",
    "        else:\n",
    "            return min_values_percentage\n",
    "    def get_dataframe_mem_insight(self, transpose=False):\n",
    "        \"\"\"\n",
    "        Generate memory insights for each column in a given dataframe.\n",
    "\n",
    "        Args:\n",
    "            self (pandas.DataFrame): The dataframe for which memory insights are to be generated.\n",
    "            transpose (bool, optional): A flag indicating whether the resulting dataframe should be transposed. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: A dataframe containing information such as column name, data type, recommended data type, memory usage, number of missing values, percentage of missing values, and number of distinct values.\n",
    "        \"\"\"\n",
    "        dataframe = []\n",
    "        for col in self.columns:\n",
    "            col_info = [\n",
    "                col,\n",
    "                str(Statistics.get_dtypes(self, [col], False)).strip(\"[]'\"),\n",
    "                Statistics.get_best_dtypes(self, [col], False, False),\n",
    "                Statistics.get_memory_usage(self, [col], False),\n",
    "                f\"{Statistics.get_memory_usage_percentage(self, [col], False)}%\",\n",
    "                Statistics.get_nulls_count(self, [col], False),\n",
    "                f\"{Statistics.get_null_percentage(self, [col], False)}%\",\n",
    "                Statistics.get_num_of_unique_values(self, [col], False)\n",
    "            ]\n",
    "            dataframe.append(col_info)\n",
    "    \n",
    "        column_names = [\n",
    "            'Column',\n",
    "            'Dtype',\n",
    "            'Recommend_Dtype',\n",
    "            'Memory',\n",
    "            'Memory_Percentage',\n",
    "            'Missing_Values',\n",
    "            'Percentage_of_Missing_Values',\n",
    "            'Distinct_Values'\n",
    "        ]\n",
    "        dataframe = pd.DataFrame(dataframe, columns=column_names)\n",
    "        if transpose:\n",
    "            dataframe = dataframe.transpose()\n",
    "            dataframe.columns = dataframe.iloc[0]\n",
    "            dataframe = dataframe[1:]\n",
    "        return dataframe.head(len(self.columns))\n",
    "    def get_dataframe_values_insight(self, transpose=False):\n",
    "        \"\"\"\n",
    "        Generates insights about the values in each column of a given dataframe.\n",
    "\n",
    "        Args:\n",
    "            self (pandas.DataFrame): The dataframe for which insights are to be generated.\n",
    "            transpose (bool, optional): A boolean flag indicating whether to transpose the resulting dataframe. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: A dataframe containing insights about the values in each column of the input dataframe. The number of rows in the resulting dataframe is equal to the number of columns in the input dataframe.\n",
    "        \"\"\"\n",
    "        dataframe = []\n",
    "        for col in self.columns:\n",
    "            col_info = [\n",
    "                col,\n",
    "                str(Statistics.get_dtypes(self, [col], False)).strip(\"[]'\"),\n",
    "                list(Statistics.get_num_of_unique_values(self, [col], False).values())[0],\n",
    "                list(Statistics.get_max_values(self, [col], False).values())[0],\n",
    "                list(Statistics.get_max_values_count(self, [col], False).values())[0],\n",
    "                f\"{list(Statistics.get_max_values_percentage(self, [col], False).values())[0]}%\",\n",
    "                list(Statistics.get_min_values(self, [col], False).values())[0],\n",
    "                list(Statistics.get_min_values_count(self, [col], False).values())[0],\n",
    "                f\"{list(Statistics.get_min_values_percentage(self, [col], False).values())[0]}%\",\n",
    "                Statistics.get_nulls_count(self, [col], False),\n",
    "                f\"{Statistics.get_null_percentage(self, [col], False)}%\" \n",
    "            ]\n",
    "            dataframe.append(col_info)\n",
    "\n",
    "        column_names = [\n",
    "            'Column',\n",
    "            'Dtype',\n",
    "            'Distinct_Values',\n",
    "            'Most_Common/Max_Value',\n",
    "            'Occurrences_of_Max_Value',\n",
    "            'Percentages_of_Occurrences_of_Max_Value',\n",
    "            'Less_Common/Min_Value',\n",
    "            'Occurrences_of_Min_Value',\n",
    "            'Percentage_of_Occurrences_of_Min_Value',\n",
    "            'Missing_Values',\n",
    "            'Percentage_of_Missing_Values'\n",
    "        ]\n",
    "        dataframe = pd.DataFrame(dataframe, columns=column_names)\n",
    "        if transpose:\n",
    "            dataframe = dataframe.transpose()\n",
    "            dataframe.columns = dataframe.iloc[0]\n",
    "            dataframe = dataframe[1:]\n",
    "        return dataframe.head(len(self.columns))\n",
    "    def find(self, conditions, AND=True, OR=False):\n",
    "        \"\"\"\n",
    "        Filter the data in a DataFrame based on specified conditions using logical operators (AND or OR).\n",
    "\n",
    "        Args:\n",
    "            conditions (list): A list of conditions to filter the data. Each condition is a logical expression using comparison operators.\n",
    "            AND (bool, optional): Indicates whether to use the AND operator for combining the conditions. Default is True.\n",
    "            OR (bool, optional): Indicates whether to use the OR operator for combining the conditions. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: A subset of the original DataFrame that satisfies the specified conditions.\n",
    "\n",
    "        Raises:\n",
    "            TypeError: If the conditions input is not a list.\n",
    "            ValueError: If both AND and OR are True simultaneously.\n",
    "            ValueError: If neither AND nor OR is True.\n",
    "        \"\"\"\n",
    "        if not isinstance(conditions, list):\n",
    "            raise TypeError(f\"{conditions} has to be a list\")\n",
    "        if OR and AND:\n",
    "            raise ValueError(\"Both AND and OR cannot be True simultaneously.\")\n",
    "        combined_condition = conditions[0]\n",
    "        if AND:\n",
    "            for condition in conditions[1:]:\n",
    "                combined_condition = combined_condition & condition\n",
    "        elif OR:\n",
    "            for condition in conditions[1:]:\n",
    "                combined_condition = combined_condition | condition\n",
    "        else:\n",
    "            raise ValueError(\"Either AND or OR must be True.\")\n",
    "\n",
    "        return self[combined_condition]\n",
    "    def find_replace(self, conditions, replace_with, AND=True, OR=False):\n",
    "        \"\"\"\n",
    "        Find rows in a DataFrame that meet certain conditions and replace values in a specified column with a new value.\n",
    "\n",
    "        Args:\n",
    "            conditions (dict): A dictionary specifying the conditions to filter the DataFrame. The keys are column names and the values are either a single value or a lambda function that returns True or False.\n",
    "            replace_with (tuple): A tuple containing the name of the column to replace values in and the new value to replace with.\n",
    "            AND (bool, optional): A boolean flag indicating whether to use the AND operator when evaluating multiple conditions. Default is True.\n",
    "            OR (bool, optional): A boolean flag indicating whether to use the OR operator when evaluating multiple conditions. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            None: The method modifies the DataFrame in-place and does not return any value.\n",
    "        \"\"\"\n",
    "        new_dataset = Statistics.find(self, conditions, AND, OR)\n",
    "        self.loc[new_dataset.index, replace_with[0]] = replace_with[1]\n",
    "        return self\n",
    "    def find_delete(self, conditions, AND=True, OR=False):\n",
    "        \"\"\"\n",
    "        Find rows in the DataFrame that meet certain conditions, delete those rows from the DataFrame, and return the modified DataFrame.\n",
    "\n",
    "        Args:\n",
    "            conditions (list): A list of conditions to filter the rows of the DataFrame.\n",
    "            AND (bool, optional): A boolean flag indicating whether the conditions should be combined using the logical AND operator. Default is True.\n",
    "            OR (bool, optional): A boolean flag indicating whether the conditions should be combined using the logical OR operator. Default is False.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: The modified DataFrame after deleting the rows that meet the conditions.\n",
    "        \"\"\"\n",
    "        new_dataset = Statistics.find(self, conditions, AND, OR)\n",
    "        self = self.drop(new_dataset.index)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from statistics import Statistics\n",
    "class Cleaning:\n",
    "    def capitalize_cols_name(self, cols = None):\n",
    "        \"\"\"\n",
    "        Capitalizes the column names of the DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "            cols (list, optional): List of column names to be capitalized. If None, all columns will be capitalized. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with capitalized column names.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        dataframe = self.copy()\n",
    "        dataframe = self.rename(columns=dict(zip(cols, map(str.capitalize, cols))))\n",
    "        return dataframe\n",
    "    def lower_cols_name(self, cols = None):\n",
    "        \"\"\"\n",
    "        Converts the column names of the DataFrame to lowercase.\n",
    "\n",
    "        Parameters:\n",
    "            cols (list, optional): List of column names to be converted. If None, all columns will be converted. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with lowercase column names.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        dataframe = self.copy()\n",
    "        dataframe = self.rename(columns=dict(zip(cols, map(str.lower, cols))))\n",
    "        return dataframe\n",
    "    def upper_cols_name(self, cols=None):\n",
    "        \"\"\"\n",
    "        Convert the column names of a DataFrame to uppercase.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names to be converted to uppercase. If not provided, all column names will be converted.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If any of the specified column names are not present in the DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: The DataFrame with the column names converted to uppercase.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        dataframe = self.copy()\n",
    "        dataframe = self.rename(columns=dict(zip(cols, map(str.upper, cols))))\n",
    "        return dataframe\n",
    "    def remove_cols_character(self, cols=None, characters=['_'], add_new_character=False, new_character=\" \"):\n",
    "        \"\"\"\n",
    "        Remove specified characters from the column names of a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): List of column names to be processed. If None, all columns will be processed. Defaults to None.\n",
    "            characters (list, optional): List of characters to be removed from the column names. Defaults to ['_'].\n",
    "            add_new_character (bool, optional): If True, a new character will be added in place of the removed character. Defaults to False.\n",
    "            new_character (str, optional): The new character to be added in place of the removed character. Defaults to \" \" (space).\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with the specified characters removed or replaced from the column names.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        new_columns = {}\n",
    "        for col in cols:\n",
    "            new_col = col \n",
    "            for character in characters:\n",
    "                for idx, letter in enumerate(col):\n",
    "                    if letter.lower() == character.lower():  \n",
    "                        new_col = new_col[:idx] + new_character + new_col[idx+1:] if add_new_character else new_col[:idx] + new_col[idx+1:]\n",
    "            new_columns[col] = new_col\n",
    "        dataframe = self.copy()\n",
    "        dataframe = self.rename(columns=new_columns)\n",
    "        return dataframe\n",
    "    def round_rows_value(self, cols=None, decimals=2):\n",
    "        \"\"\"\n",
    "        Round the numerical values in specified columns of a DataFrame to a specified number of decimal places.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): List of column names to be processed. If None, all columns will be processed. Defaults to None.\n",
    "            decimals (int, optional): The number of decimal places to round the numerical values to. Defaults to 2.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with the specified numerical values rounded to the specified number of decimal places.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        numerical_cols = [col for col in cols if Statistics.get_dtypes(self, [col], False) not in [\"categorical\", \"bool\", \"object\"]]\n",
    "        dataframe = self.copy()\n",
    "        dataframe[numerical_cols] = self[numerical_cols].applymap(lambda x: round(x, decimals) if isinstance(x, (int, float)) else x)\n",
    "        return dataframe\n",
    "    def remove_rows_character(self, cols=None, characters=[','], add_new_character=False, new_character=\" \"):\n",
    "        \"\"\"\n",
    "        Removes specified characters from the values in the specified columns of a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): List of column names to be processed. If None, all columns will be processed. Defaults to None.\n",
    "            characters (list, optional): List of characters to be removed from the values in the specified columns. Defaults to [','].\n",
    "            add_new_character (bool, optional): If True, adds a new character in place of the removed character. Defaults to False.\n",
    "            new_character (str, optional): The new character to be added if add_new_character is True. Defaults to \" \".\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with the specified characters removed from the values in the specified columns.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        dataframe = self.copy()\n",
    "        for col in cols:\n",
    "            if col in self.columns:\n",
    "                for idx, value in enumerate(self[col]):\n",
    "                    if isinstance(value, str):\n",
    "                        new_value = value\n",
    "                        for character in characters:\n",
    "                            for idx_char, letter in enumerate(new_value):\n",
    "                                if letter.lower() == character.lower():\n",
    "                                    new_value = new_value[:idx_char] + new_character + new_value[idx_char+1:] if add_new_character else new_value[:idx_char] + new_value[idx_char+1:]\n",
    "                        dataframe.at[idx, col] = new_value    \n",
    "        return dataframe\n",
    "    def capitalize_rows_string(self, cols = None):\n",
    "        \"\"\"\n",
    "        Capitalizes the string values in the specified columns.\n",
    "\n",
    "        Args:\n",
    "            cols (list): List of column names to capitalize. If None, all columns will be capitalized.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: The DataFrame with capitalized string values in the specified columns.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        dataframe = self.copy()\n",
    "        dataframe[cols] = self[cols].applymap(lambda x: x.capitalize() if isinstance(x, str) else x)\n",
    "        return dataframe\n",
    "    def lower_rows_string(self, cols=None):\n",
    "        \"\"\"\n",
    "        Convert the string values in specified columns of a DataFrame to lowercase.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): List of column names to be processed. If None, all columns will be processed.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with the specified string values converted to lowercase.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        dataframe = self.copy()\n",
    "        dataframe[cols] = self[cols].applymap(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "        return dataframe\n",
    "    def upper_rows_string(self, cols=None):\n",
    "        \"\"\"\n",
    "        Convert the string values in specified columns of a DataFrame to uppercase.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): List of column names to be processed. If None, all columns will be processed.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with the specified string values converted to uppercase.\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        dataframe = self.copy()\n",
    "        dataframe[cols] = self[cols].applymap(lambda x: x.upper() if isinstance(x, str) else x)\n",
    "        return dataframe\n",
    "    def remove_rows_with_missing_values(self, cols=None):\n",
    "        \"\"\"\n",
    "        Remove rows with missing values from the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names. If provided, only the rows with missing values in the specified columns will be removed. If not provided, all rows with missing values will be removed.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: The DataFrame with rows containing missing values removed.\n",
    "        \"\"\"\n",
    "        dataframe = self.copy()\n",
    "        if cols is None:\n",
    "            dataframe = self.dropna(axis=0)\n",
    "        else:\n",
    "            dataframe = self.dropna(subset=cols)\n",
    "        return dataframe\n",
    "    def interpolate_rows_with_missing_values(self, cols=None):\n",
    "        \"\"\"\n",
    "        Interpolates missing values in a DataFrame by filling them with interpolated values.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names to interpolate missing values. If not provided, all columns will be processed.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with missing values interpolated.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If any of the specified columns are not present in the DataFrame.\n",
    "        \"\"\"\n",
    "        dataframe = self.copy()\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        for col in cols:\n",
    "            dtype = Statistics.get_dtypes(self, [col], False)\n",
    "            dtype = str(dtype[0])     \n",
    "            if dtype in [\"categorical\", \"bool\", \"object\"]:\n",
    "                dataframe[col] = self[col].fillna(self[col].mode()[0])\n",
    "            else:\n",
    "                dataframe[col] = self[col].interpolate()\n",
    "        return dataframe\n",
    "    def foward_fill_rows_with_missing_values(self, cols = None):\n",
    "        \"\"\"\n",
    "        Forward fill missing values in a DataFrame by filling the missing values with the last known non-null value in the column.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names to forward fill missing values. If not provided, all columns will be processed.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with missing values forward filled.\n",
    "        \"\"\"\n",
    "        dataframe = self.copy()\n",
    "        if cols is None:\n",
    "            dataframe = self.ffill()\n",
    "        else:\n",
    "            dataframe = self.ffill(subset=cols)\n",
    "        return dataframe\n",
    "    def split_rows_string(self, col, new_cols, separator=\",\", delete_col=True, save_remain=True):\n",
    "        \"\"\"\n",
    "        Split the values in a specified column of a DataFrame into multiple columns based on a separator.\n",
    "\n",
    "        Args:\n",
    "            col (str): The name of the column to be split.\n",
    "            new_cols (list): A list of new column names to store the split values.\n",
    "            separator (str, optional): The separator used to split the values. Defaults to \",\".\n",
    "            delete_col (bool, optional): If True, the original column will be deleted. Defaults to True.\n",
    "            save_remain (bool, optional): If True, the remaining values after splitting will be saved in a new column. Defaults to True.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: The DataFrame with the specified column split into multiple columns.\n",
    "        \"\"\"\n",
    "        dataframe = self.copy()\n",
    "        split_result = dataframe[col].str.split(separator, expand=True)\n",
    "        split_result = split_result.fillna('')\n",
    "        for i, new_col in enumerate(new_cols):\n",
    "            if i == 0:\n",
    "                dataframe[new_col] = split_result[i]\n",
    "            else:\n",
    "                if save_remain:\n",
    "                    dataframe[new_col] = split_result.loc[:, i:].apply(lambda x: separator.join(x), axis=1)\n",
    "        if delete_col:\n",
    "            dataframe = dataframe.drop([col], axis=1)\n",
    "        else:\n",
    "            dataframe[col] = split_result[len(new_cols)]\n",
    "        return dataframe\n",
    "    def backward_fill_rows_with_missing_values(self, cols = None):\n",
    "        \"\"\"\n",
    "        Fill missing values in a DataFrame by backward filling them with the last valid value in each column.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names. If provided, only the missing values in the specified columns will be filled. If not provided, missing values in all columns will be filled.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: The DataFrame with missing values filled by backward filling with the last valid value in each column.\n",
    "        \"\"\"\n",
    "        dataframe = self.copy()\n",
    "        if cols is None:\n",
    "            dataframe = self.bfill()\n",
    "        else:\n",
    "            dataframe = self.bfill(subset=cols)\n",
    "        return dataframe\n",
    "    def fill_rows_with_missing_values_mean(self, cols=None, decimals=2):\n",
    "        \"\"\"\n",
    "        Fills missing values in a DataFrame with the mean value of the respective column.\n",
    "    \n",
    "        Args:\n",
    "            cols (list, optional): List of column names to fill missing values. If None, all columns will be processed. Defaults to None.\n",
    "            decimals (int, optional): The number of decimal places to round the mean value to. Defaults to 2.\n",
    "    \n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with missing values filled using the mean value of the respective column.\n",
    "    \n",
    "        Raises:\n",
    "            ValueError: If any of the specified columns are not present in the DataFrame.\n",
    "        \"\"\"\n",
    "        dataframe = self.copy()\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        for col in cols:\n",
    "            dtype = Statistics.get_dtypes(self, [col], False)\n",
    "            dtype = str(dtype[0])\n",
    "            if dtype in [\"categorical\", \"bool\", \"object\"]:\n",
    "                dataframe[col] = self[col].fillna(self[col].mode()[0])\n",
    "            else:\n",
    "                dataframe[col] = self[col].fillna(round(self[col].mean(), decimals))\n",
    "        return dataframe\n",
    "    def fill_rows_with_missing_values_max(self, cols = None):\n",
    "        \"\"\"\n",
    "        Fills missing values in a DataFrame with the maximum value of each column.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): List of column names to fill missing values. If None, all columns will be processed.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with missing values filled using the maximum value of each column.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If any of the specified columns are not present in the DataFrame.\n",
    "        \"\"\"\n",
    "        dataframe = self.copy()\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        for col in cols:\n",
    "            dtype = Statistics.get_dtypes(self, [col], False)\n",
    "            dtype = str(dtype[0])\n",
    "            if dtype in [\"categorical\", \"bool\", \"object\"]:\n",
    "                dataframe[col] = self[col].fillna(self[col].mode()[0])\n",
    "            else:\n",
    "                dataframe[col] = self[col].fillna(self[col].max())\n",
    "        return dataframe\n",
    "    def fill_rows_with_missing_values_min(self, cols=None):\n",
    "        \"\"\"\n",
    "        Fills missing values in a DataFrame with the minimum value of each column.\n",
    "        If a column has a categorical, boolean, or object data type, the missing values are filled with the most frequent value in that column.\n",
    "\n",
    "        Args:\n",
    "            cols (list, optional): A list of column names to fill missing values. If not provided, all columns will be processed.\n",
    "\n",
    "        Returns:\n",
    "            pandas.DataFrame: DataFrame with missing values filled using the minimum value of each column.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If any of the specified columns are not present in the DataFrame.\n",
    "        \"\"\"\n",
    "        dataframe = self.copy()\n",
    "        if cols is None:\n",
    "            cols = self.columns\n",
    "        else:\n",
    "            missing_cols = set(cols) - set(self.columns)\n",
    "            if missing_cols:\n",
    "                raise ValueError(f\"The following columns are not present in the DataFrame: {missing_cols}\")\n",
    "        for col in cols:\n",
    "            dtype = Statistics.get_dtypes(self, [col], False)\n",
    "            dtype = str(dtype[0])\n",
    "            if dtype in [\"categorical\", \"bool\", \"object\"]:\n",
    "                value = self[col].value_counts()\n",
    "                value = value.index[-1]\n",
    "                dataframe[col] = self[col].fillna(value)\n",
    "            else:\n",
    "                dataframe[col] = self[col].fillna(self[col].min())\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Next Steps** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Add more values insight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 - Visualization Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Telegram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://api.telegram.org/bot6148622889:AAFHdvQ_CxImlx1VEXE_vYhg4_2NFXk1OyU/sendPhoto\"\n",
    "def send_images_via_telegram(file_path, chat_id, caption=\"This is a caption\"):\n",
    "    my_file = open(file_path, 'rb')\n",
    "    parameters = {\n",
    "    \"chat_id\" : chat_id,\n",
    "    \"caption\" : caption\n",
    "    }\n",
    "    files = {   \n",
    "    \"photo\" : my_file\n",
    "    }\n",
    "    resp = requests.post(base_url, data=parameters, files=files)\n",
    "    print(resp.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slack\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vou mostrar as funes que me faltam criar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_token = \"xoxp-5452682117826-5446024818310-5452588829571-92e60adc3ecd07a736b6faea910b8831\"\n",
    "channel_id = \"C05DAGDAPEX\"\n",
    "client = WebClient(token=slack_token)\n",
    "def send_images_via_slack(file_path):\n",
    "    try:\n",
    "        response = client.files_upload(\n",
    "                channels=channel_id,\n",
    "                file=file_path\n",
    "                )\n",
    "        print(response)\n",
    "    except SlackApiError as e:\n",
    "        print(f\"Error uploading file: {e.response['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./Titanic.csv\")\n",
    "df1 = pd.read_csv(\"./Sales_Data.csv\")\n",
    "df2 = pd.read_parquet(\"./Titanic_Cleaned.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The character 'o' is in the string.\n"
     ]
    }
   ],
   "source": [
    "# Define the string\n",
    "my_string = \"HellO, wOrld!\"\n",
    "\n",
    "# Define the character you want to check for\n",
    "character_to_check = \"o\"\n",
    "\n",
    "# Check if the character is in the string\n",
    "if character_to_check.lower() in my_string.lower():\n",
    "    print(f\"The character '{character_to_check}' is in the string.\")\n",
    "else:\n",
    "    print(f\"The character '{character_to_check}' is not in the string.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>City</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>New York</td>\n",
       "      <td>85.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>90.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Houston</td>\n",
       "      <td>75.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name   age  Gender         City  SCORE\n",
       "0    Alice  25.0  female     New York   85.5\n",
       "1      Bob  30.0    male  Los Angeles    NaN\n",
       "2  Charlie  35.0    None      Chicago   90.7\n",
       "3    David  40.0    male      Houston   75.2\n",
       "4     Emma   NaN  female      Phoenix   88.9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a DataFrame for testing\n",
    "data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'],\n",
    "    'age': [25, 30, 35, 40, None],\n",
    "    'Gender': ['female', 'male', None, 'male', 'female'],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix'],\n",
    "    'SCORE': [85.5, None, 90.7, 75.2, 88.9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>City</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>New York</td>\n",
       "      <td>85.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35.0</td>\n",
       "      <td>None</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>90.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Houston</td>\n",
       "      <td>75.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>88.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name   age  Gender         City  SCORE\n",
       "0    Alice  25.0  female     New York   85.5\n",
       "1      Bob  30.0    male  Los Angeles    NaN\n",
       "2  Charlie  35.0    None      Chicago   90.7\n",
       "3    David  40.0    male      Houston   75.2\n",
       "4     Emma   NaN  female      Phoenix   88.9"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity Ordered</th>\n",
       "      <th>Price Each</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Purchase Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150502.0</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>700.00</td>\n",
       "      <td>02/18/19 01:35</td>\n",
       "      <td>866 Spruce St, Portland, ME 04101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150503.0</td>\n",
       "      <td>AA Batteries (4-pack)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>02/13/19 07:24</td>\n",
       "      <td>18 13th St, San Francisco, CA 94016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150504.0</td>\n",
       "      <td>27in 4K Gaming Monitor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>389.99</td>\n",
       "      <td>02/18/19 09:46</td>\n",
       "      <td>52 6th St, New York City, NY 10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150505.0</td>\n",
       "      <td>Lightning Charging Cable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>02/02/19 16:47</td>\n",
       "      <td>129 Cherry St, Atlanta, GA 30301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150506.0</td>\n",
       "      <td>AA Batteries (4-pack)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>02/28/19 20:32</td>\n",
       "      <td>548 Lincoln St, Seattle, WA 98101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order ID                   Product  Quantity Ordered  Price Each  \\\n",
       "0  150502.0                    iPhone               1.0      700.00   \n",
       "1  150503.0     AA Batteries (4-pack)               1.0        3.84   \n",
       "2  150504.0    27in 4K Gaming Monitor               1.0      389.99   \n",
       "3  150505.0  Lightning Charging Cable               1.0       14.95   \n",
       "4  150506.0     AA Batteries (4-pack)               2.0        3.84   \n",
       "\n",
       "       Order Date                     Purchase Address  \n",
       "0  02/18/19 01:35    866 Spruce St, Portland, ME 04101  \n",
       "1  02/13/19 07:24  18 13th St, San Francisco, CA 94016  \n",
       "2  02/18/19 09:46   52 6th St, New York City, NY 10001  \n",
       "3  02/02/19 16:47     129 Cherry St, Atlanta, GA 30301  \n",
       "4  02/28/19 20:32    548 Lincoln St, Seattle, WA 98101  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity Ordered</th>\n",
       "      <th>Price Each</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Purchase Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150502.0</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>700.00</td>\n",
       "      <td>02/18/19 01:35</td>\n",
       "      <td>ME 04101</td>\n",
       "      <td>866 Spruce St</td>\n",
       "      <td>Portland, ME 04101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150503.0</td>\n",
       "      <td>AA Batteries (4-pack)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>02/13/19 07:24</td>\n",
       "      <td>CA 94016</td>\n",
       "      <td>18 13th St</td>\n",
       "      <td>San Francisco, CA 94016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150504.0</td>\n",
       "      <td>27in 4K Gaming Monitor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>389.99</td>\n",
       "      <td>02/18/19 09:46</td>\n",
       "      <td>NY 10001</td>\n",
       "      <td>52 6th St</td>\n",
       "      <td>New York City, NY 10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150505.0</td>\n",
       "      <td>Lightning Charging Cable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>02/02/19 16:47</td>\n",
       "      <td>GA 30301</td>\n",
       "      <td>129 Cherry St</td>\n",
       "      <td>Atlanta, GA 30301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150506.0</td>\n",
       "      <td>AA Batteries (4-pack)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>02/28/19 20:32</td>\n",
       "      <td>WA 98101</td>\n",
       "      <td>548 Lincoln St</td>\n",
       "      <td>Seattle, WA 98101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order ID                   Product  Quantity Ordered  Price Each  \\\n",
       "0  150502.0                    iPhone               1.0      700.00   \n",
       "1  150503.0     AA Batteries (4-pack)               1.0        3.84   \n",
       "2  150504.0    27in 4K Gaming Monitor               1.0      389.99   \n",
       "3  150505.0  Lightning Charging Cable               1.0       14.95   \n",
       "4  150506.0     AA Batteries (4-pack)               2.0        3.84   \n",
       "\n",
       "       Order Date Purchase Address            City                     State  \n",
       "0  02/18/19 01:35         ME 04101   866 Spruce St        Portland, ME 04101  \n",
       "1  02/13/19 07:24         CA 94016      18 13th St   San Francisco, CA 94016  \n",
       "2  02/18/19 09:46         NY 10001       52 6th St   New York City, NY 10001  \n",
       "3  02/02/19 16:47         GA 30301   129 Cherry St         Atlanta, GA 30301  \n",
       "4  02/28/19 20:32         WA 98101  548 Lincoln St         Seattle, WA 98101  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_capitalize = Cleaning.split_rows_string(df1, col=\"Purchase Address\", new_cols=[\"City\", \"State\",], delete_col=False)\n",
    "df_capitalize.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'erro' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43merro\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'erro' is not defined"
     ]
    }
   ],
   "source": [
    "erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   sex       891 non-null    object \n",
      " 1   age       714 non-null    float64\n",
      " 2   sibsp     891 non-null    int64  \n",
      " 3   parch     891 non-null    int64  \n",
      " 4   fare      891 non-null    float64\n",
      " 5   embarked  889 non-null    object \n",
      " 6   class     891 non-null    object \n",
      " 7   who       891 non-null    object \n",
      " 8   alone     891 non-null    bool   \n",
      " 9   survived  891 non-null    int64  \n",
      "dtypes: bool(1), float64(2), int64(3), object(4)\n",
      "memory usage: 63.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# self.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   Gender               891 non-null    category\n",
      " 1   Age                  714 non-null    float64 \n",
      " 2   Siblings_on_Board    891 non-null    int8    \n",
      " 3   Parents_on_Board     891 non-null    int8    \n",
      " 4   Ticket_Price         891 non-null    float64 \n",
      " 5   Port_of_Embarkation  889 non-null    category\n",
      " 6   Class                891 non-null    category\n",
      " 7   Adult/Child          891 non-null    category\n",
      " 8   Alone                891 non-null    bool    \n",
      " 9   Survived             891 non-null    int64   \n",
      "dtypes: bool(1), category(4), float64(2), int64(1), int8(2)\n",
      "memory usage: 27.6 KB\n"
     ]
    }
   ],
   "source": [
    "# teste = File.read_file(\"./Titanic_Cleaned.parquet\")\n",
    "# teste.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25</td>\n",
       "      <td>Female</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emma</td>\n",
       "      <td>45</td>\n",
       "      <td>Female</td>\n",
       "      <td>Phoenix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age  Gender         City\n",
       "0    Alice   25  Female     New York\n",
       "1      Bob   30    Male  Los Angeles\n",
       "2  Charlie   35    Male      Chicago\n",
       "3    David   40    Male      Houston\n",
       "4     Emma   45  Female      Phoenix"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Criar um DataFrame de exemplo\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'],\n",
    "    'Age': [25, 30, 35, 40, 45],\n",
    "    'Gender': ['Female', 'Male', 'Male', 'Male', 'Female'],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>30</td>\n",
       "      <td>Male</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age Gender         City\n",
       "1      Bob   30   Male  Los Angeles\n",
       "2  Charlie   35   Male      Chicago"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conditions for filtering\n",
    "conditions = [\n",
    "    df['Age'] <= 35,\n",
    "    df['Gender'] == 'Male'\n",
    "]\n",
    "df_find = Statistics.find(df, conditions)\n",
    "df_find.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25</td>\n",
       "      <td>Female</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Male</td>\n",
       "      <td>Los Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emma</td>\n",
       "      <td>45</td>\n",
       "      <td>Female</td>\n",
       "      <td>Phoenix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name      Age  Gender         City\n",
       "0    Alice       25  Female     New York\n",
       "1      Bob  Unknown    Male  Los Angeles\n",
       "2  Charlie  Unknown    Male      Chicago\n",
       "3    David       40    Male      Houston\n",
       "4     Emma       45  Female      Phoenix"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_replaced = Statistics.find_replace(df, conditions, ('Age', 'Unknown'))\n",
    "df_replaced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>25</td>\n",
       "      <td>Female</td>\n",
       "      <td>New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>David</td>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emma</td>\n",
       "      <td>45</td>\n",
       "      <td>Female</td>\n",
       "      <td>Phoenix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name Age  Gender      City\n",
       "0  Alice  25  Female  New York\n",
       "3  David  40    Male   Houston\n",
       "4   Emma  45  Female   Phoenix"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_deleted = Statistics.find_delete(df, conditions)\n",
    "# df_deleted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best dtype for sex is category\n",
      "But consider changing it to bool, has you have 2 unique values so you can map the numbers to be True or False\n",
      "The best dtype for age is float16\n",
      "The best dtype for sibsp is int8\n",
      "The best dtype for parch is int8\n",
      "The best dtype for fare is float16\n",
      "The best dtype for embarked is category\n",
      "The best dtype for class is category\n",
      "The best dtype for who is category\n",
      "The best dtype for alone is bool\n",
      "The best dtype for survived is int8\n",
      "But consider changing it to bool, has you have 2 unique values so you can map the numbers to be True or False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>alone</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sex   age  sibsp  parch     fare embarked   class    who  alone  \\\n",
       "0      male  22.0      1      0   7.2500        S   Third    man  False   \n",
       "1    female  38.0      1      0  71.2833        C   First  woman  False   \n",
       "2    female  26.0      0      0   7.9250        S   Third  woman   True   \n",
       "3    female  35.0      1      0  53.1000        S   First  woman  False   \n",
       "4      male  35.0      0      0   8.0500        S   Third    man   True   \n",
       "..      ...   ...    ...    ...      ...      ...     ...    ...    ...   \n",
       "886    male  27.0      0      0  13.0000        S  Second    man   True   \n",
       "887  female  19.0      0      0  30.0000        S   First  woman   True   \n",
       "888  female   NaN      1      2  23.4500        S   Third  woman  False   \n",
       "889    male  26.0      0      0  30.0000        C   First    man   True   \n",
       "890    male  32.0      0      0   7.7500        Q   Third    man   True   \n",
       "\n",
       "     survived  \n",
       "0           0  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           0  \n",
       "..        ...  \n",
       "886         0  \n",
       "887         1  \n",
       "888         0  \n",
       "889         1  \n",
       "890         0  \n",
       "\n",
       "[891 rows x 10 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistics.get_best_dtypes(self, output=True, convert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gender': '0.0%',\n",
       " 'Age': '19.87%',\n",
       " 'Siblings_on_Board': '0.0%',\n",
       " 'Parents_on_Board': '0.0%',\n",
       " 'Ticket_Price': '0.0%',\n",
       " 'Port_of_Embarkation': '0.22%',\n",
       " 'Class': '0.0%',\n",
       " 'Adult/Child': '0.0%',\n",
       " 'Alone': '0.0%',\n",
       " 'Survived': '0.0%'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statistics.get_null_percentage(teste, get_dict=True, output=False, get_total=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'variables'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30978/2289734439.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_netCDF_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_30978/3187069235.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, variables, attributes)\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mattributes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"     {key}: {value}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStatistics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvar_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                 \u001b[0mcoord_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_30978/3815665975.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mvariables\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \"\"\"\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'variables'"
     ]
    }
   ],
   "source": [
    "# Metadata.read_netCDF_metadata(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_nulls_count(teste1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Creating a sample DataFrame\n",
    "# data = {\n",
    "#     'col1': ['apple, pie', 'banana! split', 'cherry? cake'],\n",
    "#     'col2': ['ice-cream', 'chocolate? cake', 'strawberry! shortcake']\n",
    "# }\n",
    "\n",
    "# teste = pd.DataFrame(data)\n",
    "# teste.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self = pd.read_csv(\"./Titanic.csv\")\n",
    "# condition = self[\"sex\"] == \"female\"\n",
    "# conditions = [condition]\n",
    "# teste = find_delete(self, conditions)\n",
    "# teste[\"sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self = pd.read_csv(\"./Titanic.csv\")\n",
    "# condition = self[\"sex\"] == \"female\"\n",
    "# conditions = [condition]\n",
    "# replace = [\"survived\", 1]\n",
    "# teste = replace.values()\n",
    "# teste\n",
    "# teste = find_replace(self, conditions, replace)\n",
    "# teste4 = find(teste, conditions)\n",
    "# teste4[\"survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self = pd.read_csv(\"./Titanic.csv\")\n",
    "# teste2 = find(self, [self[\"sex\"] == \"female\"])\n",
    "# self.loc[teste2.index, \"survived\"] = 0\n",
    "# teste3 = find(self, [self[\"sex\"] == \"female\"])\n",
    "# teste3[\"survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# condition = self[\"sex\"] == \"female\"\n",
    "# conditions = [condition]\n",
    "# replace = [self[\"survived\"], 1]\n",
    "# teste = replace.values()\n",
    "# teste\n",
    "# teste = find_replace(self, conditions, replace)\n",
    "# teste.head()\n",
    "# teste1 = find(teste, conditions)\n",
    "# teste1[\"survived\"].value_counts()\n",
    "# adw = find(teste, conditions)\n",
    "# teste.head()\n",
    "# df[\"female\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teste = remove_rows_character(teste, characters=[\"-\", \"?\", \"!\", \" \", \",\"], add_blankspace=True)\n",
    "# teste.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1[\"Product\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_nulls_count(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dtype(df1, \"Product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = get_best_dtypes(df1, convert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = remove_rows_with_missing_values(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_col_null_count(df1, [\"Purchase Address\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Quantity Ordered</th>\n",
       "      <th>Price Each</th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Purchase Address</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150502.0</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>700.00</td>\n",
       "      <td>02/18/19 01:35</td>\n",
       "      <td>866 Spruce St, Portland, ME 04101</td>\n",
       "      <td>866 Spruce St</td>\n",
       "      <td>Portland, ME 04101</td>\n",
       "      <td>ME 04101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150503.0</td>\n",
       "      <td>AA Batteries (4-pack)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>02/13/19 07:24</td>\n",
       "      <td>18 13th St, San Francisco, CA 94016</td>\n",
       "      <td>18 13th St</td>\n",
       "      <td>San Francisco, CA 94016</td>\n",
       "      <td>CA 94016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150504.0</td>\n",
       "      <td>27in 4K Gaming Monitor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>389.99</td>\n",
       "      <td>02/18/19 09:46</td>\n",
       "      <td>52 6th St, New York City, NY 10001</td>\n",
       "      <td>52 6th St</td>\n",
       "      <td>New York City, NY 10001</td>\n",
       "      <td>NY 10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150505.0</td>\n",
       "      <td>Lightning Charging Cable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>02/02/19 16:47</td>\n",
       "      <td>129 Cherry St, Atlanta, GA 30301</td>\n",
       "      <td>129 Cherry St</td>\n",
       "      <td>Atlanta, GA 30301</td>\n",
       "      <td>GA 30301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150506.0</td>\n",
       "      <td>AA Batteries (4-pack)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>02/28/19 20:32</td>\n",
       "      <td>548 Lincoln St, Seattle, WA 98101</td>\n",
       "      <td>548 Lincoln St</td>\n",
       "      <td>Seattle, WA 98101</td>\n",
       "      <td>WA 98101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372985</th>\n",
       "      <td>295660.0</td>\n",
       "      <td>AAA Batteries (4-pack)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>11/04/19 14:17</td>\n",
       "      <td>574 4th St, Los Angeles, CA 90001</td>\n",
       "      <td>574 4th St</td>\n",
       "      <td>Los Angeles, CA 90001</td>\n",
       "      <td>CA 90001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372986</th>\n",
       "      <td>295661.0</td>\n",
       "      <td>USB-C Charging Cable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.95</td>\n",
       "      <td>11/23/19 07:22</td>\n",
       "      <td>359 1st St, Austin, TX 73301</td>\n",
       "      <td>359 1st St</td>\n",
       "      <td>Austin, TX 73301</td>\n",
       "      <td>TX 73301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372987</th>\n",
       "      <td>295662.0</td>\n",
       "      <td>Lightning Charging Cable</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.95</td>\n",
       "      <td>11/13/19 16:12</td>\n",
       "      <td>900 10th St, Boston, MA 02215</td>\n",
       "      <td>900 10th St</td>\n",
       "      <td>Boston, MA 02215</td>\n",
       "      <td>MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372988</th>\n",
       "      <td>295663.0</td>\n",
       "      <td>AAA Batteries (4-pack)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>11/17/19 17:08</td>\n",
       "      <td>592 Sunset St, Boston, MA 02215</td>\n",
       "      <td>592 Sunset St</td>\n",
       "      <td>Boston, MA 02215</td>\n",
       "      <td>MA 02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372989</th>\n",
       "      <td>295664.0</td>\n",
       "      <td>Google Phone</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600.00</td>\n",
       "      <td>11/17/19 16:13</td>\n",
       "      <td>428 Jackson St, Boston, MA 02215</td>\n",
       "      <td>428 Jackson St</td>\n",
       "      <td>Boston, MA 02215</td>\n",
       "      <td>MA 02215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372990 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Order ID                   Product  Quantity Ordered  Price Each  \\\n",
       "0       150502.0                    iPhone               1.0      700.00   \n",
       "1       150503.0     AA Batteries (4-pack)               1.0        3.84   \n",
       "2       150504.0    27in 4K Gaming Monitor               1.0      389.99   \n",
       "3       150505.0  Lightning Charging Cable               1.0       14.95   \n",
       "4       150506.0     AA Batteries (4-pack)               2.0        3.84   \n",
       "...          ...                       ...               ...         ...   \n",
       "372985  295660.0    AAA Batteries (4-pack)               2.0        2.99   \n",
       "372986  295661.0      USB-C Charging Cable               1.0       11.95   \n",
       "372987  295662.0  Lightning Charging Cable               1.0       14.95   \n",
       "372988  295663.0    AAA Batteries (4-pack)               1.0        2.99   \n",
       "372989  295664.0              Google Phone               1.0      600.00   \n",
       "\n",
       "            Order Date                     Purchase Address         Address  \\\n",
       "0       02/18/19 01:35    866 Spruce St, Portland, ME 04101   866 Spruce St   \n",
       "1       02/13/19 07:24  18 13th St, San Francisco, CA 94016      18 13th St   \n",
       "2       02/18/19 09:46   52 6th St, New York City, NY 10001       52 6th St   \n",
       "3       02/02/19 16:47     129 Cherry St, Atlanta, GA 30301   129 Cherry St   \n",
       "4       02/28/19 20:32    548 Lincoln St, Seattle, WA 98101  548 Lincoln St   \n",
       "...                ...                                  ...             ...   \n",
       "372985  11/04/19 14:17    574 4th St, Los Angeles, CA 90001      574 4th St   \n",
       "372986  11/23/19 07:22         359 1st St, Austin, TX 73301      359 1st St   \n",
       "372987  11/13/19 16:12        900 10th St, Boston, MA 02215     900 10th St   \n",
       "372988  11/17/19 17:08      592 Sunset St, Boston, MA 02215   592 Sunset St   \n",
       "372989  11/17/19 16:13     428 Jackson St, Boston, MA 02215  428 Jackson St   \n",
       "\n",
       "                            City      State  \n",
       "0             Portland, ME 04101   ME 04101  \n",
       "1        San Francisco, CA 94016   CA 94016  \n",
       "2        New York City, NY 10001   NY 10001  \n",
       "3              Atlanta, GA 30301   GA 30301  \n",
       "4              Seattle, WA 98101   WA 98101  \n",
       "...                          ...        ...  \n",
       "372985     Los Angeles, CA 90001   CA 90001  \n",
       "372986          Austin, TX 73301   TX 73301  \n",
       "372987          Boston, MA 02215   MA 02215  \n",
       "372988          Boston, MA 02215   MA 02215  \n",
       "372989          Boston, MA 02215   MA 02215  \n",
       "\n",
       "[372990 rows x 9 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cleaning.split_rows_string(df1, \"Purchase Address\", [\"Address\", \"City\", \"State\"], delete_col=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygmtsar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
