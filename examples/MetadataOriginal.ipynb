{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Reading and Writing Metadata**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_variables(self):\n",
    "    variables = list(self.variables.keys())\n",
    "    print(variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NetCDf**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Libraries Needed**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's required to use `pip install xarray` or `conda install xarray`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the Data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abigor/.local/lib/python3.10/site-packages/xarray/backends/plugins.py:80: RuntimeWarning: Engine 'rasterio' loading failed:\n",
      "No module named 'click'\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Specify the file name\n",
    "file = \"example.nc\"\n",
    "# Open the NetCDF dataset\n",
    "nc_dataset = xr.open_dataset(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reading Metadata**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Knowing the Variables that are on The File**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lat', 'lon', 'los', 'pair', 'ref', 'rep']\n"
     ]
    }
   ],
   "source": [
    "# Get a list of variable names in the dataset\n",
    "variables = list(nc_dataset.variables.keys())\n",
    "# Print the list of variable names\n",
    "print(variables)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Variables**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Used Attributes in the **Variable's Metadata**:\n",
    "\n",
    "- **units**: Specifies the units of the variable.\n",
    "- **long_name**: Provides a full name of the variable.\n",
    "- **standard_name/short_name**: Follows standard naming conventions for interoperability.\n",
    "- **valid_min** and **valid_max**: Define the valid value range.\n",
    "- **missing_value** or **fill_value**: Indicates missing or undefined data.\n",
    "- **scale_factor** and **add_offset**: Scaling parameters for physical units.\n",
    "- **coordinates**: Specifies associated coordinates.\n",
    "- **axis**: Identifies the variable's varying axis (e.g., 'X', 'Y', 'Z', 'time').\n",
    "- **description**: Provides a detailed or additional explanation about the variable\n",
    "\n",
    "_Note: It's not obligatory to use all of these attributes, but this are the most commonly to seen._\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting The Variables Metadata**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Lat\n",
      "   Values:  [-7.52       -7.51916667 -7.51833333 ... -5.56833333 -5.5675\n",
      " -5.56666667]\n",
      "   Attributes:  {'Units': 'Degrees', 'Long_Name': 'Latitude', 'Short_Name': 'lat', 'Valid_min': '-90', 'Valid_Max': '90', 'missing_Value': '-9999', 'Fill_Value': '-9999', 'Scale_Factor': '1.0', 'add_offset': '0.0', 'Coordinates': 'longitude', 'Axis': 'Y', 'Description': 'The angular distance between the north and south from the equator'}\n",
      "\n",
      "Variable: Lon\n",
      "   No metadata was found for this variable.\n",
      "\n",
      "Variable: Pair\n",
      "   No metadata was found for this variable.\n",
      "\n",
      "Variable: Ref\n",
      "   No metadata was found for this variable.\n",
      "\n",
      "Variable: Rep\n",
      "   No metadata was found for this variable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over variables in the dataset\n",
    "for coord_name, coord_var in nc_dataset.coords.items():\n",
    "    coord_name = coord_name.title()  # Improve readability\n",
    "    print(\"Variable:\", coord_name)\n",
    "    if not coord_var.attrs:\n",
    "        print(\"   No metadata was found for this variable.\")\n",
    "    else:\n",
    "        print(\"   Values: \", coord_var.values)  # Print the values of the variable\n",
    "        print(\n",
    "            \"   Attributes: \", coord_var.attrs\n",
    "        )  # Print the attributes of the variable\n",
    "    print()  # Give some space to improve readability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Another possible way to visualize the metadata is**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Lat\n",
      "   No metadata was found for this variable.\n",
      "\n",
      "Variable: Lon\n",
      "   No metadata was found for this variable.\n",
      "\n",
      "Variable: Pair\n",
      "   No metadata was found for this variable.\n",
      "\n",
      "Variable: Ref\n",
      "   No metadata was found for this variable.\n",
      "\n",
      "Variable: Rep\n",
      "   No metadata was found for this variable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over the variables in the dataset\n",
    "for coord_name, coord_var in nc_dataset.coords.items():\n",
    "    coord_name = coord_name.title()  # Improve readability\n",
    "    print(\"Variable:\", coord_name)\n",
    "    if not coord_var.attrs:\n",
    "        print(\"   No metadata was found for this variable.\")\n",
    "    else:\n",
    "        print(\n",
    "            \"   \", coord_var\n",
    "        )  # Print the coordinate variable object, which includes values and attributes\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My preference to visualize the metadata is in way the first code displays it, because the second one sometimes will truncate the output and because of that we can't visualize all metadata. That's way I prefer the first one, but both work to visualize the metadata in the variable.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Print The Values of specific Variable**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will display the latitude values along with the associated attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(nc_dataset['var_name'] )#var_name = Name of The Variable that you want"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Global Attributes**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global metadata refers to attributes that apply to the entire dataset. These attributes will provide information about the whole dataset.\n",
    "Most Used **Global Attributes**:\n",
    "\n",
    "- **title**: A title or brief description of the dataset.\n",
    "- **institution**: The institution responsible for the dataset.\n",
    "- **source**: Describes the data source or generation method.\n",
    "- **history**: Records modifications or processing steps applied to the dataset.\n",
    "- **references**: Provides references to relevant publications or resources.\n",
    "- **Conventions**: Specifies the formatting conventions of the NetCDF file.\n",
    "- **creator/author**: Identifies the creator of the dataset.\n",
    "- **project**: Describes the associated project or research program.\n",
    "- **license**: Specifies the usage terms for the dataset.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting the Global Attributes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Global Attributes were found.\n"
     ]
    }
   ],
   "source": [
    "# Get the global attributes of the dataset\n",
    "global_attrs = nc_dataset.attrs\n",
    "# Check if the global attributes are present\n",
    "if not global_attrs:\n",
    "    print(\"No Global Attributes were found.\")\n",
    "else:\n",
    "    # If there are it will loop over each global attribute and print it's name and value\n",
    "    for attr_name, attr_value in global_attrs.items():\n",
    "        attr_name = attr_name.title()  # Improve readability\n",
    "        print(attr_name, \":\", attr_value)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Writing Metadata**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Variables**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes that will be used:\n",
    "\n",
    "- **units**: Specifies the units of the variable.\n",
    "- **long_name**: Provides a full name of the variable.\n",
    "- **standard_name/short_name**: Follows standard naming conventions for interoperability.\n",
    "- **valid_min** and **valid_max**: Define the valid value range.\n",
    "- **missing_value** or **fill_value**: Indicates missing or undefined data.\n",
    "- **scale_factor** and **add_offset**: Scaling parameters for physical units.\n",
    "- **coordinates**: Specifies associated coordinates.\n",
    "- **axis**: Identifies the variable's varying axis (e.g., 'X', 'Y', 'Z', 'time').\n",
    "- **description**: Provides a detailed or additional explanation about the variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'lat' (lat: 2345)>\n",
      "array([-7.52    , -7.519167, -7.518333, ..., -5.568333, -5.5675  , -5.566667])\n",
      "Coordinates:\n",
      "  * lat      (lat) float64 -7.52 -7.519 -7.518 -7.518 ... -5.568 -5.567 -5.567\n",
      "    pair     object ...\n",
      "    ref      object ...\n",
      "    rep      object ...\n",
      "Attributes:\n",
      "    Units:          Degrees\n",
      "    Long_Name:      Latitude\n",
      "    Short_Name:     lat\n",
      "    Valid_min:      -90\n",
      "    Valid_Max:      90\n",
      "    missing_Value:  -9999\n",
      "    Fill_Value:     -9999\n",
      "    Scale_Factor:   1.0\n",
      "    add_offset:     0.0\n",
      "    Coordinates:    longitude\n",
      "    Axis:           Y\n",
      "    Description:    The angular distance between the north and south from the...\n"
     ]
    }
   ],
   "source": [
    "# Dummy Data for the attributes in the latitude variable\n",
    "nc_dataset[\"lat\"].attrs[\"Units\"] = \"Degrees\"\n",
    "nc_dataset[\"lat\"].attrs[\"Long_Name\"] = \"Latitude\"\n",
    "nc_dataset[\"lat\"].attrs[\"Short_Name\"] = \"lat\"\n",
    "nc_dataset[\"lat\"].attrs[\"Valid_min\"] = \"-90\"\n",
    "nc_dataset[\"lat\"].attrs[\"Valid_Max\"] = \"90\"\n",
    "nc_dataset[\"lat\"].attrs[\"missing_Value\"] = \"-9999\"\n",
    "nc_dataset[\"lat\"].attrs[\"Fill_Value\"] = \"-9999\"\n",
    "nc_dataset[\"lat\"].attrs[\"Scale_Factor\"] = \"1.0\"\n",
    "nc_dataset[\"lat\"].attrs[\"add_offset\"] = \"0.0\"\n",
    "nc_dataset[\"lat\"].attrs[\"Coordinates\"] = \"longitude\"\n",
    "nc_dataset[\"lat\"].attrs[\"Axis\"] = \"Y\"\n",
    "nc_dataset[\"lat\"].attrs[\n",
    "    \"Description\"\n",
    "] = \"The angular distance between the north and south from the equator\"\n",
    "# Print the updated latitude metadata\n",
    "print(nc_dataset[\"lat\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Global Attributes**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributes that will be used:\n",
    "\n",
    "- **title**: A title or brief description of the dataset.\n",
    "- **institution**: The institution responsible for the dataset.\n",
    "- **source**: Describes the data source or generation method.\n",
    "- **history**: Records modifications or processing steps applied to the dataset.\n",
    "- **references**: Provides references to relevant publications or resources.\n",
    "- **Conventions**: Specifies the formatting conventions of the NetCDF file.\n",
    "- **creator/author**: Identifies the creator of the dataset.\n",
    "- **project**: Describes the associated project or research program.\n",
    "- **license**: Specifies the usage terms for the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (lat: 2345, lon: 3062)\n",
      "Coordinates:\n",
      "  * lat      (lat) float64 -7.52 -7.519 -7.518 -7.518 ... -5.568 -5.567 -5.567\n",
      "  * lon      (lon) float64 -79.5 -79.49 -79.49 -79.49 ... -76.95 -76.95 -76.94\n",
      "    pair     object ...\n",
      "    ref      object ...\n",
      "    rep      object ...\n",
      "Data variables:\n",
      "    los      (lat, lon) float32 ...\n",
      "Attributes:\n",
      "    Title:           Example Dataset\n",
      "    Institution:     Example Institution\n",
      "    Source:          Trust Me\n",
      "    History:         Created on 33th of February of 2011\n",
      "    References:      Example References\n",
      "    Conventions:     CF-1.8\n",
      "    Creator_Author:  Asato Asato\n",
      "    Project:         Example Project\n",
      "    Description:     Example of the Example in a Example Dataset for Example ...\n"
     ]
    }
   ],
   "source": [
    "# Dummy data for global attributes\n",
    "nc_dataset.attrs[\"Title\"] = \"Example Dataset\"\n",
    "nc_dataset.attrs[\"Institution\"] = \"Example Institution\"\n",
    "nc_dataset.attrs[\"Source\"] = \"Trust Me\"\n",
    "nc_dataset.attrs[\"History\"] = \"Created on 33th of February of 2011\"\n",
    "nc_dataset.attrs[\"References\"] = \"Example References\"\n",
    "nc_dataset.attrs[\"Conventions\"] = \"CF-1.8\"\n",
    "nc_dataset.attrs[\"Creator_Author\"] = \"Asato Asato\"\n",
    "nc_dataset.attrs[\"Project\"] = \"Example Project\"\n",
    "nc_dataset.attrs[\n",
    "    \"Description\"\n",
    "] = \"Example of the Example in a Example Dataset for Example purposes\"\n",
    "# Print the updated dataset\n",
    "print(nc_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Checking The Updated Version Of The Metadata**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Variables Metadata**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: Lat\n",
      "   Values:  [-7.52       -7.51916667 -7.51833333 ... -5.56833333 -5.5675\n",
      " -5.56666667]\n",
      "   Attributes:  {'Units': 'Degrees', 'Long_Name': 'Latitude', 'Short_Name': 'lat', 'Valid_min': '-90', 'Valid_Max': '90', 'missing_Value': '-9999', 'Fill_Value': '-9999', 'Scale_Factor': '1.0', 'add_offset': '0.0', 'Coordinates': 'longitude', 'Axis': 'Y', 'Description': 'The angular distance between the north and south from the equator'}\n",
      "\n",
      "Variable: Lon\n",
      "   No metadata was found for this variable.\n",
      "\n",
      "Variable: Pair\n",
      "   No metadata was found for this variable.\n",
      "\n",
      "Variable: Ref\n",
      "   No metadata was found for this variable.\n",
      "\n",
      "Variable: Rep\n",
      "   No metadata was found for this variable.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loop over variables in the dataset\n",
    "for coord_name, coord_var in nc_dataset.coords.items():\n",
    "    coord_name = coord_name.title()  # Improve readability\n",
    "    print(\"Variable:\", coord_name)\n",
    "    if not coord_var.attrs:\n",
    "        print(\"   No metadata was found for this variable.\")\n",
    "    else:\n",
    "        print(\"   Values: \", coord_var.values)  # Print the values of the variable\n",
    "        print(\n",
    "            \"   Attributes: \", coord_var.attrs\n",
    "        )  # Print the attributes of the variable\n",
    "    print()  # Give some space to improve readability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Global Attributes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title : Example Dataset\n",
      "\n",
      "Institution : Example Institution\n",
      "\n",
      "Source : Trust Me\n",
      "\n",
      "History : Created on 33th of February of 2011\n",
      "\n",
      "References : Example References\n",
      "\n",
      "Conventions : CF-1.8\n",
      "\n",
      "Creator_Author : Asato Asato\n",
      "\n",
      "Project : Example Project\n",
      "\n",
      "Description : Example of the Example in a Example Dataset for Example purposes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the global attributes of the dataset\n",
    "global_attrs = nc_dataset.attrs\n",
    "# Check if the global attributes are present\n",
    "if not global_attrs:\n",
    "    print(\"No Global Attributes were found.\")\n",
    "else:\n",
    "    # If there are it will loop over each global attribute and print it's name and value\n",
    "    for attr_name, attr_value in global_attrs.items():\n",
    "        attr_name = attr_name.title()  # Improve readability\n",
    "        print(attr_name, \":\", attr_value)\n",
    "        print()  # Give some space to improve readability"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saving The File**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_file = \"updated_example.nc\"\n",
    "nc_dataset.to_netcdf(new_file, format=\"netCDF4\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Parquet**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Libraries Needed**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's required to use `pip install pyarrow pandas` or `conda install pyarrow pandas`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the Data**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used df.info() to check the columns name which will be useful later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 10 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   Gender               891 non-null    category\n",
      " 1   Age                  714 non-null    float64 \n",
      " 2   Siblings_on_Board    891 non-null    int8    \n",
      " 3   Parents_on_Board     891 non-null    int8    \n",
      " 4   Ticket_Price         891 non-null    float64 \n",
      " 5   Port_of_Embarkation  889 non-null    category\n",
      " 6   Class                891 non-null    category\n",
      " 7   Adult/Child          891 non-null    category\n",
      " 8   Alone                891 non-null    bool    \n",
      " 9   Survived             891 non-null    int64   \n",
      "dtypes: bool(1), category(4), float64(2), int64(1), int8(2)\n",
      "memory usage: 27.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Reading the Parquet file into a DataFrame\n",
    "df = pd.read_parquet(\"Titanic.parquet\")\n",
    "# Displaying information about the DataFrame\n",
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Converting a Pandas DataFrame To a Pyarrow Table**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pa.Table.from_pandas(df)  # Converting the pandas DataFrame to a PyArrow Table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Writing The Metadata**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema for the PyArrow Table\n",
    "table_schema = pa.schema(\n",
    "    [\n",
    "        pa.field(\n",
    "            \"Gender\", \"string\", metadata={\"Description\": \"The passenger's Gender\"}\n",
    "        ),\n",
    "        pa.field(\n",
    "            \"Age\",\n",
    "            \"string\",\n",
    "            metadata={\"Description\": \"The passenger's Age\", \"Calculation\": \"No\"},\n",
    "        ),\n",
    "        pa.field(\n",
    "            \"Siblings_on_Board\",\n",
    "            \"int8\",\n",
    "            metadata={\n",
    "                \"Description\": \"Number of sibilings that the passenger had on board\",\n",
    "                \"Calculation\": \"No\",\n",
    "            },\n",
    "        ),\n",
    "        pa.field(\n",
    "            \"Parents_on_Board\",\n",
    "            \"int8\",\n",
    "            metadata={\n",
    "                \"Description\": \"Number of parents that the passenger had on board\",\n",
    "                \"Calculation\": \"No\",\n",
    "            },\n",
    "        ),\n",
    "        pa.field(\n",
    "            \"Ticket_Price\",\n",
    "            \"float64\",\n",
    "            metadata={\"Description\": \"Ticket's Price\", \"Calculation\": \"No\"},\n",
    "        ),\n",
    "        pa.field(\n",
    "            \"Port_of_Embarkation\",\n",
    "            \"string\",\n",
    "            metadata={\"Description\": \"The port were the passenger embarked\"},\n",
    "        ),\n",
    "        pa.field(\n",
    "            \"Class\",\n",
    "            \"string\",\n",
    "            metadata={\"Description\": \"The passenger's class on the ship\"},\n",
    "        ),\n",
    "        pa.field(\n",
    "            \"Adult/Child\",\n",
    "            \"string\",\n",
    "            metadata={\"Description\": \"If the passenger is child or not\"},\n",
    "        ),\n",
    "        pa.field(\n",
    "            \"Alone\",\n",
    "            \"bool\",\n",
    "            metadata={\"Description\": \"If the passenger is travelling alone or not\"},\n",
    "        ),\n",
    "        pa.field(\n",
    "            \"Survived\",\n",
    "            \"int64\",\n",
    "            metadata={\n",
    "                \"Description\": \"If the passenger survived or not\",\n",
    "                \"Calculation\": \"No\",\n",
    "            },\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The schema is defined with a list of pa.field() objects, where each field represents a column in the table. Each field specifies the column name, data type, and metadata.\n",
    "\n",
    "The metadata is defined as a dictionary within the metadata parameter of each field. It provides additional information about the column, such as descriptions or calculations.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_Some Notes:_**\n",
    "\n",
    "- _In the first two text fields(column name and data type) you need to write correctly the columns name and dtype. If you spell it wrong it will give a error._\n",
    "- _'Calculation: No' means if the values in that column were obtained by some calculation, this is normally described in column which the dtype is numerical_\n",
    "- _You can write as many metadata that you want but it needs to be saved as dict_\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Saving the new schema(metadata) into the Table**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table.cast(table_schema)  # Cast the PyArrow Table to the specified schema"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the Modifications**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender: string\n",
       "  -- field metadata --\n",
       "  Description: 'The passenger's Gender'\n",
       "Age: string\n",
       "  -- field metadata --\n",
       "  Description: 'The passenger's Age'\n",
       "  Calculation: 'No'\n",
       "Siblings_on_Board: int8\n",
       "  -- field metadata --\n",
       "  Description: 'Number of sibilings that the passenger had on board'\n",
       "  Calculation: 'No'\n",
       "Parents_on_Board: int8\n",
       "  -- field metadata --\n",
       "  Description: 'Number of parents that the passenger had on board'\n",
       "  Calculation: 'No'\n",
       "Ticket_Price: double\n",
       "  -- field metadata --\n",
       "  Description: 'Ticket's Price'\n",
       "  Calculation: 'No'\n",
       "Port_of_Embarkation: string\n",
       "  -- field metadata --\n",
       "  Description: 'The port were the passenger embarked'\n",
       "Class: string\n",
       "  -- field metadata --\n",
       "  Description: 'The passenger's class on the ship'\n",
       "Adult/Child: string\n",
       "  -- field metadata --\n",
       "  Description: 'If the passenger is child or not'\n",
       "Alone: bool\n",
       "  -- field metadata --\n",
       "  Description: 'If the passenger is travelling alone or not'\n",
       "Survived: int64\n",
       "  -- field metadata --\n",
       "  Description: 'If the passenger survived or not'\n",
       "  Calculation: 'No'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.schema  # Retrieve the schema of the PyArrow Table"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Saving The File**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the output file path and name\n",
    "output_file = \"updated_Titanic.parquet\"\n",
    "# Write the PyArrow Table to a Parquet file\n",
    "pq.write_table(table, output_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reading the Updated File**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender: string\n",
       "  -- field metadata --\n",
       "  Description: 'The passenger's Gender'\n",
       "Age: string\n",
       "  -- field metadata --\n",
       "  Description: 'The passenger's Age'\n",
       "  Calculation: 'No'\n",
       "Siblings_on_Board: int8\n",
       "  -- field metadata --\n",
       "  Description: 'Number of sibilings that the passenger had on board'\n",
       "  Calculation: 'No'\n",
       "Parents_on_Board: int8\n",
       "  -- field metadata --\n",
       "  Description: 'Number of parents that the passenger had on board'\n",
       "  Calculation: 'No'\n",
       "Ticket_Price: double\n",
       "  -- field metadata --\n",
       "  Description: 'Ticket's Price'\n",
       "  Calculation: 'No'\n",
       "Port_of_Embarkation: string\n",
       "  -- field metadata --\n",
       "  Description: 'The port were the passenger embarked'\n",
       "Class: string\n",
       "  -- field metadata --\n",
       "  Description: 'The passenger's class on the ship'\n",
       "Adult/Child: string\n",
       "  -- field metadata --\n",
       "  Description: 'If the passenger is child or not'\n",
       "Alone: bool\n",
       "  -- field metadata --\n",
       "  Description: 'If the passenger is travelling alone or not'\n",
       "Survived: int64\n",
       "  -- field metadata --\n",
       "  Description: 'If the passenger survived or not'\n",
       "  Calculation: 'No'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the updated Parquet file into a PyArrow Table\n",
    "updated_pq_dataset = pq.read_table(\"updated_Titanic.parquet\")\n",
    "# Retrieve the schema of the updated PyArrow Table\n",
    "updated_pq_dataset.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gender': Utf8,\n",
       " 'Age': Utf8,\n",
       " 'Siblings_on_Board': Int8,\n",
       " 'Parents_on_Board': Int8,\n",
       " 'Ticket_Price': Float64,\n",
       " 'Port_of_Embarkation': Utf8,\n",
       " 'Class': Utf8,\n",
       " 'Adult/Child': Utf8,\n",
       " 'Alone': Boolean,\n",
       " 'Survived': Int64}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "updated_pq_dataset = pl.read_parquet_schema(\"updated_Titanic.parquet\")\n",
    "updated_pq_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygmtsar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
