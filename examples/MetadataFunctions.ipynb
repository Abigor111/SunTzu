{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Metadata**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_file_variables(self):\n",
    "    variables = list(self.variables.keys())\n",
    "    print(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_variables(self):\n",
    "    variables = list(self.variables.keys())\n",
    "    return variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #noqa\n",
    "import polars as pl #noqa\n",
    "import xarray as xr #noqa\n",
    "def check_dataframe_type(self):\n",
    "    if isinstance(self, pd.DataFrame):\n",
    "        print(\"This is a Pandas DataFrame.\")\n",
    "    elif isinstance(self, pl.DataFrame):\n",
    "        print(\"This is a Polars DataFrame.\")\n",
    "    elif isinstance(self, xr.Dataset):\n",
    "        print(\"This is a xarray Dataset\")\n",
    "    else:\n",
    "        print(\"Unknown DataFrame/Dataset type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## netCDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_netCDF_metadata(self, variables=None, attributes=None):\n",
    "    \"\"\"\n",
    "    Get metadata for variables.\n",
    "\n",
    "    Args:\n",
    "        variables (list): List of variable names. If None, metadata for all variables will be retrieved.\n",
    "        attributes (list): List of attribute names. If None, all attributes will be retrieved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    def print_variable_metadata(var_name, var):\n",
    "        \"\"\"\n",
    "        Print metadata for a variable.\n",
    "\n",
    "        Args:\n",
    "            var_name (str): Name of the variable.\n",
    "            var (Variable): Variable object.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        print(f\"Variable: {var_name}\")\n",
    "        if not var.attrs:\n",
    "            if var.values is not None:\n",
    "                print(f\"   Values: {var.values}\")\n",
    "            else:\n",
    "                print(\"No values were found\")\n",
    "            print(\"   No attributes were found for this variable.\")\n",
    "        else:\n",
    "            print(f\" Values: {var.values}\")\n",
    "            print(\" Attributes:\")\n",
    "            for key, value in var.attrs.items():\n",
    "                if attributes is None or key in attributes:\n",
    "                    print(f\"   {key}: {value}\")\n",
    "\n",
    "    if variables is None:\n",
    "        variables = (key for key in self.coords.keys())\n",
    "    for var_name in variables:\n",
    "        try:\n",
    "            coord_var = self.coords[var_name]\n",
    "            print_variable_metadata(var_name, coord_var)\n",
    "        except (KeyError, AttributeError) as e:\n",
    "            print(f\"Error occurred while retrieving metadata for variable {var_name}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attrs(self):\n",
    "    return self.attrs\n",
    "\n",
    "def print_global_metadata(self, attributes=None):\n",
    "    \"\"\"\n",
    "    Print the global metadata attributes of the dataset.\n",
    "\n",
    "    Args:\n",
    "        attributes (list): List of attribute names to print. If None, all attributes will be printed.\n",
    "    \"\"\"\n",
    "    attrs = get_attrs(self)\n",
    "    if not attrs:\n",
    "        print(\"No Global Attributes were found.\")\n",
    "    else:\n",
    "        if attributes is None:\n",
    "            for attr_name, attr_value in attrs.items():\n",
    "                print(attr_name, \":\", attr_value)\n",
    "        else:\n",
    "            for attr_name, attr_value in attrs.items():\n",
    "                if attr_name in attributes:\n",
    "                    print(attr_name, \":\", attr_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import os.path\n",
    "def insert_netCDF_metadata_input(self, variables=None, attributes=None, new_file=False, filename=\"new_file.nc\",):\n",
    "    \"\"\"\n",
    "    This function prompts the user to input metadata for the specified variables in a netCDF file.\n",
    "    \n",
    "    Parameters:\n",
    "    - filename (str): Name of the netCDF file.\n",
    "    - variables (list): List of variable names. If None, all coordinate variables are used.\n",
    "    - attributes (list): List of attribute names. If None, default attributes are used.\n",
    "    - new_file (bool): If True, a new netCDF file is created. If False, the existing file is used.\n",
    "    \n",
    "    Raises:\n",
    "    - KeyError: If a variable was not found.\n",
    "    - FileExistsError: If the specified file already exists.\n",
    "    - ValueError: If the filename is invalid.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define default attributes if not provided\n",
    "    default_attributes = [\n",
    "        \"Units\", \"Long_Name\", \"Standard_Name/Short_Name\", \n",
    "        \"Valid_Min\", \"Valid_Max\", \"Missing_Value\", \n",
    "        \"Fill_Value\", \"Scale_Factor\", \"Add_Offset\", \n",
    "        \"Coordinates\", \"Axis\", \"Description\"\n",
    "    ]\n",
    "    if attributes is None:\n",
    "        attributes = default_attributes\n",
    "\n",
    "    if variables is None:\n",
    "        variables = (key for key in self.coords.keys())\n",
    "\n",
    "    for coord_name in variables:\n",
    "        try:\n",
    "            for attribute in attributes:\n",
    "                self[coord_name].attrs[attribute] = input(f\"{coord_name}: {attribute} - Enter value: \")\n",
    "        except KeyError as e:\n",
    "            raise KeyError(f\"Variable {coord_name} not found.\") from e\n",
    "    if new_file:\n",
    "        if not os.path.isfile(filename):\n",
    "            if pathlib.Path(filename).suffix == \".nc\":\n",
    "                write_netcdf_file(self, filename)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid filename. Please provide a valid filename.\")\n",
    "        else:\n",
    "            raise FileExistsError(f\"{filename} already exists. Please change it or delete it.\")\n",
    "\n",
    "def write_netcdf_file(self, filename):\n",
    "    \"\"\"\n",
    "    This function writes the netCDF file.\n",
    "    \n",
    "    Parameters:\n",
    "    - filename (str): Name of the netCDF file.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.isfile(filename):\n",
    "        self.to_netcdf(filename)\n",
    "    else:\n",
    "        print(f\"{filename} already exists. Please change it or delete it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "def insert_netCDF_metadata_dict(self, dictionary, variables=None, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Insert metadata into a netCDF file using a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - self: The netCDF object.\n",
    "    - dictionary: A dictionary containing the metadata to be inserted.\n",
    "    - filename: The name of the netCDF file to be created or modified.\n",
    "    - variables: A list of variables to insert the metadata into. If None, all variables will be used.\n",
    "    - new_file: If True, a new file will be created. If False, the metadata will be inserted into an existing file.\n",
    "\n",
    "    Raises:\n",
    "    - ValueError: If dictionary is None.\n",
    "    - AttributeError: If dictionary is not a dictionary.\n",
    "    - FileExistsError: If the specified file already exists.\n",
    "    - ValueError: If the filename is invalid.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    if dictionary is None:\n",
    "        raise ValueError(\"Please provide a dictionary.\")\n",
    "    if variables is None:\n",
    "        variables = (key for key in self.coords.keys())\n",
    "    if isinstance(dictionary, dict):\n",
    "        for var in variables:\n",
    "            for key, value in dictionary.items():\n",
    "                self[var].attrs[key] = value\n",
    "    else:\n",
    "        raise AttributeError(f\"{dictionary} is not a dictionary.\")\n",
    "    if new_file:\n",
    "        if not os.path.isfile(filename):\n",
    "            if pathlib.Path(filename).suffix == \".nc\":\n",
    "                write_netcdf_file(self, filename)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid filename. Please provide a valid filename.\")\n",
    "        else:\n",
    "            raise FileExistsError(f\"{filename} already exists. Please change it or delete it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonschema\n",
    "from jsonschema.exceptions import ValidationError \n",
    "\n",
    "def insert_netCDF_metadata_json(self, json_file, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Inserts metadata from a JSON file into a netCDF file.\n",
    "\n",
    "    Args:\n",
    "        self: The instance of the class that the function belongs to.\n",
    "        json_file (str): The path to the JSON file containing the metadata.\n",
    "        new_file (bool, optional): A boolean flag indicating whether a new netCDF file should be created. Defaults to False.\n",
    "        filename (str, optional): The name of the new netCDF file. Defaults to \"new_file.nc\".\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the specified filename already exists.\n",
    "\n",
    "    Returns:\n",
    "        None: The function modifies the attributes of the netCDF file directly.\n",
    "    \"\"\"\n",
    "    schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"patternProperties\": {\n",
    "        \".*\": {\n",
    "            \"type\": \"object\",\n",
    "\n",
    "\n",
    "    # Existing code continues below\n",
    "        \"patternProperties\": {\n",
    "            \".*\": {\n",
    "                \"type\": \"string\",\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"additionalProperties\": False\n",
    "    }   \n",
    "}   \n",
    "    try:\n",
    "        with open(json_file, 'r') as file:\n",
    "            metadata = json.load(file)\n",
    "    except IOError:\n",
    "        raise IOError(\"Error opening JSON file. Please check if the file exists or if there are any permission issues.\")\n",
    "    try:\n",
    "        # Validate JSON against schema\n",
    "        jsonschema.validate(instance=metadata, schema=schema)\n",
    "    except ValidationError as e:\n",
    "        raise ValidationError(str(e))\n",
    "    for var, attributes in metadata.items():\n",
    "        for attr, value in attributes.items():\n",
    "            self[var].attrs[attr] = value    \n",
    "    if new_file:\n",
    "        if not os.path.isfile(filename):\n",
    "            if pathlib.Path(filename).suffix == \".nc\":\n",
    "                write_netcdf_file(self, filename)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid filename. Please provide a valid filename.\")\n",
    "        else:\n",
    "            raise FileExistsError(f\"{filename} already exists. Please change it or delete it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_metadata(self, via=\"input\", **kwargs):\n",
    "    \"\"\"\n",
    "    Insert metadata into the netCDF file.\n",
    "\n",
    "    Parameters:\n",
    "        via (str, optional): The method of providing metadata. Can be \"dict\", \"json\", or \"input\". Defaults to \"input\".\n",
    "        **kwargs: Additional keyword arguments for the specific method.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If `via` is not a valid metadata input.\n",
    "    \"\"\"\n",
    "    via_lower = via.lower()\n",
    "    try:\n",
    "        if via_lower == \"dict\":\n",
    "            insert_netCDF_metadata_dict(self, **kwargs)\n",
    "        elif via_lower == \"json\":\n",
    "            insert_netCDF_metadata_json(self, **kwargs)\n",
    "        elif via_lower == \"input\":\n",
    "            insert_netCDF_metadata_input(self, **kwargs)\n",
    "        else:\n",
    "            raise ValueError(f\"{via} is not a valid metadata input.\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error inserting netCDF metadata: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_netCDF_global_metadata_input(self, attributes=None):\n",
    "    \"\"\"\n",
    "    Insert global netCDF metadata attributes.\n",
    "\n",
    "    Args:\n",
    "        attributes (list): List of attributes to insert. If None, default attributes will be used.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    default_attributes = [\n",
    "        \"Title\", \"Institution\", \"Source\",\n",
    "        \"History\", \"References\", \"Conventions\",\n",
    "        \"Creator_Author\", \"Project\", \"Description\"\n",
    "    ]\n",
    "    if attributes is None:\n",
    "        attributes = default_attributes\n",
    "    try:\n",
    "        if not isinstance(attributes, list):\n",
    "            raise ValueError(\"attributes must be a list\")\n",
    "        for attribute in attributes:\n",
    "            if not isinstance(attribute, str):\n",
    "                raise ValueError(\"attributes must contain only strings\")\n",
    "            self.attrs[attribute] = input(f\"{attribute} - Enter value: \")\n",
    "    except ValueError as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "def insert_netCDF_global_metadata_dict(self, dictionary, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Inserts a dictionary of global netCDF metadata into a netCDF file.\n",
    "\n",
    "    Args:\n",
    "        self: The instance of the class that the function belongs to.\n",
    "        dictionary (dict): The dictionary of global netCDF metadata to be inserted.\n",
    "        new_file (bool, optional): A boolean flag indicating whether to create a new netCDF file or not. Default is True.\n",
    "        filename (str, optional): The name of the new netCDF file to be created. Default is \"new_file.nc\".\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If the dictionary parameter is not a valid dictionary.\n",
    "        FileNotFoundError: If the filename is invalid.\n",
    "        FileExistsError: If the specified filename already exists.\n",
    "\n",
    "    Returns:\n",
    "        None. The function doesn't return any value.\n",
    "    \"\"\"\n",
    "    if not isinstance(dictionary, dict):\n",
    "        raise TypeError(f\"{dictionary} is not a dictionary.\")\n",
    "    \n",
    "    for key, value in dictionary.items():\n",
    "        self.attrs[key] = value\n",
    "    if new_file:\n",
    "        if not os.path.isfile(filename):\n",
    "            if pathlib.Path(filename).suffix == \".nc\":\n",
    "                write_netcdf_file(self, filename)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid filename. Please provide a valid filename.\")\n",
    "        else:\n",
    "            raise FileExistsError(f\"{filename} already exists. Please change it or delete it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jsonschema\n",
    "from jsonschema.exceptions import ValidationError\n",
    "import os\n",
    "import pathlib\n",
    "import json \n",
    "def insert_netCDF_global_metadata_json(self, json_file, new_file=False, filename=\"new_file.nc\"):\n",
    "    \"\"\"\n",
    "    Inserts global metadata from a JSON file into a netCDF file.\n",
    "\n",
    "    Args:\n",
    "        self: The instance of the class calling the function.\n",
    "        json_file (str): The path to the JSON file containing the metadata.\n",
    "        new_file (bool, optional): Indicates whether a new netCDF file should be created. Default is False.\n",
    "        filename (str, optional): Specifies the name of the new netCDF file. Default is \"new_file.nc\".\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If there is an error opening the JSON file.\n",
    "        json.JSONDecodeError: If there is an error decoding the JSON file.\n",
    "        ValueError: If the filename is invalid.\n",
    "        FileExistsError: If the filename already exists.\n",
    "        ValidationError: If the JSON file does not match the specified schema.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"patternProperties\": {\n",
    "            \".*\": { \"type\": \"string\" }\n",
    "        },\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with open(json_file, 'r') as file:\n",
    "            metadata = json.load(file)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"Error opening JSON file. Please check if the file exists or if there are any permission issues.\")\n",
    "    except json.JSONDecodeError:\n",
    "        raise json.JSONDecodeError(\"Error decoding JSON file. Please check if the file contains valid JSON.\")\n",
    "    \n",
    "    try:\n",
    "        # Validate JSON against schema\n",
    "        jsonschema.validate(instance=metadata, schema=schema)\n",
    "    except ValidationError as e:\n",
    "        raise ValidationError(str(e))\n",
    "        \n",
    "    if new_file:\n",
    "        if pathlib.Path(filename).suffix == \".nc\":\n",
    "            if not os.path.isfile(filename):\n",
    "                write_netcdf_file(self, filename)\n",
    "            else:\n",
    "                raise FileExistsError(f\"{filename} already exists. Please change it or delete it.\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid filename. Please provide a valid filename.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gender', 'Age', 'Siblings_on_Board', 'Parents_on_Board', 'Ticket_Price', 'Port_of_Embarkation', 'Class', 'Adult/Child', 'Alone', 'Survived']\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq #noqa\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"Titanic.parquet\")\n",
    "wdwd = [str(dtype) for dtype in df.columns.tolist()]\n",
    "print(wdwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['category', 'float64', 'int8', 'int8', 'float64', 'category', 'category', 'category', 'bool', 'int64']\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq #noqa\n",
    "import pandas as pd\n",
    "df = pd.read_parquet(\"Titanic.parquet\")\n",
    "tipos_de_dados_legiveis = [str(dtype) for dtype in df.dtypes.to_list()]\n",
    "print(tipos_de_dados_legiveis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Gender', 'category'], ['Age', 'float64'], ['Siblings_on_Board', 'int8'], ['Parents_on_Board', 'int8'], ['Ticket_Price', 'float64'], ['Port_of_Embarkation', 'category'], ['Class', 'category'], ['Adult/Child', 'category'], ['Alone', 'bool'], ['Survived', 'int64']]\n"
     ]
    }
   ],
   "source": [
    "lista_de_listas = [[x, y] for x, y in zip(wdwd, tipos_de_dados_legiveis)]\n",
    "print(lista_de_listas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for coluna in lista_de_listas:\n",
    "    if coluna[1] == 'category':\n",
    "        coluna[1] = 'string'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Gender', 'string'], ['Age', 'float64'], ['Siblings_on_Board', 'int8'], ['Parents_on_Board', 'int8'], ['Ticket_Price', 'float64'], ['Port_of_Embarkation', 'string'], ['Class', 'string'], ['Adult/Child', 'string'], ['Alone', 'bool'], ['Survived', 'int64']]\n"
     ]
    }
   ],
   "source": [
    "print(lista_de_listas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "# Define the schema for the PyArrow Table\n",
    "table_schema = pa.schema(\n",
    "    [\n",
    "        pa.field(\n",
    "            lista_de_listas[0][0], lista_de_listas[0][1], metadata={\"Description\": \"The passenger's Gender\"}\n",
    "        ),\n",
    "        pa.field(\n",
    "            lista_de_listas[1][0],\n",
    "            lista_de_listas[1][1],\n",
    "            metadata={\"Description\": \"The passenger's Age\", \"Calculation\": \"No\"},\n",
    "        ),\n",
    "        pa.field(\n",
    "            lista_de_listas[2][0],\n",
    "            lista_de_listas[2][1],\n",
    "            metadata={\n",
    "                \"Description\": \"Number of sibilings that the passenger had on board\",\n",
    "                \"Calculation\": \"No\",\n",
    "            },\n",
    "        ),\n",
    "        pa.field(\n",
    "            lista_de_listas[3][0],\n",
    "            lista_de_listas[3][1],\n",
    "            metadata={\n",
    "                \"Description\": \"Number of parents that the passenger had on board\",\n",
    "                \"Calculation\": \"No\",\n",
    "            },\n",
    "        ),\n",
    "        pa.field(\n",
    "            lista_de_listas[4][0],\n",
    "            lista_de_listas[4][1],\n",
    "            metadata={\"Description\": \"Ticket's Price\", \"Calculation\": \"No\"},\n",
    "        ),\n",
    "        pa.field(\n",
    "            lista_de_listas[5][0],\n",
    "            lista_de_listas[5][1],\n",
    "            metadata={\"Description\": \"The port were the passenger embarked\"},\n",
    "        ),\n",
    "        pa.field(\n",
    "            lista_de_listas[6][0],\n",
    "            lista_de_listas[6][1],\n",
    "            metadata={\"Description\": \"The passenger's class on the ship\"},\n",
    "        ),\n",
    "        pa.field(\n",
    "            lista_de_listas[7][0],\n",
    "            lista_de_listas[7][1],\n",
    "            metadata={\"Description\": \"If the passenger is child or not\"},\n",
    "        ),\n",
    "        pa.field(\n",
    "            lista_de_listas[8][0],\n",
    "            lista_de_listas[8][1],\n",
    "            metadata={\"Description\": \"If the passenger is travelling alone or not\"},\n",
    "        ),\n",
    "        pa.field(\n",
    "            lista_de_listas[9][0],\n",
    "            lista_de_listas[9][1],\n",
    "            metadata={\n",
    "                \"Description\": \"If the passenger survived or not\",\n",
    "                \"Calculation\": \"No\",\n",
    "            },\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyarrow.Field<Gender: string>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pa.Table.from_pandas(df)  # Converting the pandas DataFrame to a PyArrow Table\n",
    "table = table.cast(table_schema)  # Cast the PyArrow Table to the specified schema\n",
    "print(str(table.field(0)))\n",
    "type(table.field(0).metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Description': \"The passenger's Gender\"}\n",
      "Description : The passenger's Gender\n"
     ]
    }
   ],
   "source": [
    "converted_metadata = {key.decode('utf-8'): value.decode('utf-8') for key, value in table.field(0).metadata.items()}\n",
    "# Now 'converted_metadata' contains regular strings\n",
    "print(converted_metadata)\n",
    "for word, value in converted_metadata.items():\n",
    "    print(f'{word} : {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "teste = str(table.field(0))\n",
    "teste = list(re.split(\"<|:\", teste))\n",
    "print(teste[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "    Description : The passenger's Gender\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "teste = str(table.field(0))\n",
    "teste = list(re.split(\"<|:\", teste))\n",
    "print(teste[1])\n",
    "converted_metadata = {key.decode('utf-8'): value.decode('utf-8') for key, value in table.field(0).metadata.items()}\n",
    "# Now 'converted_metadata' contains regular strings\n",
    "# print(converted_metadata)\n",
    "for word, value in converted_metadata.items():\n",
    "    print(f'    {word} : {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender\n",
      "    Description : The passenger's Gender\n",
      "Age\n",
      "    Description : The passenger's Age\n",
      "    Calculation : No\n",
      "Siblings_on_Board\n",
      "    Description : Number of sibilings that the passenger had on board\n",
      "    Calculation : No\n",
      "Parents_on_Board\n",
      "    Description : Number of parents that the passenger had on board\n",
      "    Calculation : No\n",
      "Ticket_Price\n",
      "    Description : Ticket's Price\n",
      "    Calculation : No\n",
      "Port_of_Embarkation\n",
      "    Description : The port were the passenger embarked\n",
      "Class\n",
      "    Description : The passenger's class on the ship\n",
      "Adult/Child\n",
      "    Description : If the passenger is child or not\n",
      "Alone\n",
      "    Description : If the passenger is travelling alone or not\n",
      "Survived\n",
      "    Description : If the passenger survived or not\n",
      "    Calculation : No\n"
     ]
    }
   ],
   "source": [
    "for i in range(table.num_columns):\n",
    "    col = str(table.field(i))\n",
    "    col = list(re.split(\"<|:\", col))\n",
    "    metadata = {key.decode('utf-8'): value.decode('utf-8') for key, value in table.field(i).metadata.items()}\n",
    "    print(col[1])\n",
    "    for word, value in metadata.items():\n",
    "        print(f'    {word} : {value}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pygmtsar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
